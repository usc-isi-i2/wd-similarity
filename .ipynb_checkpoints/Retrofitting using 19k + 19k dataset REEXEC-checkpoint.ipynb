{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dynamic-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations\n",
    "from math import comb\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strange-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "objective-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "p279WordSimSeededDF_wabs_text = pd.read_csv(\"../data/P279_dataset/P279_ChildPar_19k_WEmbAndCosSim.csv\")\n",
    "p279Seeded_SiblingsDF3_wabs_text = pd.read_csv(\"../data/P279_dataset/P279_Siblings_19k_WEmbAndCosSim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "joint-magnet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node2</th>\n",
       "      <th>node1</th>\n",
       "      <th>id</th>\n",
       "      <th>node1_label</th>\n",
       "      <th>label</th>\n",
       "      <th>node2_label</th>\n",
       "      <th>sent</th>\n",
       "      <th>node1_emb</th>\n",
       "      <th>node2_emb</th>\n",
       "      <th>bert2SentSim</th>\n",
       "      <th>...</th>\n",
       "      <th>BERT_abstract_emb_right</th>\n",
       "      <th>BERT_abstract_firstSent_emb_right</th>\n",
       "      <th>textEmb_7props_left</th>\n",
       "      <th>textEmb_7props_right</th>\n",
       "      <th>textEmb_2props_left</th>\n",
       "      <th>textEmb_2props_right</th>\n",
       "      <th>textEmb_7props_cosSim</th>\n",
       "      <th>textEmb_2props_cosSim</th>\n",
       "      <th>BERT_abstract_cosSim</th>\n",
       "      <th>BERT_abstract_firstSent_cosSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q100171002</td>\n",
       "      <td>Q1503443</td>\n",
       "      <td>Q1503443-P279-Q100171002-8282ae74-0</td>\n",
       "      <td>secrecy</td>\n",
       "      <td>P279</td>\n",
       "      <td>concealment</td>\n",
       "      <td>secrecy is concealment</td>\n",
       "      <td>[ 4.83600467e-01  1.25958338e-01  1.84784138e+...</td>\n",
       "      <td>[ 3.61319035e-01  1.03393383e-01  1.50166345e+...</td>\n",
       "      <td>0.901134</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.87660795, 0.4991357, -0.39552155, 0.7046891...</td>\n",
       "      <td>[0.36156428, -0.015657336, -0.14483449, -0.253...</td>\n",
       "      <td>[0.79082793, 0.53679967, -0.3825465, 0.6778466...</td>\n",
       "      <td>[0.36156428, -0.015657336, -0.14483449, -0.253...</td>\n",
       "      <td>0.832602</td>\n",
       "      <td>0.823419</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1002697</td>\n",
       "      <td>Q49850</td>\n",
       "      <td>Q49850-P279-Q1002697-0c52cf68-0</td>\n",
       "      <td>journal</td>\n",
       "      <td>P279</td>\n",
       "      <td>periodical</td>\n",
       "      <td>journal is periodical</td>\n",
       "      <td>[-5.87019742e-01 -3.76376987e-01  2.21003819e+...</td>\n",
       "      <td>[-2.23196611e-01 -4.97725368e-01  2.20271492e+...</td>\n",
       "      <td>0.863449</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.28667202591896057, -0.4099476933479309, 0....</td>\n",
       "      <td>[-0.25435054302215576, -0.92085862159729, 1.68...</td>\n",
       "      <td>[1.256428, 0.3254261, -0.26960722, 0.101883665...</td>\n",
       "      <td>[0.92698413, 0.32396156, -0.7647308, 0.6973268...</td>\n",
       "      <td>[1.256428, 0.3254261, -0.26960722, 0.101883665...</td>\n",
       "      <td>[1.0344226, 0.39984593, -0.76180136, 0.8256311...</td>\n",
       "      <td>0.742638</td>\n",
       "      <td>0.734428</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q101998</td>\n",
       "      <td>Q4421</td>\n",
       "      <td>Q4421-P279-Q101998-d0983886-0</td>\n",
       "      <td>forest</td>\n",
       "      <td>P279</td>\n",
       "      <td>biome</td>\n",
       "      <td>forest is biome</td>\n",
       "      <td>[-4.80742343e-02 -4.51617390e-01  1.48896754e+...</td>\n",
       "      <td>[ 5.09670794e-01 -4.42380428e-01  1.53245163e+...</td>\n",
       "      <td>0.507148</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.12320789694786072, 0.2723684310913086, 0.05...</td>\n",
       "      <td>[0.5991100072860718, 0.15195603668689728, 0.59...</td>\n",
       "      <td>[0.8141036, 0.14491142, -0.59703183, 0.335001,...</td>\n",
       "      <td>[-0.16750671, -0.17960861, -0.58211946, -0.687...</td>\n",
       "      <td>[0.91628444, 0.104261845, -0.49683735, 0.21296...</td>\n",
       "      <td>[-0.13534825, -0.23398273, -0.5165668, -0.7297...</td>\n",
       "      <td>0.647031</td>\n",
       "      <td>0.707611</td>\n",
       "      <td>0.508060</td>\n",
       "      <td>0.455747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q102165</td>\n",
       "      <td>Q2294</td>\n",
       "      <td>Q2294-P279-Q102165-0893a180-0</td>\n",
       "      <td>proton</td>\n",
       "      <td>P279</td>\n",
       "      <td>nucleon</td>\n",
       "      <td>proton is nucleon</td>\n",
       "      <td>[-3.39149237e-01  2.01575115e-01  1.08608294e+...</td>\n",
       "      <td>[-6.87960759e-02 -1.65659860e-01  9.53789592e-...</td>\n",
       "      <td>0.798707</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.17410606145858765, 0.6839145421981812, -0.8...</td>\n",
       "      <td>[-0.04499293863773346, 0.6921464204788208, -0....</td>\n",
       "      <td>[0.469377, 0.7162001, -0.36740896, 0.76742333,...</td>\n",
       "      <td>[-0.11307852, 0.65730673, -0.13959256, 1.46633...</td>\n",
       "      <td>[0.4080446, 0.7498908, -0.2665757, 0.74437106,...</td>\n",
       "      <td>[-0.11307852, 0.65730673, -0.13959256, 1.46633...</td>\n",
       "      <td>0.836531</td>\n",
       "      <td>0.847591</td>\n",
       "      <td>0.855959</td>\n",
       "      <td>0.770030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q102205</td>\n",
       "      <td>Q11435</td>\n",
       "      <td>Q11435-P279-Q102205-7b448d05-0</td>\n",
       "      <td>liquid</td>\n",
       "      <td>P279</td>\n",
       "      <td>fluid</td>\n",
       "      <td>liquid is fluid</td>\n",
       "      <td>[-5.40423356e-02 -1.01775277e+00  2.21057415e+...</td>\n",
       "      <td>[ 1.30038410e-01 -8.53226840e-01  2.37821031e+...</td>\n",
       "      <td>0.934246</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.4393930733203888, 0.7159943580627441, 0.647...</td>\n",
       "      <td>[0.5091343522071838, -0.05845202878117561, 1.0...</td>\n",
       "      <td>[-0.19995248, 0.65605164, -0.14234662, 0.43931...</td>\n",
       "      <td>[0.4293771, 1.1976917, 0.04422909, 0.5975481, ...</td>\n",
       "      <td>[-0.45549682, 0.73478854, -0.1980287, 0.436793...</td>\n",
       "      <td>[0.33631665, 1.1661042, 0.13744242, 0.6776439,...</td>\n",
       "      <td>0.765589</td>\n",
       "      <td>0.780342</td>\n",
       "      <td>0.752693</td>\n",
       "      <td>0.515319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        node2     node1                                   id node1_label  \\\n",
       "0  Q100171002  Q1503443  Q1503443-P279-Q100171002-8282ae74-0     secrecy   \n",
       "1    Q1002697    Q49850      Q49850-P279-Q1002697-0c52cf68-0     journal   \n",
       "2     Q101998     Q4421        Q4421-P279-Q101998-d0983886-0      forest   \n",
       "3     Q102165     Q2294        Q2294-P279-Q102165-0893a180-0      proton   \n",
       "4     Q102205    Q11435       Q11435-P279-Q102205-7b448d05-0      liquid   \n",
       "\n",
       "  label  node2_label                    sent  \\\n",
       "0  P279  concealment  secrecy is concealment   \n",
       "1  P279   periodical   journal is periodical   \n",
       "2  P279        biome         forest is biome   \n",
       "3  P279      nucleon       proton is nucleon   \n",
       "4  P279        fluid         liquid is fluid   \n",
       "\n",
       "                                           node1_emb  \\\n",
       "0  [ 4.83600467e-01  1.25958338e-01  1.84784138e+...   \n",
       "1  [-5.87019742e-01 -3.76376987e-01  2.21003819e+...   \n",
       "2  [-4.80742343e-02 -4.51617390e-01  1.48896754e+...   \n",
       "3  [-3.39149237e-01  2.01575115e-01  1.08608294e+...   \n",
       "4  [-5.40423356e-02 -1.01775277e+00  2.21057415e+...   \n",
       "\n",
       "                                           node2_emb  bert2SentSim  ...  \\\n",
       "0  [ 3.61319035e-01  1.03393383e-01  1.50166345e+...      0.901134  ...   \n",
       "1  [-2.23196611e-01 -4.97725368e-01  2.20271492e+...      0.863449  ...   \n",
       "2  [ 5.09670794e-01 -4.42380428e-01  1.53245163e+...      0.507148  ...   \n",
       "3  [-6.87960759e-02 -1.65659860e-01  9.53789592e-...      0.798707  ...   \n",
       "4  [ 1.30038410e-01 -8.53226840e-01  2.37821031e+...      0.934246  ...   \n",
       "\n",
       "                             BERT_abstract_emb_right  \\\n",
       "0                                                NaN   \n",
       "1  [-0.28667202591896057, -0.4099476933479309, 0....   \n",
       "2  [0.12320789694786072, 0.2723684310913086, 0.05...   \n",
       "3  [0.17410606145858765, 0.6839145421981812, -0.8...   \n",
       "4  [0.4393930733203888, 0.7159943580627441, 0.647...   \n",
       "\n",
       "                   BERT_abstract_firstSent_emb_right  \\\n",
       "0                                                NaN   \n",
       "1  [-0.25435054302215576, -0.92085862159729, 1.68...   \n",
       "2  [0.5991100072860718, 0.15195603668689728, 0.59...   \n",
       "3  [-0.04499293863773346, 0.6921464204788208, -0....   \n",
       "4  [0.5091343522071838, -0.05845202878117561, 1.0...   \n",
       "\n",
       "                                 textEmb_7props_left  \\\n",
       "0  [0.87660795, 0.4991357, -0.39552155, 0.7046891...   \n",
       "1  [1.256428, 0.3254261, -0.26960722, 0.101883665...   \n",
       "2  [0.8141036, 0.14491142, -0.59703183, 0.335001,...   \n",
       "3  [0.469377, 0.7162001, -0.36740896, 0.76742333,...   \n",
       "4  [-0.19995248, 0.65605164, -0.14234662, 0.43931...   \n",
       "\n",
       "                                textEmb_7props_right  \\\n",
       "0  [0.36156428, -0.015657336, -0.14483449, -0.253...   \n",
       "1  [0.92698413, 0.32396156, -0.7647308, 0.6973268...   \n",
       "2  [-0.16750671, -0.17960861, -0.58211946, -0.687...   \n",
       "3  [-0.11307852, 0.65730673, -0.13959256, 1.46633...   \n",
       "4  [0.4293771, 1.1976917, 0.04422909, 0.5975481, ...   \n",
       "\n",
       "                                 textEmb_2props_left  \\\n",
       "0  [0.79082793, 0.53679967, -0.3825465, 0.6778466...   \n",
       "1  [1.256428, 0.3254261, -0.26960722, 0.101883665...   \n",
       "2  [0.91628444, 0.104261845, -0.49683735, 0.21296...   \n",
       "3  [0.4080446, 0.7498908, -0.2665757, 0.74437106,...   \n",
       "4  [-0.45549682, 0.73478854, -0.1980287, 0.436793...   \n",
       "\n",
       "                                textEmb_2props_right textEmb_7props_cosSim  \\\n",
       "0  [0.36156428, -0.015657336, -0.14483449, -0.253...              0.832602   \n",
       "1  [1.0344226, 0.39984593, -0.76180136, 0.8256311...              0.742638   \n",
       "2  [-0.13534825, -0.23398273, -0.5165668, -0.7297...              0.647031   \n",
       "3  [-0.11307852, 0.65730673, -0.13959256, 1.46633...              0.836531   \n",
       "4  [0.33631665, 1.1661042, 0.13744242, 0.6776439,...              0.765589   \n",
       "\n",
       "  textEmb_2props_cosSim BERT_abstract_cosSim BERT_abstract_firstSent_cosSim  \n",
       "0              0.823419            -1.000000                      -1.000000  \n",
       "1              0.734428            -1.000000                      -1.000000  \n",
       "2              0.707611             0.508060                       0.455747  \n",
       "3              0.847591             0.855959                       0.770030  \n",
       "4              0.780342             0.752693                       0.515319  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p279WordSimSeededDF_wabs_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "random-france",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19454.000000\n",
       "mean         0.602876\n",
       "std          0.146181\n",
       "min          0.064503\n",
       "25%          0.493110\n",
       "50%          0.597949\n",
       "75%          0.711631\n",
       "max          1.000000\n",
       "Name: bert2SentSim, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p279WordSimSeededDF_wabs_text.bert2SentSim.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incorporated-ambassador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node2', 'node1', 'id', 'node1_label', 'label', 'node2_label', 'sent',\n",
       "       'node1_emb', 'node2_emb', 'bert2SentSim', 'abstract',\n",
       "       'abstract_firstSent', 'BERT_abstract_emb',\n",
       "       'BERT_abstract_firstSent_emb', 'abstract_right',\n",
       "       'abstract_firstSent_right', 'BERT_abstract_emb_right',\n",
       "       'BERT_abstract_firstSent_emb_right', 'textEmb_7props_left',\n",
       "       'textEmb_7props_right', 'textEmb_2props_left', 'textEmb_2props_right',\n",
       "       'textEmb_7props_cosSim', 'textEmb_2props_cosSim',\n",
       "       'BERT_abstract_cosSim', 'BERT_abstract_firstSent_cosSim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p279WordSimSeededDF_wabs_text.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "original-grass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19454.000000\n",
       "mean         0.772184\n",
       "std          0.122326\n",
       "min          0.120480\n",
       "25%          0.684141\n",
       "50%          0.793718\n",
       "75%          0.874284\n",
       "max          1.000000\n",
       "Name: bert2SentSim, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p279Seeded_SiblingsDF3_wabs_text.bert2SentSim.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-rabbit",
   "metadata": {},
   "source": [
    "# Embeddings Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-intake",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Complex, Transe Embeddings Datasets generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tamil-activity",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353LatestAnnot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "immune-nashville",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wordSimOG_DF = pd.read_csv('../data/wordsim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "residential-cleaners",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New = wordSim353AnnotDF_New.set_index(['Word 1', 'Word 2']).join(wordSimOG_DF.set_index(['Word 1', 'Word 2'])[['word1_kg_id', 'word2_kg_id']]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "current-great",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>ID</th>\n",
       "      <th>H_Sim</th>\n",
       "      <th>H_Dim</th>\n",
       "      <th>F_Sim</th>\n",
       "      <th>F_Dim</th>\n",
       "      <th>N_Sim</th>\n",
       "      <th>N_Dim</th>\n",
       "      <th>D_Sim</th>\n",
       "      <th>D_Dim</th>\n",
       "      <th>P_Sim</th>\n",
       "      <th>P_Dim</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Stdev</th>\n",
       "      <th>H_orig</th>\n",
       "      <th>H_reversed</th>\n",
       "      <th>word1_kg_id</th>\n",
       "      <th>word2_kg_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>2.1250</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>Q34211</td>\n",
       "      <td>Q454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>3.0625</td>\n",
       "      <td>6.9375</td>\n",
       "      <td>Q34211</td>\n",
       "      <td>Q13648784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>4.0625</td>\n",
       "      <td>5.9375</td>\n",
       "      <td>Q8333</td>\n",
       "      <td>Q178022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>3.0</td>\n",
       "      <td>u</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>4.9375</td>\n",
       "      <td>Q8333</td>\n",
       "      <td>Q21004260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>s</td>\n",
       "      <td>2.0</td>\n",
       "      <td>s</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>4.8750</td>\n",
       "      <td>5.1250</td>\n",
       "      <td>Q13371</td>\n",
       "      <td>Q49112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word 1         Word 2   ID  H_Sim H_Dim  F_Sim F_Dim  N_Sim N_Dim  D_Sim  \\\n",
       "0   Arafat          peace    8      3     D      4   NaN      3     U      4   \n",
       "1   Arafat         terror    9      3     D      4   NaN      3     U      4   \n",
       "2      FBI    fingerprint  109      3     D      4   NaN      4   NaN      3   \n",
       "3      FBI  investigation  110      3     U      3     U      3     U      3   \n",
       "4  Harvard           Yale  137      2     S      3     S      2     S      2   \n",
       "\n",
       "  D_Dim  P_Sim P_Dim  Avg     Stdev  H_orig  H_reversed word1_kg_id  \\\n",
       "0   NaN    4.0   NaN  3.6  0.547723  2.1250      7.8750      Q34211   \n",
       "1   NaN    4.0   NaN  3.6  0.547723  3.0625      6.9375      Q34211   \n",
       "2     u    4.0   NaN  3.6  0.547723  4.0625      5.9375       Q8333   \n",
       "3     u    3.0     u  3.0  0.000000  5.0625      4.9375       Q8333   \n",
       "4     s    2.0     s  2.2  0.447214  4.8750      5.1250      Q13371   \n",
       "\n",
       "  word2_kg_id  \n",
       "0        Q454  \n",
       "1   Q13648784  \n",
       "2     Q178022  \n",
       "3   Q21004260  \n",
       "4      Q49112  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "valued-progressive",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# wordSimSet = set(wordSim353AnnotDF_New.word1_kg_id.to_list() + wordSim353AnnotDF_New.word2_kg_id.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "different-vancouver",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wordSimSet = set(p279WordSimSeededDF_wabs_text.node1.to_list() + p279WordSimSeededDF_wabs_text.node2.to_list() + p279Seeded_SiblingsDF3_wabs_text.node1.to_list() + p279Seeded_SiblingsDF3_wabs_text.node2.to_list() + wordSim353AnnotDF_New.word1_kg_id.to_list() + wordSim353AnnotDF_New.word2_kg_id.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quick-lewis",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19166"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordSimSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "collected-regular",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q1499717\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q64763437\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q17144564\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q4765290\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q16000518\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q6423382\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q2177259\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q100448831\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q2857578\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q13577338\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q96158854\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q7892\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q29053864\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q7675683\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q2380954\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q77527200\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q21083881\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q211521\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q66368425\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q16023742\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q97627995\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q16721350\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q32979618\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q4553362\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q98232491\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q66194218\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q5372\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q42559432\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q25481995\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q61466331\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q6983403\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q84105477\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q11002\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q30107768\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q56753514\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q91927989\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q12047900\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q2144951\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q11698973\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q517386\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q17097928\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q5281737\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q27983054\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q19838691\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q101541623\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q17376918\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q5193377\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q23013268\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q66363580\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q55693905\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q68131879\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q85803433\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q29053744\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q82785806\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q21406831\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q29957548\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q78710574\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q6462051\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q1042920\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q7925\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q56297152\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q2515879\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q28324850\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q28132458\n",
      "Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/Q2849391\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "compEmbeddings = {}\n",
    "transeEmbeddings = {}\n",
    "\n",
    "for wordID in wordSimSet:\n",
    "    try:\n",
    "        resp = requests.get(\"http://ckg07:9200/wikidatadwd-augmented/_doc/\"+wordID).json()['_source']\n",
    "        compEmbeddings[wordID] = resp['graph_embedding_complex']\n",
    "        transeEmbeddings[wordID] = resp['graph_embeddings_transe']\n",
    "    except:\n",
    "        print(\"Failure returned for http://ckg07:9200/wikidatadwd-augmented/_doc/\"+wordID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "elect-gothic",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(compEmbeddings.items(), columns=['node', 'complex_embedding']).to_csv('../data/wordsim353_complex_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "combined-theme",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(transeEmbeddings.items(), columns=['node', 'transe_embedding']).to_csv('../data/wordsim353_transe_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-extraction",
   "metadata": {},
   "source": [
    "# Target Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-tuition",
   "metadata": {},
   "source": [
    "## Probase Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opened-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "probDF_Qnodes_DF_WQnodes1_subset = pd.read_csv('../data/probase/probase_WQnodes_subset_and_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "major-peter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>node1_label</th>\n",
       "      <th>node2_label</th>\n",
       "      <th>no_of_relations</th>\n",
       "      <th>node1_qnode</th>\n",
       "      <th>node2_qnode</th>\n",
       "      <th>n1_final_qnode</th>\n",
       "      <th>n2_final_qnode</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>factor</td>\n",
       "      <td>age</td>\n",
       "      <td>35167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q15061738</td>\n",
       "      <td>Q100343219</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>factor</td>\n",
       "      <td>gender</td>\n",
       "      <td>14230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q48277</td>\n",
       "      <td>Q15061738</td>\n",
       "      <td>Q48277</td>\n",
       "      <td>0.913568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>factor</td>\n",
       "      <td>temperature</td>\n",
       "      <td>13660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q15061738</td>\n",
       "      <td>P2076</td>\n",
       "      <td>0.909663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>metal</td>\n",
       "      <td>copper</td>\n",
       "      <td>11142</td>\n",
       "      <td>Q11426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q11426</td>\n",
       "      <td>Q15830500</td>\n",
       "      <td>0.890199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>variable</td>\n",
       "      <td>age</td>\n",
       "      <td>9375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q10954303</td>\n",
       "      <td>Q100343219</td>\n",
       "      <td>0.873703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 node1_label  node2_label  no_of_relations node1_qnode  \\\n",
       "0           0      factor          age            35167         NaN   \n",
       "1           5      factor       gender            14230         NaN   \n",
       "2           6      factor  temperature            13660         NaN   \n",
       "3           7       metal       copper            11142      Q11426   \n",
       "4           9    variable          age             9375         NaN   \n",
       "\n",
       "  node2_qnode n1_final_qnode n2_final_qnode       sim  \n",
       "0         NaN      Q15061738     Q100343219  1.000000  \n",
       "1      Q48277      Q15061738         Q48277  0.913568  \n",
       "2         NaN      Q15061738          P2076  0.909663  \n",
       "3         NaN         Q11426      Q15830500  0.890199  \n",
       "4         NaN      Q10954303     Q100343219  0.873703  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probDF_Qnodes_DF_WQnodes1_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "photographic-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "probDF_Qnodes_DF_WQnodes1_subset = probDF_Qnodes_DF_WQnodes1_subset.rename(columns={'n1_final_qnode': 'node1', 'n2_final_qnode': 'node2', 'sim': 'bert2SentSim'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "russian-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "probDF_Qnodes_DF_WQnodes1_subset['bert2SentSim'] = 0.5 + 0.5 * probDF_Qnodes_DF_WQnodes1_subset['bert2SentSim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "painted-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.600841e+06\n",
       "mean     5.429549e-01\n",
       "std      5.363352e-02\n",
       "min      5.000000e-01\n",
       "25%      5.000000e-01\n",
       "50%      5.331083e-01\n",
       "75%      5.662167e-01\n",
       "max      1.000000e+00\n",
       "Name: bert2SentSim, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probDF_Qnodes_DF_WQnodes1_subset['bert2SentSim'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-occupation",
   "metadata": {},
   "source": [
    "# Retrofitting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "consolidated-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(embedDict):\n",
    "    for key, val in embedDict.items():\n",
    "        temp = np.array([float(val1) for val1 in val])\n",
    "        temp2 = temp**2\n",
    "        embedDict[key] = temp / np.sqrt((temp2.sum() + 1e-6))\n",
    "    return embedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "irish-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchEmbeddings(df):\n",
    "    embedDict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        embedDict[row.node] = row.value\n",
    "    return normalize(embedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "orange-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchNeighbours(df):\n",
    "    neighboursDict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        if row.node1 not in neighboursDict:\n",
    "            neighboursDict[row.node1] = []\n",
    "        neighboursDict[row.node1].append((row.node2, row.bert2SentSim))\n",
    "        \n",
    "        if row.node2 not in neighboursDict:\n",
    "            neighboursDict[row.node2] = []\n",
    "        neighboursDict[row.node2].append((row.node1, row.bert2SentSim))\n",
    "    print(max([len(neigh) for neigh in neighboursDict.values()]))\n",
    "    return neighboursDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "joined-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofit(embedDict, neighDict, weightCase):\n",
    "    newEmbedDict = {}\n",
    "    for word in embedDict.keys():\n",
    "        if word in neighDict:\n",
    "            neighbs = neighDict[word]\n",
    "            neighbs = list(filter(lambda p: p[0] in embedDict, neighbs))\n",
    "            if len(neighbs) == 0:\n",
    "                newEmbedDict[word] = embedDict[word]\n",
    "                continue\n",
    "#             assert len(neighbs) == 1\n",
    "            sumOfSims = sum([neighb[1] for neighb in neighbs])\n",
    "            sumOfEmbs = sum([embedDict[neighb[0]] * float(neighb[1]) for neighb in neighbs])\n",
    "            if weightCase == 1:\n",
    "                newEmbedDict[word] = (embedDict[word] * (len(neighbs)) + sumOfEmbs) / ((len(neighbs)) + sumOfSims)\n",
    "            elif weightCase == 2:\n",
    "                newEmbedDict[word] = (embedDict[word] * (len(neighbs))**2 + sumOfEmbs) / ((len(neighbs))**2 + sumOfSims)\n",
    "            elif weightCase == 0.5:\n",
    "                newEmbedDict[word] = (embedDict[word] * (len(neighbs))**0.5 + sumOfEmbs) / ((len(neighbs))**0.5 + sumOfSims)\n",
    "            else:\n",
    "                raise\n",
    "        else:\n",
    "            newEmbedDict[word] = embedDict[word]\n",
    "    return newEmbedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "collected-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineDistances(embedDict, newEmbedDict):\n",
    "    dist = []\n",
    "    for word in embedDict.keys():\n",
    "        dist.append(euclidean_distances([embedDict[word]], [newEmbedDict[word]])[0][0])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-dimension",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-milan",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Sample attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "substantial-aggregate",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p279WordSimSeededDF_wabs_text_sample = p279WordSimSeededDF_wabs_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "analyzed-passion",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embedDict = fetchEmbeddings(p279WordSimSeededDF_wabs_text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "japanese-defense",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "neighDict = fetchNeighbours(p279WordSimSeededDF_wabs_text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dying-nigeria",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "newEmbedDict = retrofit(embedDict, neighDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "reduced-avenue",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "advised-hollywood",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dists = determineDistances(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "authentic-greene",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1034.000000\n",
       "mean        0.281990\n",
       "std         0.054759\n",
       "min         0.069792\n",
       "25%         0.244698\n",
       "50%         0.278019\n",
       "75%         0.319656\n",
       "max         0.450444\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dists).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-transportation",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ChildPar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "central-spyware",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embedDict = fetchEmbeddings(p279WordSimSeededDF_wabs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "white-genesis",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "neighDict = fetchNeighbours(p279WordSimSeededDF_wabs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "registered-original",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "newEmbedDict = retrofit(embedDict, neighDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "experienced-conspiracy",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18860"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "every-interface",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dists = determineDistances(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "specified-berry",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    18860.000000\n",
       "mean         0.283712\n",
       "std          0.056573\n",
       "min          0.050719\n",
       "25%          0.246137\n",
       "50%          0.281897\n",
       "75%          0.319687\n",
       "max          0.564922\n",
       "dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dists).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-calvin",
   "metadata": {},
   "source": [
    "# Correlation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "answering-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelSamples(score):\n",
    "    return 'I' if score <= 1.75 else 'U' if score >= 3.5 else 'M'\n",
    "LABELS = ['I','U','M']\n",
    "def fetchCorrelationResults(embedDict, newEmbedDict):\n",
    "    wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')\n",
    "    print(f\"Length of wordsim dataset: {len(wordSim353AnnotDF_New)}\")\n",
    "    assert wordSim353AnnotDF_New.word1_kg_id.isna().sum() == 0\n",
    "    assert wordSim353AnnotDF_New.word2_kg_id.isna().sum() == 0\n",
    "    wordSim353AnnotDF_New['category'] = wordSim353AnnotDF_New.Avg.apply(labelSamples)\n",
    "    wordSim353AnnotDF_New2 = wordSim353AnnotDF_New[wordSim353AnnotDF_New.apply(lambda p: p['word1_kg_id'] in embedDict and p['word2_kg_id'] in embedDict, axis=1)]\n",
    "    wordSimMissingSet = set(wordSim353AnnotDF_New[wordSim353AnnotDF_New.word1_kg_id.apply(lambda p: p not in embedDict)].word1_kg_id.to_list() + wordSim353AnnotDF_New[wordSim353AnnotDF_New.word2_kg_id.apply(lambda p: p not in embedDict)].word2_kg_id.to_list())\n",
    "#     wordSimMissingSet\n",
    "    print(f\"No. of pairs with some value for embeddings: {len(wordSim353AnnotDF_New2)}\")\n",
    "    wordSim353AnnotDF_New2['textOld'] = wordSim353AnnotDF_New2.apply(lambda p: cosine_similarity(np.array(embedDict[p['word1_kg_id']]).reshape(1,-1), np.array(embedDict[p['word2_kg_id']]).reshape(1,-1))[0][0], axis=1)\n",
    "    wordSim353AnnotDF_New2['textNew'] = wordSim353AnnotDF_New2.apply(lambda p: cosine_similarity(np.array(newEmbedDict[p['word1_kg_id']]).reshape(1,-1), np.array(newEmbedDict[p['word2_kg_id']]).reshape(1,-1))[0][0], axis=1)\n",
    "    wordSim353AnnotDF_New2['textOld'] = wordSim353AnnotDF_New2.textOld.apply(lambda p: 4 - 3 * p)\n",
    "    wordSim353AnnotDF_New2['textNew'] = wordSim353AnnotDF_New2.textNew.apply(lambda p: 4 - 3 * p)\n",
    "    print(f\"KT Corr of old emb with Annotated Avg: {stats.kendalltau(wordSim353AnnotDF_New2['textOld'], wordSim353AnnotDF_New2['Avg'])}\")\n",
    "    print(f\"KT Corr of new emb with Annotated Avg: {stats.kendalltau(wordSim353AnnotDF_New2['textNew'], wordSim353AnnotDF_New2['Avg'])}\")\n",
    "    print(f\"KT Corr of old emb with Human Avg Reversed: {stats.kendalltau(wordSim353AnnotDF_New2['textOld'], wordSim353AnnotDF_New2['H_reversed'])}\")\n",
    "    print(f\"KT Corr of new emb with Human Avg Reversed: {stats.kendalltau(wordSim353AnnotDF_New2['textNew'], wordSim353AnnotDF_New2['H_reversed'])}\")\n",
    "    \n",
    "    print(f\"Classification Accuracy of old embeddings categories vs annotated averages categories: {accuracy_score(wordSim353AnnotDF_New2['textOld'].apply(labelSamples), wordSim353AnnotDF_New2['category'])}\")\n",
    "    print(f\"Classification Accuracy of new embeddings categories vs annotated averages categories: {accuracy_score(wordSim353AnnotDF_New2['textNew'].apply(labelSamples), wordSim353AnnotDF_New2['category'])}\")\n",
    "    \n",
    "    cm_old = confusion_matrix(wordSim353AnnotDF_New2['category'], wordSim353AnnotDF_New2['textOld'].apply(labelSamples), labels=LABELS)\n",
    "    cm_new = confusion_matrix(wordSim353AnnotDF_New2['category'], wordSim353AnnotDF_New2['textNew'].apply(labelSamples), labels=LABELS)\n",
    "    \n",
    "    return wordSimMissingSet, cm_old, cm_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-bacon",
   "metadata": {},
   "source": [
    "# Dataset-Target Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "premier-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedDictMaster = {}\n",
    "newEmbedDictMaster = {}\n",
    "confusionMatrixMaster = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-heading",
   "metadata": {},
   "source": [
    "### Text Embeddings | 19k + 19k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stretch-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "textEmb_7props_DF = pd.read_csv('../data/P279_dataset/output/P279-text-embedding-7-props-all.tsv', sep='\\t')\n",
    "textEmb_7props_DF['value'] = textEmb_7props_DF['value'].apply(lambda p: [float(p1) for p1 in p.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sapphire-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>property</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q99907279</td>\n",
       "      <td>text_embedding</td>\n",
       "      <td>[-0.13148594, 0.20147827, 0.015393771, 1.12779...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q99898510</td>\n",
       "      <td>text_embedding</td>\n",
       "      <td>[0.19386396, 0.41306746, -0.32783666, 0.450188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q99526025</td>\n",
       "      <td>text_embedding</td>\n",
       "      <td>[0.89479333, 0.27038768, 0.15989815, -0.092144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q99365546</td>\n",
       "      <td>text_embedding</td>\n",
       "      <td>[0.10686234, 0.95048314, 0.32389534, 0.1960084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q993308</td>\n",
       "      <td>text_embedding</td>\n",
       "      <td>[0.23211154, 0.060303785, -1.0003253, 0.637829...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        node        property  \\\n",
       "0  Q99907279  text_embedding   \n",
       "1  Q99898510  text_embedding   \n",
       "2  Q99526025  text_embedding   \n",
       "3  Q99365546  text_embedding   \n",
       "4    Q993308  text_embedding   \n",
       "\n",
       "                                               value  \n",
       "0  [-0.13148594, 0.20147827, 0.015393771, 1.12779...  \n",
       "1  [0.19386396, 0.41306746, -0.32783666, 0.450188...  \n",
       "2  [0.89479333, 0.27038768, 0.15989815, -0.092144...  \n",
       "3  [0.10686234, 0.95048314, 0.32389534, 0.1960084...  \n",
       "4  [0.23211154, 0.060303785, -1.0003253, 0.637829...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textEmb_7props_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rising-lawyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19155"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textEmb_7props_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "closed-charles",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662\n",
      "No. of keys in embedDict: 19155\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19155.000000\n",
      "mean         0.271898\n",
      "std          0.057984\n",
      "min          0.000000\n",
      "25%          0.231530\n",
      "50%          0.268294\n",
      "75%          0.308696\n",
      "max          0.564922\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 326\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.3975352135008474, pvalue=2.274798622604064e-24)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3876948460943732, pvalue=2.944054929116869e-23)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.4253385100650523, pvalue=3.397679519805734e-30)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.41910186320873755, pvalue=2.2966918648680457e-29)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.5950920245398773\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.5153374233128835\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19155.000000\n",
      "mean         0.193850\n",
      "std          0.113418\n",
      "min          0.000000\n",
      "25%          0.086588\n",
      "50%          0.192671\n",
      "75%          0.291258\n",
      "max          0.564922\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 326\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.3975352135008474, pvalue=2.274798622604064e-24)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3896871945725784, pvalue=1.7567320499364868e-23)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.4253385100650523, pvalue=3.397679519805734e-30)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.429300613416863, pvalue=9.889526081071043e-31)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.5950920245398773\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.5920245398773006\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19155.000000\n",
      "mean         0.325848\n",
      "std          0.071942\n",
      "min          0.000000\n",
      "25%          0.277981\n",
      "50%          0.321763\n",
      "75%          0.370070\n",
      "max          0.648638\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 326\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.3975352135008474, pvalue=2.274798622604064e-24)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.380602867202403, pvalue=1.7935601808141945e-22)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.4253385100650523, pvalue=3.397679519805734e-30)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.3995893685604078, pvalue=7.608607437786723e-27)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.5950920245398773\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.39570552147239263\n"
     ]
    }
   ],
   "source": [
    "embedDict = fetchEmbeddings(textEmb_7props_DF)\n",
    "embedDictMaster['text_7props_19k'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['text_7props_19k_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _, confusionMatrixMaster['text_7props_19k_old_'+str(weightCase)], confusionMatrixMaster['text_7props_19k_new_'+str(weightCase)] = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-isolation",
   "metadata": {},
   "source": [
    "### Text Embeddings - 2 props | 19k + 19k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bored-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "textEmb_7props_DF = pd.read_csv('../data/P279_dataset/output/P279-text-embedding-2-props-all.tsv', sep='\\t')\n",
    "textEmb_7props_DF['value'] = textEmb_7props_DF['value'].apply(lambda p: [float(p1) for p1 in p.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "speaking-sharing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>property</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q99907279</td>\n",
       "      <td>text_embedding</td>\n",
       "      <td>[-0.13148594, 0.20147827, 0.015393771, 1.12779...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q99898510</td>\n",
       "      <td>text_embedding</td>\n",
       "      <td>[0.19386396, 0.41306746, -0.32783666, 0.450188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q99526025</td>\n",
       "      <td>text_embedding</td>\n",
       "      <td>[0.89479333, 0.27038768, 0.15989815, -0.092144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q99365546</td>\n",
       "      <td>text_embedding</td>\n",
       "      <td>[0.10686234, 0.95048314, 0.32389534, 0.1960084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q993308</td>\n",
       "      <td>text_embedding</td>\n",
       "      <td>[0.23211154, 0.060303785, -1.0003253, 0.637829...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        node        property  \\\n",
       "0  Q99907279  text_embedding   \n",
       "1  Q99898510  text_embedding   \n",
       "2  Q99526025  text_embedding   \n",
       "3  Q99365546  text_embedding   \n",
       "4    Q993308  text_embedding   \n",
       "\n",
       "                                               value  \n",
       "0  [-0.13148594, 0.20147827, 0.015393771, 1.12779...  \n",
       "1  [0.19386396, 0.41306746, -0.32783666, 0.450188...  \n",
       "2  [0.89479333, 0.27038768, 0.15989815, -0.092144...  \n",
       "3  [0.10686234, 0.95048314, 0.32389534, 0.1960084...  \n",
       "4  [0.23211154, 0.060303785, -1.0003253, 0.637829...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textEmb_7props_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "addressed-march",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19155"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textEmb_7props_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "latter-spelling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662\n",
      "No. of keys in embedDict: 19155\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19155.000000\n",
      "mean         0.270895\n",
      "std          0.059990\n",
      "min          0.000000\n",
      "25%          0.228547\n",
      "50%          0.266816\n",
      "75%          0.309132\n",
      "max          0.564922\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 326\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.37836622063614156, pvalue=3.15520072942914e-22)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3793643502923977, pvalue=2.45298661169592e-22)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.39160232226212405, pvalue=7.580483725421636e-26)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.40586371991954756, pvalue=1.2142237724855381e-27)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.588957055214724\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.49079754601226994\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19155.000000\n",
      "mean         0.194648\n",
      "std          0.115900\n",
      "min          0.000000\n",
      "25%          0.083470\n",
      "50%          0.191821\n",
      "75%          0.294976\n",
      "max          0.564922\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 326\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.37836622063614156, pvalue=3.15520072942914e-22)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.36958425592956784, pvalue=2.7849781516020684e-21)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.39160232226212405, pvalue=7.580483725421636e-26)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.39348934596160956, pvalue=4.414924758703321e-26)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.588957055214724\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.5766871165644172\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19155.000000\n",
      "mean         0.323673\n",
      "std          0.069955\n",
      "min          0.000000\n",
      "25%          0.277272\n",
      "50%          0.319275\n",
      "75%          0.365774\n",
      "max          0.677490\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 326\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.37836622063614156, pvalue=3.15520072942914e-22)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3746327832763941, pvalue=8.004468522493588e-22)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.39160232226212405, pvalue=7.580483725421636e-26)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.39398189437020814, pvalue=3.8343633718362455e-26)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.588957055214724\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.3834355828220859\n"
     ]
    }
   ],
   "source": [
    "embedDict = fetchEmbeddings(textEmb_7props_DF)\n",
    "embedDictMaster['text_2props_19k'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['text_2props_19k_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _,confusionMatrixMaster['text_2props_19k_old_'+str(weightCase)], confusionMatrixMaster['text_2props_19k_new_'+str(weightCase)] = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-estonia",
   "metadata": {},
   "source": [
    "### Complex Embeddings | 19k + 19k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "flexible-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF = pd.read_csv('../data/wordsim353_complex_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sustainable-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF['complex_embedding'] = compEmbeddingsDF['complex_embedding'].apply(lambda p: [float(p1) for p1 in p.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "amino-there",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>complex_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q18037012</td>\n",
       "      <td>[-0.263069391, 0.028501017, -0.034664098, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q13112971</td>\n",
       "      <td>[0.148671135, 0.003585682, 0.319970608, 0.2488...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q59336660</td>\n",
       "      <td>[0.396341473, 0.148302898, 0.221964046, 0.5786...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q289472</td>\n",
       "      <td>[-0.069007814, -0.053335845, -0.03083352, 0.56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1931010</td>\n",
       "      <td>[0.366982907, -0.250219911, -0.287434697, 0.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>Q2963354</td>\n",
       "      <td>[-0.377670556, 0.123239793, 0.159144968, 0.648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>Q412770</td>\n",
       "      <td>[-0.082544975, 0.058447052, -0.614189446, 0.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>Q8063082</td>\n",
       "      <td>[0.132387042, -0.025238875, -0.262788028, 0.36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>Q58308662</td>\n",
       "      <td>[0.459155083, -0.277395934, -0.454340786, 0.44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100</th>\n",
       "      <td>Q7205879</td>\n",
       "      <td>[0.133135661, -0.003577206, -0.233342946, 0.46...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19101 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            node                                  complex_embedding\n",
       "0      Q18037012  [-0.263069391, 0.028501017, -0.034664098, 0.13...\n",
       "1      Q13112971  [0.148671135, 0.003585682, 0.319970608, 0.2488...\n",
       "2      Q59336660  [0.396341473, 0.148302898, 0.221964046, 0.5786...\n",
       "3        Q289472  [-0.069007814, -0.053335845, -0.03083352, 0.56...\n",
       "4       Q1931010  [0.366982907, -0.250219911, -0.287434697, 0.45...\n",
       "...          ...                                                ...\n",
       "19096   Q2963354  [-0.377670556, 0.123239793, 0.159144968, 0.648...\n",
       "19097    Q412770  [-0.082544975, 0.058447052, -0.614189446, 0.81...\n",
       "19098   Q8063082  [0.132387042, -0.025238875, -0.262788028, 0.36...\n",
       "19099  Q58308662  [0.459155083, -0.277395934, -0.454340786, 0.44...\n",
       "19100   Q7205879  [0.133135661, -0.003577206, -0.233342946, 0.46...\n",
       "\n",
       "[19101 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compEmbeddingsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "yellow-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddings = {}\n",
    "for _, row in compEmbeddingsDF.iterrows():\n",
    "    compEmbeddings[row['node']] = np.array(row['complex_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "necessary-house",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662\n",
      "No. of keys in embedDict: 19101\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19101.000000\n",
      "mean         0.316720\n",
      "std          0.076381\n",
      "min          0.000000\n",
      "25%          0.261478\n",
      "50%          0.313781\n",
      "75%          0.370851\n",
      "max          0.600672\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.34963457034499734, pvalue=3.525500513811503e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3168500395328192, pvalue=7.486323665386832e-17)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.3027318092124757, pvalue=7.573910025067949e-17)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.27202499209162273, pvalue=6.770258859650813e-14)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6647230320699709\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6559766763848397\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19101.000000\n",
      "mean         0.232133\n",
      "std          0.142269\n",
      "min          0.000000\n",
      "25%          0.089938\n",
      "50%          0.228553\n",
      "75%          0.361251\n",
      "max          0.600672\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.34963457034499734, pvalue=3.525500513811503e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3361212489826738, pvalue=9.03613034020374e-19)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.3027318092124757, pvalue=7.573910025067949e-17)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.29248433284517855, pvalue=7.890529591252537e-16)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6647230320699709\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6618075801749271\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19101.000000\n",
      "mean         0.375082\n",
      "std          0.073982\n",
      "min          0.000000\n",
      "25%          0.330119\n",
      "50%          0.377307\n",
      "75%          0.421860\n",
      "max          0.841769\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.34963457034499734, pvalue=3.525500513811503e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.26508277549218445, pvalue=3.0194195465523546e-12)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.3027318092124757, pvalue=7.573910025067949e-17)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.21338136285025483, pvalue=4.17252744630606e-09)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6647230320699709\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.5830903790087464\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(compEmbeddings)\n",
    "embedDictMaster['complex_19k'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['complex_19k_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _,confusionMatrixMaster['complex_19k_old_'+str(weightCase)], confusionMatrixMaster['complex_19k_new_'+str(weightCase)] = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-tutorial",
   "metadata": {},
   "source": [
    "### Transe Embeddings | 19k + 19k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dominant-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF = pd.read_csv('../data/wordsim353_transe_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "complicated-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF['transe_embedding'] = compEmbeddingsDF['transe_embedding'].apply(lambda p: [float(p1) for p1 in p.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "interstate-worst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>transe_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q18037012</td>\n",
       "      <td>[0.000987129, -0.157959029, 0.601584613, -0.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q13112971</td>\n",
       "      <td>[0.323111564, -0.157194719, 0.350547582, -0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q59336660</td>\n",
       "      <td>[0.067076892, -0.706452787, -0.070606612, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q289472</td>\n",
       "      <td>[-0.444723994, -0.020702582, 0.109241754, -0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1931010</td>\n",
       "      <td>[-0.055137988, -0.652317405, 0.043370813, -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        node                                   transe_embedding\n",
       "0  Q18037012  [0.000987129, -0.157959029, 0.601584613, -0.41...\n",
       "1  Q13112971  [0.323111564, -0.157194719, 0.350547582, -0.13...\n",
       "2  Q59336660  [0.067076892, -0.706452787, -0.070606612, 0.06...\n",
       "3    Q289472  [-0.444723994, -0.020702582, 0.109241754, -0.4...\n",
       "4   Q1931010  [-0.055137988, -0.652317405, 0.043370813, -0.3..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compEmbeddingsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "color-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in compEmbeddingsDF.iterrows():\n",
    "    compEmbeddings[row['node']] = np.array(row['transe_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sealed-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662\n",
      "No. of keys in embedDict: 19101\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19101.000000\n",
      "mean         0.332525\n",
      "std          0.085513\n",
      "min          0.000000\n",
      "25%          0.269043\n",
      "50%          0.327802\n",
      "75%          0.393660\n",
      "max          0.679789\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.2509658430035214, pvalue=3.9754031639979325e-11)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.23996930346932127, pvalue=2.6942170209534906e-10)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.22562477749827262, pvalue=5.15975984253164e-10)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.21449104599327523, pvalue=3.4760310637715348e-09)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6005830903790087\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6559766763848397\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19101.000000\n",
      "mean         0.242979\n",
      "std          0.150562\n",
      "min          0.000000\n",
      "25%          0.094960\n",
      "50%          0.237343\n",
      "75%          0.378069\n",
      "max          0.679789\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.2509658430035214, pvalue=3.9754031639979325e-11)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.24439786532398405, pvalue=1.2600161404554345e-10)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.22562477749827262, pvalue=5.15975984253164e-10)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.22590625729631375, pvalue=4.917533132159808e-10)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6005830903790087\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.60932944606414\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19101.000000\n",
      "mean         0.394277\n",
      "std          0.086197\n",
      "min          0.000000\n",
      "25%          0.339162\n",
      "50%          0.397921\n",
      "75%          0.452267\n",
      "max          0.850905\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.2509658430035214, pvalue=3.9754031639979325e-11)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.24274131207452157, pvalue=1.6736422306859635e-10)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.22562477749827262, pvalue=5.15975984253164e-10)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.201734473314897, pvalue=2.7559659468673134e-08)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6005830903790087\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6064139941690962\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(compEmbeddings)\n",
    "embedDictMaster['transe_19k'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['transe_19k_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _,confusionMatrixMaster['transe_19k_old_'+str(weightCase)], confusionMatrixMaster['transe_19k_new_'+str(weightCase)] = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-priority",
   "metadata": {},
   "source": [
    "### Complex Embeddings | Probase Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "coastal-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF = pd.read_csv('../data/wordsim353_complex_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "familiar-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF['complex_embedding'] = compEmbeddingsDF['complex_embedding'].apply(lambda p: [float(p1) for p1 in p.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "duplicate-storm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>complex_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q18037012</td>\n",
       "      <td>[-0.263069391, 0.028501017, -0.034664098, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q13112971</td>\n",
       "      <td>[0.148671135, 0.003585682, 0.319970608, 0.2488...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q59336660</td>\n",
       "      <td>[0.396341473, 0.148302898, 0.221964046, 0.5786...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q289472</td>\n",
       "      <td>[-0.069007814, -0.053335845, -0.03083352, 0.56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1931010</td>\n",
       "      <td>[0.366982907, -0.250219911, -0.287434697, 0.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>Q2963354</td>\n",
       "      <td>[-0.377670556, 0.123239793, 0.159144968, 0.648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>Q412770</td>\n",
       "      <td>[-0.082544975, 0.058447052, -0.614189446, 0.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>Q8063082</td>\n",
       "      <td>[0.132387042, -0.025238875, -0.262788028, 0.36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>Q58308662</td>\n",
       "      <td>[0.459155083, -0.277395934, -0.454340786, 0.44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100</th>\n",
       "      <td>Q7205879</td>\n",
       "      <td>[0.133135661, -0.003577206, -0.233342946, 0.46...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19101 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            node                                  complex_embedding\n",
       "0      Q18037012  [-0.263069391, 0.028501017, -0.034664098, 0.13...\n",
       "1      Q13112971  [0.148671135, 0.003585682, 0.319970608, 0.2488...\n",
       "2      Q59336660  [0.396341473, 0.148302898, 0.221964046, 0.5786...\n",
       "3        Q289472  [-0.069007814, -0.053335845, -0.03083352, 0.56...\n",
       "4       Q1931010  [0.366982907, -0.250219911, -0.287434697, 0.45...\n",
       "...          ...                                                ...\n",
       "19096   Q2963354  [-0.377670556, 0.123239793, 0.159144968, 0.648...\n",
       "19097    Q412770  [-0.082544975, 0.058447052, -0.614189446, 0.81...\n",
       "19098   Q8063082  [0.132387042, -0.025238875, -0.262788028, 0.36...\n",
       "19099  Q58308662  [0.459155083, -0.277395934, -0.454340786, 0.44...\n",
       "19100   Q7205879  [0.133135661, -0.003577206, -0.233342946, 0.46...\n",
       "\n",
       "[19101 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compEmbeddingsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "unsigned-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in compEmbeddingsDF.iterrows():\n",
    "    compEmbeddings[row['node']] = np.array(row['complex_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "mental-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17845\n",
      "No. of keys in embedDict: 19101\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    1.910100e+04\n",
      "mean     7.887688e-02\n",
      "std      1.377091e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      1.490116e-08\n",
      "75%      2.314421e-01\n",
      "max      5.041080e-01\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.34963457034499734, pvalue=3.525500513811503e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.31031745482774675, pvalue=3.150145092040765e-16)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.3027318092124757, pvalue=7.573910025067949e-17)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.26161279947706156, pvalue=5.774092784287413e-13)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6647230320699709\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6268221574344023\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    1.910100e+04\n",
      "mean     3.252887e-02\n",
      "std      8.773144e-02\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      1.490116e-08\n",
      "75%      1.094678e-03\n",
      "max      5.041080e-01\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.34963457034499734, pvalue=3.525500513811503e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.35020973149202944, pvalue=3.059720074110226e-20)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.3027318092124757, pvalue=7.573910025067949e-17)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.3013432304449195, pvalue=1.0451590470362559e-16)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6647230320699709\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6588921282798834\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    1.910100e+04\n",
      "mean     1.251606e-01\n",
      "std      2.222320e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      1.490116e-08\n",
      "75%      2.940167e-01\n",
      "max      8.900593e-01\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.34963457034499734, pvalue=3.525500513811503e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.14149430916593933, pvalue=0.00019608082976567604)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.3027318092124757, pvalue=7.573910025067949e-17)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.14687524939411561, pvalue=5.22383486460822e-05)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6647230320699709\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.1457725947521866\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(compEmbeddings)\n",
    "embedDictMaster['complex_probase'] = embedDict\n",
    "neighDict = fetchNeighbours(probDF_Qnodes_DF_WQnodes1_subset)\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['complex_probase_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _ = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-light",
   "metadata": {},
   "source": [
    "### Transe Embeddings | Probase Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "normal-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF = pd.read_csv('../data/wordsim353_transe_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "reserved-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF['transe_embedding'] = compEmbeddingsDF['transe_embedding'].apply(lambda p: [float(p1) for p1 in p.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "norman-graph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>transe_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q18037012</td>\n",
       "      <td>[0.000987129, -0.157959029, 0.601584613, -0.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q13112971</td>\n",
       "      <td>[0.323111564, -0.157194719, 0.350547582, -0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q59336660</td>\n",
       "      <td>[0.067076892, -0.706452787, -0.070606612, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q289472</td>\n",
       "      <td>[-0.444723994, -0.020702582, 0.109241754, -0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1931010</td>\n",
       "      <td>[-0.055137988, -0.652317405, 0.043370813, -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        node                                   transe_embedding\n",
       "0  Q18037012  [0.000987129, -0.157959029, 0.601584613, -0.41...\n",
       "1  Q13112971  [0.323111564, -0.157194719, 0.350547582, -0.13...\n",
       "2  Q59336660  [0.067076892, -0.706452787, -0.070606612, 0.06...\n",
       "3    Q289472  [-0.444723994, -0.020702582, 0.109241754, -0.4...\n",
       "4   Q1931010  [-0.055137988, -0.652317405, 0.043370813, -0.3..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compEmbeddingsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "identical-amsterdam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>transe_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q18037012</td>\n",
       "      <td>[0.000987129, -0.157959029, 0.601584613, -0.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q13112971</td>\n",
       "      <td>[0.323111564, -0.157194719, 0.350547582, -0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q59336660</td>\n",
       "      <td>[0.067076892, -0.706452787, -0.070606612, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q289472</td>\n",
       "      <td>[-0.444723994, -0.020702582, 0.109241754, -0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1931010</td>\n",
       "      <td>[-0.055137988, -0.652317405, 0.043370813, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>Q2963354</td>\n",
       "      <td>[0.126148477, -0.760043263, 0.834101379, 0.413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>Q412770</td>\n",
       "      <td>[-0.131047472, -0.532605469, -0.180144981, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>Q8063082</td>\n",
       "      <td>[0.173550904, -0.246142939, 0.750203907, 0.030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>Q58308662</td>\n",
       "      <td>[0.572182953, 0.186988175, -0.116030365, -0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100</th>\n",
       "      <td>Q7205879</td>\n",
       "      <td>[0.752269626, -0.460156113, 0.517503202, 0.019...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19101 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            node                                   transe_embedding\n",
       "0      Q18037012  [0.000987129, -0.157959029, 0.601584613, -0.41...\n",
       "1      Q13112971  [0.323111564, -0.157194719, 0.350547582, -0.13...\n",
       "2      Q59336660  [0.067076892, -0.706452787, -0.070606612, 0.06...\n",
       "3        Q289472  [-0.444723994, -0.020702582, 0.109241754, -0.4...\n",
       "4       Q1931010  [-0.055137988, -0.652317405, 0.043370813, -0.3...\n",
       "...          ...                                                ...\n",
       "19096   Q2963354  [0.126148477, -0.760043263, 0.834101379, 0.413...\n",
       "19097    Q412770  [-0.131047472, -0.532605469, -0.180144981, -0....\n",
       "19098   Q8063082  [0.173550904, -0.246142939, 0.750203907, 0.030...\n",
       "19099  Q58308662  [0.572182953, 0.186988175, -0.116030365, -0.35...\n",
       "19100   Q7205879  [0.752269626, -0.460156113, 0.517503202, 0.019...\n",
       "\n",
       "[19101 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compEmbeddingsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "knowing-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in compEmbeddingsDF.iterrows():\n",
    "    compEmbeddings[row['node']] = np.array(row['transe_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "inside-opportunity",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17845\n",
      "No. of keys in embedDict: 19101\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    1.910100e+04\n",
      "mean     8.215694e-02\n",
      "std      1.439020e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      1.490116e-08\n",
      "75%      2.305726e-01\n",
      "max      5.315488e-01\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.2509658430035214, pvalue=3.9754031639979325e-11)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.22012582471779607, pvalue=6.9001945281841384e-09)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.22562477749827262, pvalue=5.15975984253164e-10)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.19941082640413085, pvalue=3.969975785916229e-08)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6005830903790087\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6472303206997084\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    1.910100e+04\n",
      "mean     3.399453e-02\n",
      "std      9.216743e-02\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      1.490116e-08\n",
      "75%      1.230265e-03\n",
      "max      5.315488e-01\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.2509658430035214, pvalue=3.9754031639979325e-11)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.24783606125619878, pvalue=6.903890636652704e-11)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.22562477749827262, pvalue=5.15975984253164e-10)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.22349921038500295, pvalue=7.473348989752392e-10)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6005830903790087\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6005830903790087\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    1.910100e+04\n",
      "mean     1.302927e-01\n",
      "std      2.320257e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      1.490116e-08\n",
      "75%      2.960976e-01\n",
      "max      9.949517e-01\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.2509658430035214, pvalue=3.9754031639979325e-11)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.12855892543728606, pvalue=0.0007155142288469726)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.22562477749827262, pvalue=5.15975984253164e-10)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.13749877727529278, pvalue=0.00015240104075019828)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6005830903790087\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.17784256559766765\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(compEmbeddings)\n",
    "embedDictMaster['transe_probase'] = embedDict\n",
    "neighDict = fetchNeighbours(probDF_Qnodes_DF_WQnodes1_subset)\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['transe_probase_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _ = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-parent",
   "metadata": {},
   "source": [
    "### Complex Embeddings | Probase + 19k + 19k Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "sustained-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF = pd.read_csv('../data/wordsim353_complex_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "qualified-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF['complex_embedding'] = compEmbeddingsDF['complex_embedding'].apply(lambda p: [float(p1) for p1 in p.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "occupational-survival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>complex_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q18037012</td>\n",
       "      <td>[-0.263069391, 0.028501017, -0.034664098, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q13112971</td>\n",
       "      <td>[0.148671135, 0.003585682, 0.319970608, 0.2488...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q59336660</td>\n",
       "      <td>[0.396341473, 0.148302898, 0.221964046, 0.5786...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q289472</td>\n",
       "      <td>[-0.069007814, -0.053335845, -0.03083352, 0.56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1931010</td>\n",
       "      <td>[0.366982907, -0.250219911, -0.287434697, 0.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>Q2963354</td>\n",
       "      <td>[-0.377670556, 0.123239793, 0.159144968, 0.648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>Q412770</td>\n",
       "      <td>[-0.082544975, 0.058447052, -0.614189446, 0.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>Q8063082</td>\n",
       "      <td>[0.132387042, -0.025238875, -0.262788028, 0.36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>Q58308662</td>\n",
       "      <td>[0.459155083, -0.277395934, -0.454340786, 0.44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100</th>\n",
       "      <td>Q7205879</td>\n",
       "      <td>[0.133135661, -0.003577206, -0.233342946, 0.46...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19101 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            node                                  complex_embedding\n",
       "0      Q18037012  [-0.263069391, 0.028501017, -0.034664098, 0.13...\n",
       "1      Q13112971  [0.148671135, 0.003585682, 0.319970608, 0.2488...\n",
       "2      Q59336660  [0.396341473, 0.148302898, 0.221964046, 0.5786...\n",
       "3        Q289472  [-0.069007814, -0.053335845, -0.03083352, 0.56...\n",
       "4       Q1931010  [0.366982907, -0.250219911, -0.287434697, 0.45...\n",
       "...          ...                                                ...\n",
       "19096   Q2963354  [-0.377670556, 0.123239793, 0.159144968, 0.648...\n",
       "19097    Q412770  [-0.082544975, 0.058447052, -0.614189446, 0.81...\n",
       "19098   Q8063082  [0.132387042, -0.025238875, -0.262788028, 0.36...\n",
       "19099  Q58308662  [0.459155083, -0.277395934, -0.454340786, 0.44...\n",
       "19100   Q7205879  [0.133135661, -0.003577206, -0.233342946, 0.46...\n",
       "\n",
       "[19101 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compEmbeddingsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "intermediate-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in compEmbeddingsDF.iterrows():\n",
    "    compEmbeddings[row['node']] = np.array(row['complex_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "piano-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17849\n",
      "No. of keys in embedDict: 19101\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19101.000000\n",
      "mean         0.302721\n",
      "std          0.067184\n",
      "min          0.000000\n",
      "25%          0.259615\n",
      "50%          0.294771\n",
      "75%          0.342928\n",
      "max          0.600672\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.34963457034499734, pvalue=3.525500513811503e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.31582754528140355, pvalue=9.373921755437325e-17)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.3027318092124757, pvalue=7.573910025067949e-17)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.27369250100948833, pvalue=4.756656623381545e-14)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6647230320699709\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6326530612244898\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19101.000000\n",
      "mean         0.178804\n",
      "std          0.139703\n",
      "min          0.000000\n",
      "25%          0.054379\n",
      "50%          0.137749\n",
      "75%          0.307442\n",
      "max          0.600672\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.34963457034499734, pvalue=3.525500513811503e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3464370368444909, pvalue=7.656876025494246e-20)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.3027318092124757, pvalue=7.573910025067949e-17)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.3011763909407297, pvalue=1.0831987277611373e-16)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6647230320699709\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6647230320699709\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19101.000000\n",
      "mean         0.402505\n",
      "std          0.098028\n",
      "min          0.000000\n",
      "25%          0.339741\n",
      "50%          0.393894\n",
      "75%          0.452606\n",
      "max          0.889403\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.34963457034499734, pvalue=3.525500513811503e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.12191472957942284, pvalue=0.0013338871853105486)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.3027318092124757, pvalue=7.573910025067949e-17)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.14137053781971248, pvalue=9.875366583327447e-05)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6647230320699709\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.16034985422740525\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(compEmbeddings)\n",
    "embedDictMaster['complex_probase_19k'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text, probDF_Qnodes_DF_WQnodes1_subset]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['complex_probase_19k_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _ = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-outreach",
   "metadata": {},
   "source": [
    "### Transe Embeddings | Probase + 19k + 19k Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "powered-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF = pd.read_csv('../data/wordsim353_transe_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eligible-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "compEmbeddingsDF['transe_embedding'] = compEmbeddingsDF['transe_embedding'].apply(lambda p: [float(p1) for p1 in p.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "passing-france",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>transe_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q18037012</td>\n",
       "      <td>[0.000987129, -0.157959029, 0.601584613, -0.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q13112971</td>\n",
       "      <td>[0.323111564, -0.157194719, 0.350547582, -0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q59336660</td>\n",
       "      <td>[0.067076892, -0.706452787, -0.070606612, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q289472</td>\n",
       "      <td>[-0.444723994, -0.020702582, 0.109241754, -0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1931010</td>\n",
       "      <td>[-0.055137988, -0.652317405, 0.043370813, -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        node                                   transe_embedding\n",
       "0  Q18037012  [0.000987129, -0.157959029, 0.601584613, -0.41...\n",
       "1  Q13112971  [0.323111564, -0.157194719, 0.350547582, -0.13...\n",
       "2  Q59336660  [0.067076892, -0.706452787, -0.070606612, 0.06...\n",
       "3    Q289472  [-0.444723994, -0.020702582, 0.109241754, -0.4...\n",
       "4   Q1931010  [-0.055137988, -0.652317405, 0.043370813, -0.3..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compEmbeddingsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "catholic-flexibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>transe_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q18037012</td>\n",
       "      <td>[0.000987129, -0.157959029, 0.601584613, -0.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q13112971</td>\n",
       "      <td>[0.323111564, -0.157194719, 0.350547582, -0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q59336660</td>\n",
       "      <td>[0.067076892, -0.706452787, -0.070606612, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q289472</td>\n",
       "      <td>[-0.444723994, -0.020702582, 0.109241754, -0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1931010</td>\n",
       "      <td>[-0.055137988, -0.652317405, 0.043370813, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>Q2963354</td>\n",
       "      <td>[0.126148477, -0.760043263, 0.834101379, 0.413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>Q412770</td>\n",
       "      <td>[-0.131047472, -0.532605469, -0.180144981, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>Q8063082</td>\n",
       "      <td>[0.173550904, -0.246142939, 0.750203907, 0.030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>Q58308662</td>\n",
       "      <td>[0.572182953, 0.186988175, -0.116030365, -0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100</th>\n",
       "      <td>Q7205879</td>\n",
       "      <td>[0.752269626, -0.460156113, 0.517503202, 0.019...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19101 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            node                                   transe_embedding\n",
       "0      Q18037012  [0.000987129, -0.157959029, 0.601584613, -0.41...\n",
       "1      Q13112971  [0.323111564, -0.157194719, 0.350547582, -0.13...\n",
       "2      Q59336660  [0.067076892, -0.706452787, -0.070606612, 0.06...\n",
       "3        Q289472  [-0.444723994, -0.020702582, 0.109241754, -0.4...\n",
       "4       Q1931010  [-0.055137988, -0.652317405, 0.043370813, -0.3...\n",
       "...          ...                                                ...\n",
       "19096   Q2963354  [0.126148477, -0.760043263, 0.834101379, 0.413...\n",
       "19097    Q412770  [-0.131047472, -0.532605469, -0.180144981, -0....\n",
       "19098   Q8063082  [0.173550904, -0.246142939, 0.750203907, 0.030...\n",
       "19099  Q58308662  [0.572182953, 0.186988175, -0.116030365, -0.35...\n",
       "19100   Q7205879  [0.752269626, -0.460156113, 0.517503202, 0.019...\n",
       "\n",
       "[19101 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compEmbeddingsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "every-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in compEmbeddingsDF.iterrows():\n",
    "    compEmbeddings[row['node']] = np.array(row['transe_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "floral-union",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17849\n",
      "No. of keys in embedDict: 19101\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19101.000000\n",
      "mean         0.316457\n",
      "std          0.074755\n",
      "min          0.000000\n",
      "25%          0.265029\n",
      "50%          0.307908\n",
      "75%          0.361417\n",
      "max          0.679789\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.2509658430035214, pvalue=3.9754031639979325e-11)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.22203711859153544, pvalue=5.1043215609543335e-09)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.22562477749827262, pvalue=5.15975984253164e-10)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.20512238050033801, pvalue=1.6083667850582075e-08)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6005830903790087\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6443148688046647\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19101.000000\n",
      "mean         0.186190\n",
      "std          0.146220\n",
      "min          0.000000\n",
      "25%          0.056864\n",
      "50%          0.144985\n",
      "75%          0.307240\n",
      "max          0.679789\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.2509658430035214, pvalue=3.9754031639979325e-11)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.2479273527617227, pvalue=6.816190052635217e-11)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.22562477749827262, pvalue=5.15975984253164e-10)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.2263056114290315, pvalue=4.5887579264134097e-10)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6005830903790087\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.597667638483965\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19101.000000\n",
      "mean         0.421187\n",
      "std          0.108116\n",
      "min          0.000000\n",
      "25%          0.350740\n",
      "50%          0.416101\n",
      "75%          0.480072\n",
      "max          0.972091\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.2509658430035214, pvalue=3.9754031639979325e-11)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.12731453008255086, pvalue=0.0008059106457544173)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.22562477749827262, pvalue=5.15975984253164e-10)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.1476648434866464, pvalue=4.7610094969077205e-05)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6005830903790087\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.2594752186588921\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(compEmbeddings)\n",
    "embedDictMaster['transe_probase_19k'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text, probDF_Qnodes_DF_WQnodes1_subset]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['transe_probase_19k_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _ = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-earth",
   "metadata": {},
   "source": [
    "### Abstract Text Embeddings | 19k+19k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "royal-update",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "absEmbeddings = {}\n",
    "for _, row in pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text]).iterrows():\n",
    "    if not(pd.isna(row['BERT_abstract_emb'])):\n",
    "        absEmbeddings[row['node1']] = np.array([float(val1) for val1 in row['BERT_abstract_emb'][1:-1].split(',')])\n",
    "    elif not(pd.isna(row['node1_emb'])):\n",
    "        absEmbeddings[row['node1']] = np.array([float(val1) for val1 in list(filter(lambda p: p, re.split(\"[\\n\\s]\", row['node1_emb'][1:-1])))])\n",
    "        \n",
    "    if not(pd.isna(row['BERT_abstract_emb_right'])):\n",
    "        absEmbeddings[row['node2']] = np.array([float(val1) for val1 in row['BERT_abstract_emb_right'][1:-1].split(',')])\n",
    "    elif not(pd.isna(row['node2_emb'])):\n",
    "        absEmbeddings[row['node2']] = np.array([float(val1) for val1 in list(filter(lambda p: p, re.split(\"[\\n\\s]\", row['node2_emb'][1:-1])))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "straight-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "pursuant-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordSimOG_DF = pd.read_csv('../data/wordsim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "australian-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordSim353AnnotDF_New = wordSim353AnnotDF_New.set_index(['Word 1', 'Word 2']).join(wordSimOG_DF.set_index(['Word 1', 'Word 2'])[['word1_kg_id', 'word2_kg_id']]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "advanced-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from time import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "funded-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentEmbeddings(valSeries, modelName):\n",
    "    model = SentenceTransformer(modelName)\n",
    "    start = time()\n",
    "    encodings = model.encode(valSeries)\n",
    "    print(time()-start,'s')\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "identical-aspect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>ID</th>\n",
       "      <th>H_Sim</th>\n",
       "      <th>H_Dim</th>\n",
       "      <th>F_Sim</th>\n",
       "      <th>F_Dim</th>\n",
       "      <th>N_Sim</th>\n",
       "      <th>N_Dim</th>\n",
       "      <th>D_Sim</th>\n",
       "      <th>D_Dim</th>\n",
       "      <th>P_Sim</th>\n",
       "      <th>P_Dim</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Stdev</th>\n",
       "      <th>H_orig</th>\n",
       "      <th>H_reversed</th>\n",
       "      <th>word1_kg_id</th>\n",
       "      <th>word2_kg_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>2.1250</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>Q34211</td>\n",
       "      <td>Q454</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>3.0625</td>\n",
       "      <td>6.9375</td>\n",
       "      <td>Q34211</td>\n",
       "      <td>Q13648784</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>4.0625</td>\n",
       "      <td>5.9375</td>\n",
       "      <td>Q8333</td>\n",
       "      <td>Q178022</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>3.0</td>\n",
       "      <td>u</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>4.9375</td>\n",
       "      <td>Q8333</td>\n",
       "      <td>Q21004260</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>s</td>\n",
       "      <td>2.0</td>\n",
       "      <td>s</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>4.8750</td>\n",
       "      <td>5.1250</td>\n",
       "      <td>Q13371</td>\n",
       "      <td>Q49112</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word 1         Word 2   ID  H_Sim H_Dim  F_Sim F_Dim  N_Sim N_Dim  D_Sim  \\\n",
       "0   Arafat          peace    8      3     D      4   NaN      3     U      4   \n",
       "1   Arafat         terror    9      3     D      4   NaN      3     U      4   \n",
       "2      FBI    fingerprint  109      3     D      4   NaN      4   NaN      3   \n",
       "3      FBI  investigation  110      3     U      3     U      3     U      3   \n",
       "4  Harvard           Yale  137      2     S      3     S      2     S      2   \n",
       "\n",
       "  D_Dim  P_Sim P_Dim  Avg     Stdev  H_orig  H_reversed word1_kg_id  \\\n",
       "0   NaN    4.0   NaN  3.6  0.547723  2.1250      7.8750      Q34211   \n",
       "1   NaN    4.0   NaN  3.6  0.547723  3.0625      6.9375      Q34211   \n",
       "2     u    4.0   NaN  3.6  0.547723  4.0625      5.9375       Q8333   \n",
       "3     u    3.0     u  3.0  0.000000  5.0625      4.9375       Q8333   \n",
       "4     s    2.0     s  2.2  0.447214  4.8750      5.1250      Q13371   \n",
       "\n",
       "  word2_kg_id category  \n",
       "0        Q454        U  \n",
       "1   Q13648784        U  \n",
       "2     Q178022        U  \n",
       "3   Q21004260        M  \n",
       "4      Q49112        M  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "specific-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingWordSimSet = set(wordSim353AnnotDF_New[wordSim353AnnotDF_New.word1_kg_id.apply(lambda p: p not in absEmbeddings)] + wordSim353AnnotDF_New[wordSim353AnnotDF_New.word2_kg_id.apply(lambda p: p not in absEmbeddings)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "affected-consolidation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3354244232177734 s\n",
      "0.11755561828613281 s\n",
      "0.11744570732116699 s\n",
      "0.1175832748413086 s\n",
      "0.11750054359436035 s\n",
      "0.11730837821960449 s\n",
      "0.11754989624023438 s\n",
      "0.11766695976257324 s\n",
      "0.11713695526123047 s\n",
      "0.11739706993103027 s\n",
      "0.12069988250732422 s\n",
      "0.11744093894958496 s\n",
      "0.11738061904907227 s\n",
      "0.11722540855407715 s\n",
      "0.11743450164794922 s\n",
      "0.11770343780517578 s\n",
      "0.11734700202941895 s\n",
      "0.11752867698669434 s\n",
      "0.11753010749816895 s\n",
      "0.11727476119995117 s\n",
      "0.11757302284240723 s\n",
      "0.11744475364685059 s\n",
      "0.1178896427154541 s\n",
      "0.11759018898010254 s\n",
      "0.11737680435180664 s\n",
      "0.11777734756469727 s\n",
      "0.11771225929260254 s\n",
      "0.11792659759521484 s\n",
      "0.1174314022064209 s\n",
      "0.1175081729888916 s\n",
      "0.11757636070251465 s\n",
      "0.11760926246643066 s\n",
      "0.11748123168945312 s\n",
      "0.11753368377685547 s\n",
      "0.11712884902954102 s\n",
      "0.11767840385437012 s\n",
      "0.11764121055603027 s\n",
      "0.11763525009155273 s\n",
      "0.11754012107849121 s\n",
      "0.11885714530944824 s\n"
     ]
    }
   ],
   "source": [
    "for _, row in wordSim353AnnotDF_New.iterrows():\n",
    "    if row.word1_kg_id not in absEmbeddings:\n",
    "        absEmbeddings[row.word1_kg_id] = getSentEmbeddings(row['Word 1'], 'bert-base-nli-mean-tokens')\n",
    "    if row.word2_kg_id not in absEmbeddings:\n",
    "        absEmbeddings[row.word2_kg_id] = getSentEmbeddings(row['Word 2'], 'bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fuzzy-attack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missingWordSimSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "hawaiian-portal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662\n",
      "No. of keys in embedDict: 19166\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19166.000000\n",
      "mean         0.336606\n",
      "std          0.081060\n",
      "min          0.000000\n",
      "25%          0.278247\n",
      "50%          0.326289\n",
      "75%          0.388139\n",
      "max          0.669782\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 344\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.3498489915976348, pvalue=2.913399131760102e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3471431474655109, pvalue=5.660815639939061e-20)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.34236242720323, pvalue=3.60507767671425e-21)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.35383380764979844, pvalue=1.6754686847593527e-22)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.627906976744186\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.5697674418604651\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19166.000000\n",
      "mean         0.244583\n",
      "std          0.150115\n",
      "min          0.000000\n",
      "25%          0.103316\n",
      "50%          0.233314\n",
      "75%          0.372639\n",
      "max          0.669782\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 344\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.3498489915976348, pvalue=2.913399131760102e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.34735894519691607, pvalue=5.347633678079643e-20)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.34236242720323, pvalue=3.60507767671425e-21)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.3462632061224712, pvalue=1.2793035570514484e-21)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.627906976744186\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.627906976744186\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19166.000000\n",
      "mean         0.400089\n",
      "std          0.083229\n",
      "min          0.000000\n",
      "25%          0.344853\n",
      "50%          0.397861\n",
      "75%          0.451782\n",
      "max          0.835283\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 344\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.3498489915976348, pvalue=2.913399131760102e-20)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.32390174521065745, pvalue=1.3650315049340146e-17)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.34236242720323, pvalue=3.60507767671425e-21)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.3325159043509967, pvalue=4.65056862032923e-20)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.627906976744186\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.47093023255813954\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(absEmbeddings)\n",
    "embedDictMaster['abstract_19k'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['abstract_19k_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _,confusionMatrixMaster['abstract_19k_old_'+str(weightCase)], confusionMatrixMaster['abstract_19k_new_'+str(weightCase)] = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-valley",
   "metadata": {},
   "source": [
    "### Abstract 1st Sentence Text Embeddings | 19k+19k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "occupied-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "absEmbeddings = {}\n",
    "for _, row in pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text]).iterrows():\n",
    "    if not(pd.isna(row['BERT_abstract_firstSent_emb'])):\n",
    "        absEmbeddings[row['node1']] = np.array([float(val1) for val1 in row['BERT_abstract_firstSent_emb'][1:-1].split(',')])\n",
    "    elif not(pd.isna(row['node1_emb'])):\n",
    "        absEmbeddings[row['node1']] = np.array([float(val1) for val1 in list(filter(lambda p: p, re.split(\"[\\n\\s]\", row['node1_emb'][1:-1])))])\n",
    "        \n",
    "    if not(pd.isna(row['BERT_abstract_firstSent_emb_right'])):\n",
    "        absEmbeddings[row['node2']] = np.array([float(val1) for val1 in row['BERT_abstract_firstSent_emb_right'][1:-1].split(',')])\n",
    "    elif not(pd.isna(row['node2_emb'])):\n",
    "        absEmbeddings[row['node2']] = np.array([float(val1) for val1 in list(filter(lambda p: p, re.split(\"[\\n\\s]\", row['node2_emb'][1:-1])))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "sexual-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cognitive-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordSimOG_DF = pd.read_csv('../data/wordsim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "irish-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordSim353AnnotDF_New = wordSim353AnnotDF_New.set_index(['Word 1', 'Word 2']).join(wordSimOG_DF.set_index(['Word 1', 'Word 2'])[['word1_kg_id', 'word2_kg_id']]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "neural-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from time import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "apart-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentEmbeddings(valSeries, modelName):\n",
    "    model = SentenceTransformer(modelName)\n",
    "    start = time()\n",
    "    encodings = model.encode(valSeries)\n",
    "    print(time()-start,'s')\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "monthly-enough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>ID</th>\n",
       "      <th>H_Sim</th>\n",
       "      <th>H_Dim</th>\n",
       "      <th>F_Sim</th>\n",
       "      <th>F_Dim</th>\n",
       "      <th>N_Sim</th>\n",
       "      <th>N_Dim</th>\n",
       "      <th>D_Sim</th>\n",
       "      <th>D_Dim</th>\n",
       "      <th>P_Sim</th>\n",
       "      <th>P_Dim</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Stdev</th>\n",
       "      <th>H_orig</th>\n",
       "      <th>H_reversed</th>\n",
       "      <th>word1_kg_id</th>\n",
       "      <th>word2_kg_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>2.1250</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>Q34211</td>\n",
       "      <td>Q454</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>3.0625</td>\n",
       "      <td>6.9375</td>\n",
       "      <td>Q34211</td>\n",
       "      <td>Q13648784</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>4.0625</td>\n",
       "      <td>5.9375</td>\n",
       "      <td>Q8333</td>\n",
       "      <td>Q178022</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>3.0</td>\n",
       "      <td>u</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>4.9375</td>\n",
       "      <td>Q8333</td>\n",
       "      <td>Q21004260</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>s</td>\n",
       "      <td>2.0</td>\n",
       "      <td>s</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>4.8750</td>\n",
       "      <td>5.1250</td>\n",
       "      <td>Q13371</td>\n",
       "      <td>Q49112</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word 1         Word 2   ID  H_Sim H_Dim  F_Sim F_Dim  N_Sim N_Dim  D_Sim  \\\n",
       "0   Arafat          peace    8      3     D      4   NaN      3     U      4   \n",
       "1   Arafat         terror    9      3     D      4   NaN      3     U      4   \n",
       "2      FBI    fingerprint  109      3     D      4   NaN      4   NaN      3   \n",
       "3      FBI  investigation  110      3     U      3     U      3     U      3   \n",
       "4  Harvard           Yale  137      2     S      3     S      2     S      2   \n",
       "\n",
       "  D_Dim  P_Sim P_Dim  Avg     Stdev  H_orig  H_reversed word1_kg_id  \\\n",
       "0   NaN    4.0   NaN  3.6  0.547723  2.1250      7.8750      Q34211   \n",
       "1   NaN    4.0   NaN  3.6  0.547723  3.0625      6.9375      Q34211   \n",
       "2     u    4.0   NaN  3.6  0.547723  4.0625      5.9375       Q8333   \n",
       "3     u    3.0     u  3.0  0.000000  5.0625      4.9375       Q8333   \n",
       "4     s    2.0     s  2.2  0.447214  4.8750      5.1250      Q13371   \n",
       "\n",
       "  word2_kg_id category  \n",
       "0        Q454        U  \n",
       "1   Q13648784        U  \n",
       "2     Q178022        U  \n",
       "3   Q21004260        M  \n",
       "4      Q49112        M  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "varying-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingWordSimSet = set(wordSim353AnnotDF_New[wordSim353AnnotDF_New.word1_kg_id.apply(lambda p: p not in absEmbeddings)] + wordSim353AnnotDF_New[wordSim353AnnotDF_New.word2_kg_id.apply(lambda p: p not in absEmbeddings)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "changing-cycle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11401677131652832 s\n",
      "0.11957383155822754 s\n",
      "0.09752821922302246 s\n",
      "0.128997802734375 s\n",
      "0.11990189552307129 s\n",
      "0.11844491958618164 s\n",
      "0.11752724647521973 s\n",
      "0.11877274513244629 s\n",
      "0.11719059944152832 s\n",
      "0.11760425567626953 s\n",
      "0.11708760261535645 s\n",
      "0.09807181358337402 s\n",
      "0.0916135311126709 s\n",
      "0.09286952018737793 s\n",
      "0.0907738208770752 s\n",
      "0.0915842056274414 s\n",
      "0.09347748756408691 s\n",
      "0.08993768692016602 s\n",
      "0.10148978233337402 s\n",
      "0.11854410171508789 s\n",
      "0.12027955055236816 s\n",
      "0.13148927688598633 s\n",
      "0.11908864974975586 s\n",
      "0.13748478889465332 s\n",
      "0.13097643852233887 s\n",
      "0.11984562873840332 s\n",
      "0.12159109115600586 s\n",
      "0.12565040588378906 s\n",
      "0.1192171573638916 s\n",
      "0.14190435409545898 s\n",
      "0.128098726272583 s\n",
      "0.1173861026763916 s\n",
      "0.11848211288452148 s\n",
      "0.11741471290588379 s\n",
      "0.11730766296386719 s\n",
      "0.12353205680847168 s\n",
      "0.11716032028198242 s\n",
      "0.11889147758483887 s\n",
      "0.11724376678466797 s\n",
      "0.11714792251586914 s\n"
     ]
    }
   ],
   "source": [
    "for _, row in wordSim353AnnotDF_New.iterrows():\n",
    "    if row.word1_kg_id not in absEmbeddings:\n",
    "        absEmbeddings[row.word1_kg_id] = getSentEmbeddings(row['Word 1'], 'bert-base-nli-mean-tokens')\n",
    "    if row.word2_kg_id not in absEmbeddings:\n",
    "        absEmbeddings[row.word2_kg_id] = getSentEmbeddings(row['Word 2'], 'bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "documentary-midnight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missingWordSimSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "sixth-paradise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662\n",
      "No. of keys in embedDict: 19166\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19166.000000\n",
      "mean         0.339064\n",
      "std          0.072734\n",
      "min          0.000000\n",
      "25%          0.287403\n",
      "50%          0.334725\n",
      "75%          0.388172\n",
      "max          0.660678\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 344\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.37808291427810886, pvalue=2.1412324981626763e-23)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3571490077264898, pvalue=4.7415066582386246e-21)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.36636798649447055, pvalue=5.2187863707845704e-24)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.3713906787854944, pvalue=1.253257701630852e-24)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6511627906976745\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6017441860465116\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19166.000000\n",
      "mean         0.244476\n",
      "std          0.145834\n",
      "min          0.000000\n",
      "25%          0.104152\n",
      "50%          0.234678\n",
      "75%          0.376765\n",
      "max          0.660678\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 344\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.37808291427810886, pvalue=2.1412324981626763e-23)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.37186923032141733, pvalue=1.0985961673989065e-22)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.36636798649447055, pvalue=5.2187863707845704e-24)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.37051869405377086, pvalue=1.6123151472069758e-24)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6511627906976745\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6540697674418605\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19166.000000\n",
      "mean         0.404541\n",
      "std          0.081848\n",
      "min          0.000000\n",
      "25%          0.351736\n",
      "50%          0.401690\n",
      "75%          0.453416\n",
      "max          0.872588\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 344\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.37808291427810886, pvalue=2.1412324981626763e-23)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.31762341611315487, pvalue=5.624902334302071e-17)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.36636798649447055, pvalue=5.2187863707845704e-24)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.33907069116618244, pvalue=8.52432972070843e-21)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6511627906976745\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.4941860465116279\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(absEmbeddings)\n",
    "embedDictMaster['abstract_firstSent_19k'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['abstract_firstSent_19k_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _, confusionMatrixMaster['abstract_firstSent_19k_old_'+str(weightCase)], confusionMatrixMaster['abstract_firstSent_19k_new_'+str(weightCase)] = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-cameroon",
   "metadata": {},
   "source": [
    "### Combination of all old embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "smooth-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text_7props_19k', 'text_2props_19k', 'complex_19k', 'transe_19k', 'complex_probase', 'transe_probase', 'complex_probase_19k', 'transe_probase_19k', 'abstract_19k', 'abstract_firstSent_19k'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedDictMaster.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "material-design",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text_7props_19k_1', 'text_7props_19k_2', 'text_7props_19k_0.5', 'text_2props_19k_1', 'text_2props_19k_2', 'text_2props_19k_0.5', 'complex_19k_1', 'complex_19k_2', 'complex_19k_0.5', 'transe_19k_1', 'transe_19k_2', 'transe_19k_0.5', 'complex_probase_1', 'complex_probase_2', 'complex_probase_0.5', 'transe_probase_1', 'transe_probase_2', 'transe_probase_0.5', 'complex_probase_19k_1', 'complex_probase_19k_2', 'complex_probase_19k_0.5', 'transe_probase_19k_1', 'transe_probase_19k_2', 'transe_probase_19k_0.5', 'abstract_19k_1', 'abstract_19k_2', 'abstract_19k_0.5', 'abstract_firstSent_19k_1', 'abstract_firstSent_19k_2', 'abstract_firstSent_19k_0.5'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newEmbedDictMaster.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-frederick",
   "metadata": {},
   "source": [
    "#### Compl + Transe + Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "removed-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedDictConcat = {}\n",
    "for key1 in ['complex_19k', 'transe_19k', \n",
    "            'abstract_firstSent_19k']:\n",
    "    for word in embedDictMaster[key1].keys():\n",
    "        if word not in embedDictConcat:\n",
    "            embedDictConcat[word] = []\n",
    "        embedDictConcat[word].append(embedDictMaster[key1][word])\n",
    "for word in embedDictConcat.keys():\n",
    "    embedDictConcat[word] = [item for sublist in embedDictConcat[word] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "indie-washington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embedding: 968\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of embedding: {len(embedDictConcat['Q18037012'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "caring-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word1 in list(embedDictConcat.keys()):\n",
    "    if len(embedDictConcat[word1]) != 968:\n",
    "        del embedDictConcat[word1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "twelve-tribute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19101.0\n",
       "mean       968.0\n",
       "std          0.0\n",
       "min        968.0\n",
       "25%        968.0\n",
       "50%        968.0\n",
       "75%        968.0\n",
       "max        968.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([len(val1) for val1 in embedDictConcat.values()]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "animated-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662\n",
      "No. of keys in embedDict: 19101\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19101.000000\n",
      "mean         0.336903\n",
      "std          0.071873\n",
      "min          0.000000\n",
      "25%          0.284286\n",
      "50%          0.332284\n",
      "75%          0.389200\n",
      "max          0.596558\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.33855152383136056, pvalue=5.074789109206347e-19)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.31344285039654224, pvalue=1.587990989990702e-16)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.31870634863885755, pvalue=1.6590685394196158e-18)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.2983652058391759, pvalue=2.0692364624319403e-16)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6822157434402333\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6676384839650146\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19101.000000\n",
      "mean         0.245075\n",
      "std          0.146398\n",
      "min          0.000000\n",
      "25%          0.099960\n",
      "50%          0.239725\n",
      "75%          0.380577\n",
      "max          0.596558\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.33855152383136056, pvalue=5.074789109206347e-19)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3270255968193857, pvalue=7.482780885295614e-18)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.31870634863885755, pvalue=1.6590685394196158e-18)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.3144288703997577, pvalue=4.696112489737555e-18)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6822157434402333\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6880466472303207\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19101.000000\n",
      "mean         0.400303\n",
      "std          0.071506\n",
      "min          0.000000\n",
      "25%          0.357059\n",
      "50%          0.402058\n",
      "75%          0.445388\n",
      "max          0.813749\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.33855152383136056, pvalue=5.074789109206347e-19)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.2967991230842074, pvalue=5.639053240442108e-15)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.31870634863885755, pvalue=1.6590685394196158e-18)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.2739615906247492, pvalue=4.489403776140874e-14)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6822157434402333\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6005830903790087\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(embedDictConcat)\n",
    "embedDictMaster['concat_19k_v1'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['concat_19k_v1_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _ = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "suspected-footage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17849\n",
      "No. of keys in embedDict: 19101\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19101.000000\n",
      "mean         0.321205\n",
      "std          0.063429\n",
      "min          0.000000\n",
      "25%          0.277493\n",
      "50%          0.311720\n",
      "75%          0.359268\n",
      "max          0.596557\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.33868087126132435, pvalue=4.924627127334063e-19)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.2891828519936888, pvalue=2.717366700252014e-14)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.31852085513832423, pvalue=1.7372739400060115e-18)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.27713398557337643, pvalue=2.2907553462981174e-14)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6822157434402333\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6501457725947521\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19101.000000\n",
      "mean         0.188928\n",
      "std          0.144828\n",
      "min          0.000000\n",
      "25%          0.059667\n",
      "50%          0.147733\n",
      "75%          0.327197\n",
      "max          0.596557\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.33868087126132435, pvalue=4.924627127334063e-19)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.33562487778756755, pvalue=1.0136749729444057e-18)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.31852085513832423, pvalue=1.7372739400060115e-18)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.31665315908408964, pvalue=2.7384643013776528e-18)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6822157434402333\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6822157434402333\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19101.000000\n",
      "mean         0.427234\n",
      "std          0.094690\n",
      "min          0.000000\n",
      "25%          0.367149\n",
      "50%          0.418971\n",
      "75%          0.473102\n",
      "max          0.895330\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 343\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.33868087126132435, pvalue=4.924627127334063e-19)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.13050673469358315, pvalue=0.0005927381978235836)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.31852085513832423, pvalue=1.7372739400060115e-18)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.1636905372538761, pvalue=6.524566396115546e-06)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6822157434402333\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.22157434402332363\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(embedDictConcat)\n",
    "embedDictMaster['concat_probase_19k_v1'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text, probDF_Qnodes_DF_WQnodes1_subset]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['concat_probase_19k__v1_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _ = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-norway",
   "metadata": {},
   "source": [
    "#### Text_7props + Text_2props + Complex + Transe + Abstract + Abstract_FirstSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "guided-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedDictConcat = {}\n",
    "for key1 in ['text_7props_19k', 'text_2props_19k', 'complex_19k', 'transe_19k', \n",
    "            'abstract_19k', 'abstract_firstSent_19k']:\n",
    "    for word in embedDictMaster[key1].keys():\n",
    "        if word not in embedDictConcat:\n",
    "            embedDictConcat[word] = []\n",
    "        embedDictConcat[word].append(embedDictMaster[key1][word])\n",
    "for word in embedDictConcat.keys():\n",
    "    embedDictConcat[word] = [item for sublist in embedDictConcat[word] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "creative-advice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embedding: 3784\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of embedding: {len(embedDictConcat['Q18037012'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "apart-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word1 in list(embedDictConcat.keys()):\n",
    "    if len(embedDictConcat[word1]) != 3784:\n",
    "        del embedDictConcat[word1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "foreign-merchant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19090.0\n",
       "mean      3784.0\n",
       "std          0.0\n",
       "min       3784.0\n",
       "25%       3784.0\n",
       "50%       3784.0\n",
       "75%       3784.0\n",
       "max       3784.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([len(val1) for val1 in embedDictConcat.values()]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aquatic-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662\n",
      "No. of keys in embedDict: 19090\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19090.000000\n",
      "mean         0.318414\n",
      "std          0.060577\n",
      "min          0.000000\n",
      "25%          0.273273\n",
      "50%          0.313881\n",
      "75%          0.362231\n",
      "max          0.546240\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 325\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.41886430173530353, pvalue=8.645413536273471e-27)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.40347307747318084, pvalue=5.629213176377413e-25)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.4124606263600543, pvalue=2.0652878227656027e-28)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.40536224043013125, pvalue=1.6868252763103453e-27)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6523076923076923\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6307692307692307\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19090.000000\n",
      "mean         0.230697\n",
      "std          0.135101\n",
      "min          0.000000\n",
      "25%          0.097307\n",
      "50%          0.223935\n",
      "75%          0.356438\n",
      "max          0.546240\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 325\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.41886430173530353, pvalue=8.645413536273471e-27)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.40442451164800897, pvalue=4.371701842100601e-25)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.4124606263600543, pvalue=2.0652878227656027e-28)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.4101503518414275, pvalue=4.1055209935697305e-28)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6523076923076923\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6523076923076923\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19090.000000\n",
      "mean         0.378997\n",
      "std          0.061137\n",
      "min          0.000000\n",
      "25%          0.342927\n",
      "50%          0.379359\n",
      "75%          0.416067\n",
      "max          0.760023\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 325\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.41886430173530353, pvalue=8.645413536273471e-27)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3828276431671376, pvalue=1.2015280268194575e-22)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.4124606263600543, pvalue=2.0652878227656027e-28)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.36987136293537864, pvalue=3.618695156207996e-23)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6523076923076923\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.5415384615384615\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(embedDictConcat)\n",
    "embedDictMaster['concat_19k_v2'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['concat_19k_v2_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _ = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "behavioral-brooks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17849\n",
      "No. of keys in embedDict: 19090\n",
      "\n",
      "\n",
      "Weight Case: 1\n",
      "count    19090.000000\n",
      "mean         0.304466\n",
      "std          0.054097\n",
      "min          0.000000\n",
      "25%          0.266260\n",
      "50%          0.295631\n",
      "75%          0.337646\n",
      "max          0.546240\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 325\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.418699029532589, pvalue=9.039782435991911e-27)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.3563958420194592, pvalue=7.705212357023742e-20)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.41247576976710154, pvalue=2.053616736808825e-28)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.36941390801600477, pvalue=4.091096997249633e-23)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6523076923076923\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6092307692307692\n",
      "\n",
      "\n",
      "Weight Case: 2\n",
      "count    19090.000000\n",
      "mean         0.178573\n",
      "std          0.134771\n",
      "min          0.000000\n",
      "25%          0.057617\n",
      "50%          0.140175\n",
      "75%          0.314839\n",
      "max          0.546240\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 325\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.418699029532589, pvalue=9.039782435991911e-27)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.4167472980442226, pvalue=1.5499840293424274e-26)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.41247576976710154, pvalue=2.053616736808825e-28)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.41238438242524034, pvalue=2.1128593107239733e-28)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6523076923076923\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.6553846153846153\n",
      "\n",
      "\n",
      "Weight Case: 0.5\n",
      "count    19090.000000\n",
      "mean         0.405175\n",
      "std          0.085240\n",
      "min          0.000000\n",
      "25%          0.352177\n",
      "50%          0.394099\n",
      "75%          0.443428\n",
      "max          0.797620\n",
      "dtype: float64\n",
      "\n",
      "Length of wordsim dataset: 344\n",
      "No. of pairs with some value for embeddings: 325\n",
      "KT Corr of old emb with Annotated Avg: KendalltauResult(correlation=0.418699029532589, pvalue=9.039782435991911e-27)\n",
      "KT Corr of new emb with Annotated Avg: KendalltauResult(correlation=0.1299009113611685, pvalue=0.0008902251998159792)\n",
      "KT Corr of old emb with Human Avg Reversed: KendalltauResult(correlation=0.41247576976710154, pvalue=2.053616736808825e-28)\n",
      "KT Corr of new emb with Human Avg Reversed: KendalltauResult(correlation=0.1761010833372823, pvalue=2.3561612238907513e-06)\n",
      "Classification Accuracy of old embeddings categories vs annotated averages categories: 0.6523076923076923\n",
      "Classification Accuracy of new embeddings categories vs annotated averages categories: 0.16923076923076924\n"
     ]
    }
   ],
   "source": [
    "embedDict = normalize(embedDictConcat)\n",
    "embedDictMaster['concat_probase_19k_v2'] = embedDict\n",
    "neighDict = fetchNeighbours(pd.concat([p279WordSimSeededDF_wabs_text, p279Seeded_SiblingsDF3_wabs_text, probDF_Qnodes_DF_WQnodes1_subset]))\n",
    "print(f\"No. of keys in embedDict: {len(embedDict.keys())}\")\n",
    "for weightCase in [1,2,0.5]:\n",
    "    print(f\"\\n\\nWeight Case: {weightCase}\")\n",
    "    newEmbedDict = retrofit(embedDict, neighDict, weightCase)\n",
    "    newEmbedDictMaster['concat_probase_19k_v2_'+str(weightCase)] = newEmbedDict\n",
    "    dists = determineDistances(embedDict, newEmbedDict)\n",
    "    print(pd.Series(dists).describe())\n",
    "    print()\n",
    "    _ = fetchCorrelationResults(embedDict, newEmbedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-insured",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-pipeline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-student",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "extensive-forty",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrixMaster.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedDict = embedDictMaster['text_7props_19k']\n",
    "newEmbedDict = newEmbedDictMaster['text_7props_19k_2']\n",
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')\n",
    "print(f\"Length of wordsim dataset: {len(wordSim353AnnotDF_New)}\")\n",
    "assert wordSim353AnnotDF_New.word1_kg_id.isna().sum() == 0\n",
    "assert wordSim353AnnotDF_New.word2_kg_id.isna().sum() == 0\n",
    "wordSim353AnnotDF_New['category'] = wordSim353AnnotDF_New.Avg.apply(labelSamples)\n",
    "wordSim353AnnotDF_New2 = wordSim353AnnotDF_New[wordSim353AnnotDF_New.apply(lambda p: p['word1_kg_id'] in embedDict and p['word2_kg_id'] in embedDict, axis=1)]\n",
    "wordSimMissingSet = set(wordSim353AnnotDF_New[wordSim353AnnotDF_New.word1_kg_id.apply(lambda p: p not in embedDict)].word1_kg_id.to_list() + wordSim353AnnotDF_New[wordSim353AnnotDF_New.word2_kg_id.apply(lambda p: p not in embedDict)].word2_kg_id.to_list())\n",
    "#     wordSimMissingSet\n",
    "print(f\"No. of pairs with some value for embeddings: {len(wordSim353AnnotDF_New2)}\")\n",
    "wordSim353AnnotDF_New2['textOld'] = wordSim353AnnotDF_New2.apply(lambda p: cosine_similarity(np.array(embedDict[p['word1_kg_id']]).reshape(1,-1), np.array(embedDict[p['word2_kg_id']]).reshape(1,-1))[0][0], axis=1)\n",
    "wordSim353AnnotDF_New2['textNew'] = wordSim353AnnotDF_New2.apply(lambda p: cosine_similarity(np.array(newEmbedDict[p['word1_kg_id']]).reshape(1,-1), np.array(newEmbedDict[p['word2_kg_id']]).reshape(1,-1))[0][0], axis=1)\n",
    "wordSim353AnnotDF_New2['textOld'] = wordSim353AnnotDF_New2.textOld.apply(lambda p: 4 - 3 * p)\n",
    "wordSim353AnnotDF_New2['textNew'] = wordSim353AnnotDF_New2.textNew.apply(lambda p: 4 - 3 * p)\n",
    "print(f\"KT Corr of old emb with Annotated Avg: {stats.kendalltau(wordSim353AnnotDF_New2['textOld'], wordSim353AnnotDF_New2['Avg'])}\")\n",
    "print(f\"KT Corr of new emb with Annotated Avg: {stats.kendalltau(wordSim353AnnotDF_New2['textNew'], wordSim353AnnotDF_New2['Avg'])}\")\n",
    "print(f\"KT Corr of old emb with Human Avg Reversed: {stats.kendalltau(wordSim353AnnotDF_New2['textOld'], wordSim353AnnotDF_New2['H_reversed'])}\")\n",
    "print(f\"KT Corr of new emb with Human Avg Reversed: {stats.kendalltau(wordSim353AnnotDF_New2['textNew'], wordSim353AnnotDF_New2['H_reversed'])}\")\n",
    "\n",
    "print(f\"Classification Accuracy of old embeddings categories vs annotated averages categories: {accuracy_score(wordSim353AnnotDF_New2['textOld'].apply(labelSamples), wordSim353AnnotDF_New2['category'])}\")\n",
    "print(f\"Classification Accuracy of new embeddings categories vs annotated averages categories: {accuracy_score(wordSim353AnnotDF_New2['textNew'].apply(labelSamples), wordSim353AnnotDF_New2['category'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "distinct-timothy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    210\n",
       "U    101\n",
       "I     20\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New2['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "antique-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(20,20))\n",
    "for num, key1 in enumerate(['text_7props_19k_old_2', 'text_7props_19k_new_2', 'text_2props_19k_old_2', 'text_2props_19k_new_2', \n",
    "             'transe_19k_old_1', 'transe_19k_new_1', 'complex_19k_old_1', 'complex_19k_new_1']):\n",
    "    plt.subplot(4, 2, num+1)\n",
    "    sns.heatmap(pd.DataFrame(confusionMatrixMaster[key1], LABELS, LABELS), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-letters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "micro-phrase",
   "metadata": {},
   "source": [
    "# Save all embeddings and similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "boring-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "newEmbedDictMaster['concat_probase_19k_v1_2'] = newEmbedDictMaster['concat_probase_19k__v1_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "automatic-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of wordsim dataset: 344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97162bbb58542999eb317ede34a3300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emb_pairs = [('text_7props_19k', 'text_7props_19k_2'),\n",
    "             ('text_2props_19k', 'text_2props_19k_2'),\n",
    "             ('complex_19k', 'complex_19k_2'),\n",
    "             ('transe_19k', 'transe_19k_1'),\n",
    "             ('abstract_19k', 'abstract_19k_2'),\n",
    "             ('abstract_firstSent_19k', 'abstract_firstSent_19k_2'),\n",
    "             ('complex_probase', 'complex_probase_2'),\n",
    "             ('transe_probase', 'transe_probase_1'),\n",
    "             ('complex_probase_19k', 'complex_probase_19k_2'),\n",
    "             ('transe_probase_19k', 'transe_probase_19k_1'),\n",
    "             ('concat_19k_v1', 'concat_19k_v1_2'),\n",
    "             ('concat_probase_19k_v1', 'concat_probase_19k_v1_2'),\n",
    "             ('concat_19k_v2', 'concat_19k_v2_2'),\n",
    "             ('concat_probase_19k_v2', 'concat_probase_19k_v2_2')]\n",
    "\n",
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')\n",
    "print(f\"Length of wordsim dataset: {len(wordSim353AnnotDF_New)}\")\n",
    "assert wordSim353AnnotDF_New.word1_kg_id.isna().sum() == 0\n",
    "assert wordSim353AnnotDF_New.word2_kg_id.isna().sum() == 0\n",
    "wordSim353AnnotDF_New['category'] = wordSim353AnnotDF_New.Avg.apply(labelSamples)\n",
    "\n",
    "\n",
    "for key1, key2 in tqdm(emb_pairs):\n",
    "#     wordSim353AnnotDF_New2 = wordSim353AnnotDF_New[wordSim353AnnotDF_New.apply(lambda p: p['word1_kg_id'] in embedDict and p['word2_kg_id'] in embedDict, axis=1)]\n",
    "#     wordSimMissingSet = set(wordSim353AnnotDF_New[wordSim353AnnotDF_New.word1_kg_id.apply(lambda p: p not in embedDict)].word1_kg_id.to_list() + wordSim353AnnotDF_New[wordSim353AnnotDF_New.word2_kg_id.apply(lambda p: p not in embedDict)].word2_kg_id.to_list())\n",
    "    #     wordSimMissingSet\n",
    "#     print(f\"No. of pairs with some value for embeddings: {len(wordSim353AnnotDF_New2)}\")\n",
    "\n",
    "    embedDict = embedDictMaster[key1]\n",
    "    newEmbedDict = newEmbedDictMaster[key2]\n",
    "    \n",
    "    wordSim353AnnotDF_New[key1+'_word1_old'] = wordSim353AnnotDF_New.apply(lambda p: embedDict[p['word1_kg_id']].tolist() if p['word1_kg_id'] in embedDict else None, axis=1)\n",
    "    wordSim353AnnotDF_New[key1+'_word2_old'] = wordSim353AnnotDF_New.apply(lambda p: embedDict[p['word2_kg_id']].tolist() if p['word2_kg_id'] in embedDict else None, axis=1)\n",
    "    \n",
    "    wordSim353AnnotDF_New[key1+'_word1_new'] = wordSim353AnnotDF_New.apply(lambda p: newEmbedDict[p['word1_kg_id']].tolist() if p['word1_kg_id'] in newEmbedDict else None, axis=1)\n",
    "    wordSim353AnnotDF_New[key1+'_word2_new'] = wordSim353AnnotDF_New.apply(lambda p: newEmbedDict[p['word2_kg_id']].tolist() if p['word2_kg_id'] in newEmbedDict else None, axis=1)\n",
    "    \n",
    "    wordSim353AnnotDF_New[key1+'_old_cosSim'] = wordSim353AnnotDF_New.apply(lambda p: cosine_similarity(np.array(embedDict[p['word1_kg_id']]).reshape(1,-1), np.array(embedDict[p['word2_kg_id']]).reshape(1,-1))[0][0] if p['word1_kg_id'] in embedDict and p['word2_kg_id'] in embedDict else -1, axis=1)\n",
    "    wordSim353AnnotDF_New[key2+'_new_cosSim'] = wordSim353AnnotDF_New.apply(lambda p: cosine_similarity(np.array(newEmbedDict[p['word1_kg_id']]).reshape(1,-1), np.array(newEmbedDict[p['word2_kg_id']]).reshape(1,-1))[0][0] if p['word1_kg_id'] in newEmbedDict and p['word2_kg_id'] in newEmbedDict else -1, axis=1)\n",
    "    wordSim353AnnotDF_New[key1+'_old_cosSim'] = wordSim353AnnotDF_New[key1+'_old_cosSim'].apply(lambda p: 4 - 3 * p)\n",
    "    wordSim353AnnotDF_New[key2+'_new_cosSim'] = wordSim353AnnotDF_New[key2+'_new_cosSim'].apply(lambda p: 4 - 3 * p)\n",
    "wordSim353AnnotDF_New_Merged_DF = wordSim353AnnotDF_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "related-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Word 1', 'Word 2', 'ID', 'H_Sim', 'H_Dim', 'F_Sim', 'F_Dim', 'N_Sim',\n",
       "       'N_Dim', 'D_Sim',\n",
       "       ...\n",
       "       'concat_19k_v2_word1_new', 'concat_19k_v2_word2_new',\n",
       "       'concat_19k_v2_old_cosSim', 'concat_19k_v2_2_new_cosSim',\n",
       "       'concat_probase_19k_v2_word1_old', 'concat_probase_19k_v2_word2_old',\n",
       "       'concat_probase_19k_v2_word1_new', 'concat_probase_19k_v2_word2_new',\n",
       "       'concat_probase_19k_v2_old_cosSim',\n",
       "       'concat_probase_19k_v2_2_new_cosSim'],\n",
       "      dtype='object', length=104)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "allied-sunrise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>ID</th>\n",
       "      <th>H_Sim</th>\n",
       "      <th>H_Dim</th>\n",
       "      <th>F_Sim</th>\n",
       "      <th>F_Dim</th>\n",
       "      <th>N_Sim</th>\n",
       "      <th>N_Dim</th>\n",
       "      <th>D_Sim</th>\n",
       "      <th>...</th>\n",
       "      <th>concat_19k_v2_word1_new</th>\n",
       "      <th>concat_19k_v2_word2_new</th>\n",
       "      <th>concat_19k_v2_old_cosSim</th>\n",
       "      <th>concat_19k_v2_2_new_cosSim</th>\n",
       "      <th>concat_probase_19k_v2_word1_old</th>\n",
       "      <th>concat_probase_19k_v2_word2_old</th>\n",
       "      <th>concat_probase_19k_v2_word1_new</th>\n",
       "      <th>concat_probase_19k_v2_word2_new</th>\n",
       "      <th>concat_probase_19k_v2_old_cosSim</th>\n",
       "      <th>concat_probase_19k_v2_2_new_cosSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0067204430541292475, 0.008331487632641807, ...</td>\n",
       "      <td>[-0.004515859562266559, -0.011723668837741234,...</td>\n",
       "      <td>3.468370</td>\n",
       "      <td>3.384407</td>\n",
       "      <td>[0.006720440253943506, 0.00833148416118722, 0....</td>\n",
       "      <td>[-0.0050116109222357935, -0.013383541509188317...</td>\n",
       "      <td>[0.006720440253943506, 0.00833148416118722, 0....</td>\n",
       "      <td>[-0.004971298302113362, -0.013254267455943004,...</td>\n",
       "      <td>3.468370</td>\n",
       "      <td>3.463734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0067204430541292475, 0.008331487632641807, ...</td>\n",
       "      <td>[-0.004862257036458548, 0.014077170447753274, ...</td>\n",
       "      <td>3.035534</td>\n",
       "      <td>2.991152</td>\n",
       "      <td>[0.006720440253943506, 0.00833148416118722, 0....</td>\n",
       "      <td>[-0.005805280378137928, 0.015115419540555773, ...</td>\n",
       "      <td>[0.006720440253943506, 0.00833148416118722, 0....</td>\n",
       "      <td>[-0.004862255010517295, 0.01407716458226321, 0...</td>\n",
       "      <td>3.035534</td>\n",
       "      <td>2.991152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.006466897046995817, 0.014694837513784692, -...</td>\n",
       "      <td>[0.01523113313292473, 0.005271417432183582, -0...</td>\n",
       "      <td>2.902356</td>\n",
       "      <td>2.850218</td>\n",
       "      <td>[0.0064668943524542844, 0.014694831390933237, ...</td>\n",
       "      <td>[0.013922101038066187, 0.0023911841962956006, ...</td>\n",
       "      <td>[0.0064668943524542844, 0.014694831390933237, ...</td>\n",
       "      <td>[0.01381456413075283, 0.0024352598782685863, -...</td>\n",
       "      <td>2.902356</td>\n",
       "      <td>2.895993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.006466897046995817, 0.014694837513784692, -...</td>\n",
       "      <td>[0.013016090555331788, 0.01114268765690899, -0...</td>\n",
       "      <td>2.995206</td>\n",
       "      <td>2.962306</td>\n",
       "      <td>[0.0064668943524542844, 0.014694831390933237, ...</td>\n",
       "      <td>[0.013274960537868754, 0.010965634834463656, -...</td>\n",
       "      <td>[0.0064668943524542844, 0.014694831390933237, ...</td>\n",
       "      <td>[0.013242882478240212, 0.010953106140234146, -...</td>\n",
       "      <td>2.995206</td>\n",
       "      <td>2.993596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.01322626153814759, 0.005047111609608307, -0...</td>\n",
       "      <td>[0.010410829355084429, 0.014776997941327313, -...</td>\n",
       "      <td>1.689315</td>\n",
       "      <td>1.689315</td>\n",
       "      <td>[0.013226256027203037, 0.00504710950664428, -0...</td>\n",
       "      <td>[0.010410825017237097, 0.01477699178424233, -0...</td>\n",
       "      <td>[0.013226256027203037, 0.00504710950664428, -0...</td>\n",
       "      <td>[0.010410825017237097, 0.01477699178424233, -0...</td>\n",
       "      <td>1.689315</td>\n",
       "      <td>1.689315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word 1         Word 2   ID  H_Sim H_Dim  F_Sim F_Dim  N_Sim N_Dim  D_Sim  \\\n",
       "0   Arafat          peace    8      3     D      4   NaN      3     U      4   \n",
       "1   Arafat         terror    9      3     D      4   NaN      3     U      4   \n",
       "2      FBI    fingerprint  109      3     D      4   NaN      4   NaN      3   \n",
       "3      FBI  investigation  110      3     U      3     U      3     U      3   \n",
       "4  Harvard           Yale  137      2     S      3     S      2     S      2   \n",
       "\n",
       "   ...                            concat_19k_v2_word1_new  \\\n",
       "0  ...  [0.0067204430541292475, 0.008331487632641807, ...   \n",
       "1  ...  [0.0067204430541292475, 0.008331487632641807, ...   \n",
       "2  ...  [0.006466897046995817, 0.014694837513784692, -...   \n",
       "3  ...  [0.006466897046995817, 0.014694837513784692, -...   \n",
       "4  ...  [0.01322626153814759, 0.005047111609608307, -0...   \n",
       "\n",
       "                             concat_19k_v2_word2_new concat_19k_v2_old_cosSim  \\\n",
       "0  [-0.004515859562266559, -0.011723668837741234,...                 3.468370   \n",
       "1  [-0.004862257036458548, 0.014077170447753274, ...                 3.035534   \n",
       "2  [0.01523113313292473, 0.005271417432183582, -0...                 2.902356   \n",
       "3  [0.013016090555331788, 0.01114268765690899, -0...                 2.995206   \n",
       "4  [0.010410829355084429, 0.014776997941327313, -...                 1.689315   \n",
       "\n",
       "   concat_19k_v2_2_new_cosSim  \\\n",
       "0                    3.384407   \n",
       "1                    2.991152   \n",
       "2                    2.850218   \n",
       "3                    2.962306   \n",
       "4                    1.689315   \n",
       "\n",
       "                     concat_probase_19k_v2_word1_old  \\\n",
       "0  [0.006720440253943506, 0.00833148416118722, 0....   \n",
       "1  [0.006720440253943506, 0.00833148416118722, 0....   \n",
       "2  [0.0064668943524542844, 0.014694831390933237, ...   \n",
       "3  [0.0064668943524542844, 0.014694831390933237, ...   \n",
       "4  [0.013226256027203037, 0.00504710950664428, -0...   \n",
       "\n",
       "                     concat_probase_19k_v2_word2_old  \\\n",
       "0  [-0.0050116109222357935, -0.013383541509188317...   \n",
       "1  [-0.005805280378137928, 0.015115419540555773, ...   \n",
       "2  [0.013922101038066187, 0.0023911841962956006, ...   \n",
       "3  [0.013274960537868754, 0.010965634834463656, -...   \n",
       "4  [0.010410825017237097, 0.01477699178424233, -0...   \n",
       "\n",
       "                     concat_probase_19k_v2_word1_new  \\\n",
       "0  [0.006720440253943506, 0.00833148416118722, 0....   \n",
       "1  [0.006720440253943506, 0.00833148416118722, 0....   \n",
       "2  [0.0064668943524542844, 0.014694831390933237, ...   \n",
       "3  [0.0064668943524542844, 0.014694831390933237, ...   \n",
       "4  [0.013226256027203037, 0.00504710950664428, -0...   \n",
       "\n",
       "                     concat_probase_19k_v2_word2_new  \\\n",
       "0  [-0.004971298302113362, -0.013254267455943004,...   \n",
       "1  [-0.004862255010517295, 0.01407716458226321, 0...   \n",
       "2  [0.01381456413075283, 0.0024352598782685863, -...   \n",
       "3  [0.013242882478240212, 0.010953106140234146, -...   \n",
       "4  [0.010410825017237097, 0.01477699178424233, -0...   \n",
       "\n",
       "  concat_probase_19k_v2_old_cosSim concat_probase_19k_v2_2_new_cosSim  \n",
       "0                         3.468370                           3.463734  \n",
       "1                         3.035534                           2.991152  \n",
       "2                         2.902356                           2.895993  \n",
       "3                         2.995206                           2.993596  \n",
       "4                         1.689315                           1.689315  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "connected-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_ann_3 = pd.read_csv('../data/consolidated_annotation_r3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "trying-authorization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>H_Sim</th>\n",
       "      <th>H_Dim</th>\n",
       "      <th>F_Sim</th>\n",
       "      <th>F_Dim</th>\n",
       "      <th>N_Sim</th>\n",
       "      <th>N_Dim</th>\n",
       "      <th>D_Sim</th>\n",
       "      <th>D_Dim</th>\n",
       "      <th>P_Sim</th>\n",
       "      <th>P_Dim</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Stdev</th>\n",
       "      <th>H_orig</th>\n",
       "      <th>H_reversed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tool</td>\n",
       "      <td>implement</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>i</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.894</td>\n",
       "      <td>5.313</td>\n",
       "      <td>4.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arrangement</td>\n",
       "      <td>accommodation</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.304</td>\n",
       "      <td>5.125</td>\n",
       "      <td>4.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wood</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.095</td>\n",
       "      <td>7.938</td>\n",
       "      <td>2.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>benchmark</td>\n",
       "      <td>index</td>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.095</td>\n",
       "      <td>5.500</td>\n",
       "      <td>4.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>practice</td>\n",
       "      <td>institution</td>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>3</td>\n",
       "      <td>L,I</td>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.447</td>\n",
       "      <td>3.563</td>\n",
       "      <td>6.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word 1         Word 2  H_Sim H_Dim  F_Sim F_Dim  N_Sim N_Dim  D_Sim  \\\n",
       "0         tool      implement      1   NaN      3     U      1   NaN      2   \n",
       "1  arrangement  accommodation      1   NaN      4   NaN      2     I      1   \n",
       "2         wood         forest      3     H      1   NaN      1   NaN      1   \n",
       "3    benchmark          index      2     I      2     I      2     I      4   \n",
       "4     practice    institution      2     I      3   L,I      3     I      3   \n",
       "\n",
       "  D_Dim  P_Sim P_Dim  Avg  Stdev  H_orig  H_reversed  \n",
       "0     i      1   NaN  1.6  0.894   5.313       4.688  \n",
       "1   NaN      1   NaN  1.8  1.304   5.125       4.875  \n",
       "2   NaN      3     l  1.8  1.095   7.938       2.063  \n",
       "3   NaN      4   NaN  2.8  1.095   5.500       4.500  \n",
       "4     i      3     i  2.8  0.447   3.563       6.438  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_ann_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "political-laptop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cons_ann_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "improved-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_cols = cons_ann_3.columns\n",
    "for _,row in cons_ann_3.iterrows():\n",
    "#     if ((wordSim353AnnotDF_New_Merged_DF['Word 1'] == row['Word 1']) & (wordSim353AnnotDF_New_Merged_DF['Word 2'] == row['Word 2'])).sum() == 2:\n",
    "#         print(row['Word 1'], row['Word 2'])\n",
    "#         print(wordSim353AnnotDF_New_Merged_DF[((wordSim353AnnotDF_New_Merged_DF['Word 1'] == row['Word 1']) & (wordSim353AnnotDF_New_Merged_DF['Word 2'] == row['Word 2']))])\n",
    "#     print (((wordSim353AnnotDF_New_Merged_DF['Word 1'] == row['Word 1']) & (wordSim353AnnotDF_New_Merged_DF['Word 2'] == row['Word 2'])).sum())\n",
    "    for col in ca_cols:\n",
    "        if col in ['Word 1', 'Word 2']:\n",
    "            continue\n",
    "        \n",
    "        wordSim353AnnotDF_New_Merged_DF.at[wordSim353AnnotDF_New_Merged_DF.index[(wordSim353AnnotDF_New_Merged_DF['Word 1'] == row['Word 1']) & (wordSim353AnnotDF_New_Merged_DF['Word 2'] == row['Word 2'])], col] = row[col]\n",
    "#         print(wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['Word 1'] == row['Word 1']) & (wordSim353AnnotDF_New_Merged_DF['Word 2'] == row['Word 2'])][col])\n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "relevant-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF = wordSim353AnnotDF_New_Merged_DF[~wordSim353AnnotDF_New_Merged_DF[['Word 1', 'Word 2']].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-letters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "pretty-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.to_csv('../data/wordsim353_all_embeddings_with_retrofits_new.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "gorgeous-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[['Word 1',\n",
    " 'Word 2',\n",
    " 'ID',\n",
    " 'H_Sim',\n",
    " 'H_Dim',\n",
    " 'F_Sim',\n",
    " 'F_Dim',\n",
    " 'N_Sim',\n",
    " 'N_Dim',\n",
    " 'D_Sim',\n",
    " 'D_Dim',\n",
    " 'P_Sim',\n",
    " 'P_Dim',\n",
    " 'Avg',\n",
    " 'Stdev',\n",
    " 'H_orig',\n",
    " 'H_reversed',\n",
    " 'word1_kg_id',\n",
    " 'word2_kg_id',\n",
    " 'category'] + list(filter(lambda p: 'cosSim' in p, wordSim353AnnotDF_New_Merged_DF.columns.to_list()))].to_csv('../data/wordsim353_all_embeddings_with_retrofits_scores_only_new.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-department",
   "metadata": {},
   "source": [
    "# Determine Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ahead-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF = pd.read_csv('../data/wordsim353_all_embeddings_with_retrofits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suspended-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF['transe_19k_old_cosSim_Diff'] = abs(wordSim353AnnotDF_New_Merged_DF['transe_19k_old_cosSim'] - wordSim353AnnotDF_New_Merged_DF['Avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "racial-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF['transe_19k_1_new_cosSim_Diff'] = abs(wordSim353AnnotDF_New_Merged_DF['transe_19k_1_new_cosSim'] - wordSim353AnnotDF_New_Merged_DF['Avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "another-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metallic-smith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    344.000000\n",
       "mean       0.580594\n",
       "std        0.457960\n",
       "min        0.000000\n",
       "25%        0.222619\n",
       "50%        0.495179\n",
       "75%        0.852326\n",
       "max        5.000000\n",
       "Name: transe_19k_old_cosSim_Diff, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.sort_values(by=['transe_19k_old_cosSim_Diff'],ascending=False)['transe_19k_old_cosSim_Diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "designed-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    344.000000\n",
       "mean       0.645644\n",
       "std        0.526932\n",
       "min        0.000000\n",
       "25%        0.250461\n",
       "50%        0.562808\n",
       "75%        0.927608\n",
       "max        5.000000\n",
       "Name: transe_19k_1_new_cosSim_Diff, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.sort_values(by=['transe_19k_1_new_cosSim_Diff'],ascending=False)['transe_19k_1_new_cosSim_Diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facial-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineFarNessOfOld(val1):\n",
    "    if 0.000000 <= val1 < 0.495179:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def determineFarNessOfNew(val1):\n",
    "    if 0 <= val1 < 0.562808:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "wordSim353AnnotDF_New_Merged_DF['transe_19k_old_cosSim_Diff_Cat'] = wordSim353AnnotDF_New_Merged_DF['transe_19k_old_cosSim_Diff'].apply(determineFarNessOfOld)\n",
    "wordSim353AnnotDF_New_Merged_DF['transe_19k_1_new_cosSim_Diff_Cat'] = wordSim353AnnotDF_New_Merged_DF['transe_19k_1_new_cosSim_Diff'].apply(determineFarNessOfNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lightweight-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF = wordSim353AnnotDF_New_Merged_DF[['Word 1', 'Word 2', 'Avg', 'transe_19k_old_cosSim', 'transe_19k_1_new_cosSim', 'transe_19k_old_cosSim_Diff', 'transe_19k_1_new_cosSim_Diff', 'transe_19k_old_cosSim_Diff_Cat', 'transe_19k_1_new_cosSim_Diff_Cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "american-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Avg</th>\n",
       "      <th>transe_19k_old_cosSim</th>\n",
       "      <th>transe_19k_1_new_cosSim</th>\n",
       "      <th>transe_19k_old_cosSim_Diff</th>\n",
       "      <th>transe_19k_1_new_cosSim_Diff</th>\n",
       "      <th>transe_19k_old_cosSim_Diff_Cat</th>\n",
       "      <th>transe_19k_1_new_cosSim_Diff_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.076303</td>\n",
       "      <td>3.477665</td>\n",
       "      <td>0.523697</td>\n",
       "      <td>0.122335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.103668</td>\n",
       "      <td>2.952181</td>\n",
       "      <td>0.496332</td>\n",
       "      <td>0.647819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.911334</td>\n",
       "      <td>3.126209</td>\n",
       "      <td>0.688666</td>\n",
       "      <td>0.473791</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.881763</td>\n",
       "      <td>2.943750</td>\n",
       "      <td>0.118237</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.135042</td>\n",
       "      <td>2.080022</td>\n",
       "      <td>0.064958</td>\n",
       "      <td>0.119978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>war</td>\n",
       "      <td>troops</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.807539</td>\n",
       "      <td>3.161937</td>\n",
       "      <td>0.192461</td>\n",
       "      <td>0.161937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>weapon</td>\n",
       "      <td>secret</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.310261</td>\n",
       "      <td>2.793832</td>\n",
       "      <td>0.489739</td>\n",
       "      <td>1.006168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.449602</td>\n",
       "      <td>2.739280</td>\n",
       "      <td>0.550398</td>\n",
       "      <td>0.260720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>wood</td>\n",
       "      <td>forest</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.931610</td>\n",
       "      <td>3.541754</td>\n",
       "      <td>1.131610</td>\n",
       "      <td>1.741754</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>word</td>\n",
       "      <td>similarity</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.648427</td>\n",
       "      <td>2.758156</td>\n",
       "      <td>1.101573</td>\n",
       "      <td>0.991844</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word 1         Word 2   Avg  transe_19k_old_cosSim  \\\n",
       "0     Arafat          peace  3.60               3.076303   \n",
       "1     Arafat         terror  3.60               3.103668   \n",
       "2        FBI    fingerprint  3.60               2.911334   \n",
       "3        FBI  investigation  3.00               2.881763   \n",
       "4    Harvard           Yale  2.20               2.135042   \n",
       "..       ...            ...   ...                    ...   \n",
       "339      war         troops  3.00               2.807539   \n",
       "340   weapon         secret  3.80               3.310261   \n",
       "341  weather       forecast  3.00               2.449602   \n",
       "342     wood         forest  1.80               2.931610   \n",
       "343     word     similarity  3.75               2.648427   \n",
       "\n",
       "     transe_19k_1_new_cosSim  transe_19k_old_cosSim_Diff  \\\n",
       "0                   3.477665                    0.523697   \n",
       "1                   2.952181                    0.496332   \n",
       "2                   3.126209                    0.688666   \n",
       "3                   2.943750                    0.118237   \n",
       "4                   2.080022                    0.064958   \n",
       "..                       ...                         ...   \n",
       "339                 3.161937                    0.192461   \n",
       "340                 2.793832                    0.489739   \n",
       "341                 2.739280                    0.550398   \n",
       "342                 3.541754                    1.131610   \n",
       "343                 2.758156                    1.101573   \n",
       "\n",
       "     transe_19k_1_new_cosSim_Diff  transe_19k_old_cosSim_Diff_Cat  \\\n",
       "0                        0.122335                               1   \n",
       "1                        0.647819                               1   \n",
       "2                        0.473791                               1   \n",
       "3                        0.056250                               0   \n",
       "4                        0.119978                               0   \n",
       "..                            ...                             ...   \n",
       "339                      0.161937                               0   \n",
       "340                      1.006168                               0   \n",
       "341                      0.260720                               1   \n",
       "342                      1.741754                               1   \n",
       "343                      0.991844                               1   \n",
       "\n",
       "     transe_19k_1_new_cosSim_Diff_Cat  \n",
       "0                                   0  \n",
       "1                                   1  \n",
       "2                                   0  \n",
       "3                                   0  \n",
       "4                                   0  \n",
       "..                                ...  \n",
       "339                                 0  \n",
       "340                                 1  \n",
       "341                                 0  \n",
       "342                                 1  \n",
       "343                                 1  \n",
       "\n",
       "[344 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "automotive-trouble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['transe_19k_old_cosSim_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['transe_19k_1_new_cosSim_Diff_Cat'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "compressed-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF['old_cat'] = wordSim353AnnotDF_New_Merged_DF['transe_19k_old_cosSim'].apply(labelSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "alert-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF['new_cat'] = wordSim353AnnotDF_New_Merged_DF['transe_19k_1_new_cosSim'].apply(labelSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "psychological-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF['cat'] = wordSim353AnnotDF_New_Merged_DF['Avg'].apply(labelSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "arabic-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[wordSim353AnnotDF_New_Merged_DF['old_cat'] != wordSim353AnnotDF_New_Merged_DF['cat']].to_csv('../data/transEmb/badBefore.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acoustic-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[wordSim353AnnotDF_New_Merged_DF['new_cat'] != wordSim353AnnotDF_New_Merged_DF['cat']].to_csv('../data/transEmb/badAfter.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "accompanied-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.to_csv('../data/transEmb/entireSet.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-difference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "breathing-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['transe_19k_old_cosSim_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['transe_19k_1_new_cosSim_Diff_Cat'] == 0)].to_csv('../data/transEmb/good+good.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chief-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['transe_19k_old_cosSim_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['transe_19k_1_new_cosSim_Diff_Cat'] == 1)].to_csv('../data/transEmb/good+bad.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "shaped-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['transe_19k_old_cosSim_Diff_Cat'] == 1) & (wordSim353AnnotDF_New_Merged_DF['transe_19k_1_new_cosSim_Diff_Cat'] == 0)].to_csv('../data/transEmb/bad+good.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adolescent-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['transe_19k_old_cosSim_Diff_Cat'] == 1) & (wordSim353AnnotDF_New_Merged_DF['transe_19k_1_new_cosSim_Diff_Cat'] == 1)].to_csv('../data/transEmb/bad+bad.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-bridal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-mirror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "placed-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff'] = abs(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim'] - wordSim353AnnotDF_New_Merged_DF['Avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stopped-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff'] = abs(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim'] - wordSim353AnnotDF_New_Merged_DF['Avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deadly-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southeast-canal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    344.000000\n",
       "mean       0.567297\n",
       "std        0.435379\n",
       "min        0.000000\n",
       "25%        0.250130\n",
       "50%        0.508725\n",
       "75%        0.835197\n",
       "max        5.000000\n",
       "Name: concat_19k_v1_old_cosSim_Diff, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.sort_values(by=['concat_19k_v1_old_cosSim_Diff'],ascending=False)['concat_19k_v1_old_cosSim_Diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adequate-terminology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.440000e+02\n",
       "mean     5.938081e-01\n",
       "std      4.503200e-01\n",
       "min      4.440892e-16\n",
       "25%      2.665817e-01\n",
       "50%      5.349785e-01\n",
       "75%      8.528840e-01\n",
       "max      5.000000e+00\n",
       "Name: concat_19k_v1_2_new_cosSim_Diff, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.sort_values(by=['concat_19k_v1_2_new_cosSim_Diff'],ascending=False)['concat_19k_v1_2_new_cosSim_Diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wired-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineFarNessOfOld(val1):\n",
    "    if 0.000000 <= val1 < 0.508725:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def determineFarNessOfNew(val1):\n",
    "    if 0 <= val1 < 5.349785e-01:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] = wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff'].apply(determineFarNessOfOld)\n",
    "wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] = wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff'].apply(determineFarNessOfNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "operating-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF = wordSim353AnnotDF_New_Merged_DF[['Word 1', 'Word 2', 'Avg', 'concat_19k_v1_old_cosSim', 'concat_19k_v1_2_new_cosSim', 'concat_19k_v1_old_cosSim_Diff', 'concat_19k_v1_2_new_cosSim_Diff', 'concat_19k_v1_old_cosSim_Diff_Cat', 'concat_19k_v1_2_new_cosSim_Diff_Cat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quantitative-money",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Avg</th>\n",
       "      <th>concat_19k_v1_old_cosSim</th>\n",
       "      <th>concat_19k_v1_2_new_cosSim</th>\n",
       "      <th>concat_19k_v1_old_cosSim_Diff</th>\n",
       "      <th>concat_19k_v1_2_new_cosSim_Diff</th>\n",
       "      <th>concat_19k_v1_old_cosSim_Diff_Cat</th>\n",
       "      <th>concat_19k_v1_2_new_cosSim_Diff_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.251198</td>\n",
       "      <td>3.193271</td>\n",
       "      <td>0.348802</td>\n",
       "      <td>0.406729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.231409</td>\n",
       "      <td>3.157229</td>\n",
       "      <td>0.368591</td>\n",
       "      <td>0.442771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.948487</td>\n",
       "      <td>2.853048</td>\n",
       "      <td>0.651513</td>\n",
       "      <td>0.746952</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.930365</td>\n",
       "      <td>2.895604</td>\n",
       "      <td>0.069635</td>\n",
       "      <td>0.104396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.991054</td>\n",
       "      <td>1.991054</td>\n",
       "      <td>0.208946</td>\n",
       "      <td>0.208946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>war</td>\n",
       "      <td>troops</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.913931</td>\n",
       "      <td>2.787213</td>\n",
       "      <td>0.086069</td>\n",
       "      <td>0.212787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>weapon</td>\n",
       "      <td>secret</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.152513</td>\n",
       "      <td>3.119065</td>\n",
       "      <td>0.647487</td>\n",
       "      <td>0.680935</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.492765</td>\n",
       "      <td>2.462389</td>\n",
       "      <td>0.507235</td>\n",
       "      <td>0.537611</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>wood</td>\n",
       "      <td>forest</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.612681</td>\n",
       "      <td>2.606941</td>\n",
       "      <td>0.812681</td>\n",
       "      <td>0.806941</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>word</td>\n",
       "      <td>similarity</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.678276</td>\n",
       "      <td>2.652829</td>\n",
       "      <td>1.071724</td>\n",
       "      <td>1.097171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word 1         Word 2   Avg  concat_19k_v1_old_cosSim  \\\n",
       "0     Arafat          peace  3.60                  3.251198   \n",
       "1     Arafat         terror  3.60                  3.231409   \n",
       "2        FBI    fingerprint  3.60                  2.948487   \n",
       "3        FBI  investigation  3.00                  2.930365   \n",
       "4    Harvard           Yale  2.20                  1.991054   \n",
       "..       ...            ...   ...                       ...   \n",
       "339      war         troops  3.00                  2.913931   \n",
       "340   weapon         secret  3.80                  3.152513   \n",
       "341  weather       forecast  3.00                  2.492765   \n",
       "342     wood         forest  1.80                  2.612681   \n",
       "343     word     similarity  3.75                  2.678276   \n",
       "\n",
       "     concat_19k_v1_2_new_cosSim  concat_19k_v1_old_cosSim_Diff  \\\n",
       "0                      3.193271                       0.348802   \n",
       "1                      3.157229                       0.368591   \n",
       "2                      2.853048                       0.651513   \n",
       "3                      2.895604                       0.069635   \n",
       "4                      1.991054                       0.208946   \n",
       "..                          ...                            ...   \n",
       "339                    2.787213                       0.086069   \n",
       "340                    3.119065                       0.647487   \n",
       "341                    2.462389                       0.507235   \n",
       "342                    2.606941                       0.812681   \n",
       "343                    2.652829                       1.071724   \n",
       "\n",
       "     concat_19k_v1_2_new_cosSim_Diff  concat_19k_v1_old_cosSim_Diff_Cat  \\\n",
       "0                           0.406729                                  0   \n",
       "1                           0.442771                                  0   \n",
       "2                           0.746952                                  1   \n",
       "3                           0.104396                                  0   \n",
       "4                           0.208946                                  0   \n",
       "..                               ...                                ...   \n",
       "339                         0.212787                                  0   \n",
       "340                         0.680935                                  1   \n",
       "341                         0.537611                                  0   \n",
       "342                         0.806941                                  1   \n",
       "343                         1.097171                                  1   \n",
       "\n",
       "     concat_19k_v1_2_new_cosSim_Diff_Cat  \n",
       "0                                      0  \n",
       "1                                      0  \n",
       "2                                      1  \n",
       "3                                      0  \n",
       "4                                      0  \n",
       "..                                   ...  \n",
       "339                                    0  \n",
       "340                                    1  \n",
       "341                                    1  \n",
       "342                                    1  \n",
       "343                                    1  \n",
       "\n",
       "[344 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "attractive-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "proof-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] == 0)].to_csv('../data/concEmb/good+good.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "elder-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] == 1)].to_csv('../data/concEmb/good+bad.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "magnetic-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] == 1) & (wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] == 0)].to_csv('../data/concEmb/bad+good.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "satisfied-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] == 1) & (wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] == 1)].to_csv('../data/concEmb/bad+bad.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-milan",
   "metadata": {},
   "source": [
    "# SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "adopted-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datacompy\n",
      "  Downloading datacompy-0.7.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /nas/home/kshenoy/miniconda3/lib/python3.8/site-packages (from datacompy) (1.20.1)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /nas/home/kshenoy/miniconda3/lib/python3.8/site-packages (from datacompy) (1.2.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /nas/home/kshenoy/miniconda3/lib/python3.8/site-packages (from pandas>=0.25.0->datacompy) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /nas/home/kshenoy/miniconda3/lib/python3.8/site-packages (from pandas>=0.25.0->datacompy) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /nas/home/kshenoy/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.25.0->datacompy) (1.15.0)\n",
      "Installing collected packages: datacompy\n",
      "Successfully installed datacompy-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datacompy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "overhead-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF = pd.read_csv('../data/wordsim353_all_embeddings_with_retrofits_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "looking-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF_old = pd.read_csv('../data/wordsim353_all_embeddings_with_retrofits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "interim-shirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>ID</th>\n",
       "      <th>H_Sim</th>\n",
       "      <th>H_Dim</th>\n",
       "      <th>F_Sim</th>\n",
       "      <th>F_Dim</th>\n",
       "      <th>N_Sim</th>\n",
       "      <th>N_Dim</th>\n",
       "      <th>D_Sim</th>\n",
       "      <th>...</th>\n",
       "      <th>concat_19k_v2_word1_new</th>\n",
       "      <th>concat_19k_v2_word2_new</th>\n",
       "      <th>concat_19k_v2_old_cosSim</th>\n",
       "      <th>concat_19k_v2_2_new_cosSim</th>\n",
       "      <th>concat_probase_19k_v2_word1_old</th>\n",
       "      <th>concat_probase_19k_v2_word2_old</th>\n",
       "      <th>concat_probase_19k_v2_word1_new</th>\n",
       "      <th>concat_probase_19k_v2_word2_new</th>\n",
       "      <th>concat_probase_19k_v2_old_cosSim</th>\n",
       "      <th>concat_probase_19k_v2_2_new_cosSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.006720443092017323, 0.008331487679612525, 0...</td>\n",
       "      <td>[-0.004515859576248157, -0.01172366887295375, ...</td>\n",
       "      <td>3.244539</td>\n",
       "      <td>3.175157</td>\n",
       "      <td>[0.006720440291834372, 0.008331484208161396, 0...</td>\n",
       "      <td>[-0.005011610937734838, -0.013383541550578623,...</td>\n",
       "      <td>[0.006720440291834372, 0.008331484208161396, 0...</td>\n",
       "      <td>[-0.00497129831746384, -0.01325426749683971, -...</td>\n",
       "      <td>3.244539</td>\n",
       "      <td>3.240270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.006720443092017323, 0.008331487679612525, 0...</td>\n",
       "      <td>[-0.004862257088069111, 0.014077170590128979, ...</td>\n",
       "      <td>3.085083</td>\n",
       "      <td>3.013958</td>\n",
       "      <td>[0.006720440291834372, 0.008331484208161396, 0...</td>\n",
       "      <td>[-0.005805280438126139, 0.015115419696749257, ...</td>\n",
       "      <td>[0.006720440291834372, 0.008331484208161396, 0...</td>\n",
       "      <td>[-0.004862255062129871, 0.014077164724644747, ...</td>\n",
       "      <td>3.085083</td>\n",
       "      <td>3.013958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.006466897059812569, 0.014694837542908411, -...</td>\n",
       "      <td>[0.01523113309590259, 0.005271417380511587, -0...</td>\n",
       "      <td>2.823093</td>\n",
       "      <td>2.745230</td>\n",
       "      <td>[0.006466894365273728, 0.014694831420063071, -...</td>\n",
       "      <td>[0.013922101136130544, 0.0023911842131386003, ...</td>\n",
       "      <td>[0.006466894365273728, 0.014694831420063071, -...</td>\n",
       "      <td>[0.013814564227839972, 0.0024352598952305004, ...</td>\n",
       "      <td>2.823093</td>\n",
       "      <td>2.816176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.006466897059812569, 0.014694837542908411, -...</td>\n",
       "      <td>[0.013016090623183913, 0.01114268771757639, -0...</td>\n",
       "      <td>2.920986</td>\n",
       "      <td>2.886161</td>\n",
       "      <td>[0.006466894365273728, 0.014694831420063071, -...</td>\n",
       "      <td>[0.01327496060589727, 0.010965634890657862, -0...</td>\n",
       "      <td>[0.006466894365273728, 0.014694831420063071, -...</td>\n",
       "      <td>[0.013242882546106787, 0.010953106196386554, -...</td>\n",
       "      <td>2.920986</td>\n",
       "      <td>2.919120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.01322626159341165, 0.005047111630696947, -0...</td>\n",
       "      <td>[0.010410829393995813, 0.014776997996557633, -...</td>\n",
       "      <td>1.707655</td>\n",
       "      <td>1.707655</td>\n",
       "      <td>[0.013226256082472592, 0.005047109527735016, -...</td>\n",
       "      <td>[0.010410825056152807, 0.014776991839478788, -...</td>\n",
       "      <td>[0.013226256082472592, 0.005047109527735016, -...</td>\n",
       "      <td>[0.010410825056152807, 0.014776991839478788, -...</td>\n",
       "      <td>1.707655</td>\n",
       "      <td>1.707655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word 1         Word 2   ID  H_Sim H_Dim  F_Sim F_Dim  N_Sim N_Dim  D_Sim  \\\n",
       "0   Arafat          peace    8      3     D      4   NaN      3     U      4   \n",
       "1   Arafat         terror    9      3     D      4   NaN      3     U      4   \n",
       "2      FBI    fingerprint  109      3     D      4   NaN      4   NaN      3   \n",
       "3      FBI  investigation  110      3     U      3     U      3     U      3   \n",
       "4  Harvard           Yale  137      2     S      3     S      2     S      2   \n",
       "\n",
       "   ...                            concat_19k_v2_word1_new  \\\n",
       "0  ...  [0.006720443092017323, 0.008331487679612525, 0...   \n",
       "1  ...  [0.006720443092017323, 0.008331487679612525, 0...   \n",
       "2  ...  [0.006466897059812569, 0.014694837542908411, -...   \n",
       "3  ...  [0.006466897059812569, 0.014694837542908411, -...   \n",
       "4  ...  [0.01322626159341165, 0.005047111630696947, -0...   \n",
       "\n",
       "                             concat_19k_v2_word2_new concat_19k_v2_old_cosSim  \\\n",
       "0  [-0.004515859576248157, -0.01172366887295375, ...                 3.244539   \n",
       "1  [-0.004862257088069111, 0.014077170590128979, ...                 3.085083   \n",
       "2  [0.01523113309590259, 0.005271417380511587, -0...                 2.823093   \n",
       "3  [0.013016090623183913, 0.01114268771757639, -0...                 2.920986   \n",
       "4  [0.010410829393995813, 0.014776997996557633, -...                 1.707655   \n",
       "\n",
       "   concat_19k_v2_2_new_cosSim  \\\n",
       "0                    3.175157   \n",
       "1                    3.013958   \n",
       "2                    2.745230   \n",
       "3                    2.886161   \n",
       "4                    1.707655   \n",
       "\n",
       "                     concat_probase_19k_v2_word1_old  \\\n",
       "0  [0.006720440291834372, 0.008331484208161396, 0...   \n",
       "1  [0.006720440291834372, 0.008331484208161396, 0...   \n",
       "2  [0.006466894365273728, 0.014694831420063071, -...   \n",
       "3  [0.006466894365273728, 0.014694831420063071, -...   \n",
       "4  [0.013226256082472592, 0.005047109527735016, -...   \n",
       "\n",
       "                     concat_probase_19k_v2_word2_old  \\\n",
       "0  [-0.005011610937734838, -0.013383541550578623,...   \n",
       "1  [-0.005805280438126139, 0.015115419696749257, ...   \n",
       "2  [0.013922101136130544, 0.0023911842131386003, ...   \n",
       "3  [0.01327496060589727, 0.010965634890657862, -0...   \n",
       "4  [0.010410825056152807, 0.014776991839478788, -...   \n",
       "\n",
       "                     concat_probase_19k_v2_word1_new  \\\n",
       "0  [0.006720440291834372, 0.008331484208161396, 0...   \n",
       "1  [0.006720440291834372, 0.008331484208161396, 0...   \n",
       "2  [0.006466894365273728, 0.014694831420063071, -...   \n",
       "3  [0.006466894365273728, 0.014694831420063071, -...   \n",
       "4  [0.013226256082472592, 0.005047109527735016, -...   \n",
       "\n",
       "                     concat_probase_19k_v2_word2_new  \\\n",
       "0  [-0.00497129831746384, -0.01325426749683971, -...   \n",
       "1  [-0.004862255062129871, 0.014077164724644747, ...   \n",
       "2  [0.013814564227839972, 0.0024352598952305004, ...   \n",
       "3  [0.013242882546106787, 0.010953106196386554, -...   \n",
       "4  [0.010410825056152807, 0.014776991839478788, -...   \n",
       "\n",
       "  concat_probase_19k_v2_old_cosSim concat_probase_19k_v2_2_new_cosSim  \n",
       "0                         3.244539                           3.240270  \n",
       "1                         3.085083                           3.013958  \n",
       "2                         2.823093                           2.816176  \n",
       "3                         2.920986                           2.919120  \n",
       "4                         1.707655                           1.707655  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "moderate-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacompy\n",
    "compare = datacompy.Compare(\n",
    "    wordSim353AnnotDF_New_Merged_DF[['word 1',\n",
    " 'word 2',\n",
    " 'avg',\n",
    " 'word1_kg_id',\n",
    " 'word2_kg_id',\n",
    " 'category'] + list(filter(lambda p: 'cossim' in p, wordSim353AnnotDF_New_Merged_DF.columns.to_list()))],\n",
    "    wordSim353AnnotDF_New_Merged_DF_old[['word 1',\n",
    " 'word 2',\n",
    " 'avg',\n",
    " 'word1_kg_id',\n",
    " 'word2_kg_id',\n",
    " 'category'] + list(filter(lambda p: 'cossim' in p, wordSim353AnnotDF_New_Merged_DF_old.columns.to_list()))],\n",
    "    join_columns = ['word 1', 'word 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "surprised-eight",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataComPy Comparison\n",
      "--------------------\n",
      "\n",
      "DataFrame Summary\n",
      "-----------------\n",
      "\n",
      "  DataFrame  Columns  Rows\n",
      "0       df1       34   346\n",
      "1       df2       34   344\n",
      "\n",
      "Column Summary\n",
      "--------------\n",
      "\n",
      "Number of columns in common: 32\n",
      "Number of columns in df1 but not in df2: 2\n",
      "Number of columns in df2 but not in df1: 2\n",
      "\n",
      "Row Summary\n",
      "-----------\n",
      "\n",
      "Matched on: word 1, word 2\n",
      "Any duplicates on match values: Yes\n",
      "Absolute Tolerance: 0\n",
      "Relative Tolerance: 0\n",
      "Number of rows in common: 344\n",
      "Number of rows in df1 but not in df2: 2\n",
      "Number of rows in df2 but not in df1: 0\n",
      "\n",
      "Number of rows with some compared columns unequal: 343\n",
      "Number of rows with all compared columns equal: 1\n",
      "\n",
      "Column Comparison\n",
      "-----------------\n",
      "\n",
      "Number of columns compared with some values unequal: 27\n",
      "Number of columns compared with all values equal: 5\n",
      "Total number of values which compare unequal: 5,136\n",
      "\n",
      "Columns with Unequal Values or Types\n",
      "------------------------------------\n",
      "\n",
      "                                 Column df1 dtype df2 dtype  # Unequal      Max Diff  # Null Diff\n",
      "25            abstract_19k_2_new_cossim   float64   float64          8  4.440892e-16            0\n",
      "17              abstract_19k_old_cossim   float64   float64          9  4.440892e-16            0\n",
      "8   abstract_firstsent_19k_2_new_cossim   float64   float64          8  4.440892e-16            0\n",
      "19    abstract_firstsent_19k_old_cossim   float64   float64          8  4.440892e-16            0\n",
      "6                              category    object    object          4  0.000000e+00            0\n",
      "12               complex_19k_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "21       complex_probase_19k_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "11         complex_probase_2_new_cossim   float64   float64          8  4.440892e-16            0\n",
      "18           complex_probase_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "1            concat_19k_v1_2_new_cossim   float64   float64        343  9.656675e-01            0\n",
      "22             concat_19k_v1_old_cossim   float64   float64        343  9.684394e-01            0\n",
      "2            concat_19k_v2_2_new_cossim   float64   float64        325  4.810998e-01            0\n",
      "3              concat_19k_v2_old_cossim   float64   float64        324  4.842197e-01            0\n",
      "10   concat_probase_19k_v1_2_new_cossim   float64   float64        341  9.673423e-01            0\n",
      "7      concat_probase_19k_v1_old_cossim   float64   float64        343  9.684394e-01            0\n",
      "26   concat_probase_19k_v2_2_new_cossim   float64   float64        324  4.828636e-01            0\n",
      "9      concat_probase_19k_v2_old_cossim   float64   float64        324  4.842197e-01            0\n",
      "15         text_2props_19k_2_new_cossim   float64   float64          7  4.440892e-16            0\n",
      "0            text_2props_19k_old_cossim   float64   float64          5  4.440892e-16            0\n",
      "14         text_7props_19k_2_new_cossim   float64   float64         11  4.440892e-16            0\n",
      "24           text_7props_19k_old_cossim   float64   float64          7  4.440892e-16            0\n",
      "5               transe_19k_1_new_cossim   float64   float64          5  4.440892e-16            0\n",
      "4                 transe_19k_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "16      transe_probase_19k_1_new_cossim   float64   float64        340  1.192889e-08            0\n",
      "20        transe_probase_19k_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "23          transe_probase_1_new_cossim   float64   float64          9  4.440892e-16            0\n",
      "13            transe_probase_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "\n",
      "Sample Rows with Unequal Values\n",
      "-------------------------------\n",
      "\n",
      "           word 1       word 2  text_2props_19k_old_cossim (df1)  text_2props_19k_old_cossim (df2)\n",
      "170        credit         card                          1.834364                          1.834364\n",
      "204         drink          ear                          2.515900                          2.515900\n",
      "143  registration  arrangement                          1.826611                          1.826611\n",
      "160        bishop        rabbi                          2.333195                          2.333195\n",
      "48           line    insurance                          2.670612                          2.670612\n",
      "\n",
      "           word 1       word 2  concat_19k_v1_2_new_cossim (df1)  concat_19k_v1_2_new_cossim (df2)\n",
      "67          money       wealth                          2.594056                          2.324713\n",
      "68          money         bank                          2.659692                          2.472590\n",
      "76            car       flight                          3.064250                          2.948899\n",
      "304           cup         food                          3.048451                          2.740541\n",
      "247       century       nation                          2.896171                          2.916821\n",
      "206         drink        mouth                          3.185446                          2.656735\n",
      "4    championship   tournament                          2.078515                          2.124749\n",
      "60          opera  performance                          3.230684                          3.163359\n",
      "148   development        issue                          2.128967                          2.203126\n",
      "94      territory      surface                          3.215735                          2.642104\n",
      "\n",
      "          word 1       word 2  concat_19k_v2_2_new_cossim (df1)  concat_19k_v2_2_new_cossim (df2)\n",
      "30         stock          egg                          2.847432                          2.851658\n",
      "217        image      surface                          2.811049                          2.849672\n",
      "144    volunteer        motto                          2.876196                          2.876781\n",
      "257  calculation  computation                          1.805635                          1.840498\n",
      "161         life         term                          2.894241                          3.090963\n",
      "26       theater      history                          2.771044                          2.665424\n",
      "298      listing     category                          2.946733                          2.775793\n",
      "197       doctor    liability                          3.166078                          2.991543\n",
      "76           car       flight                          2.858563                          2.800924\n",
      "93       concert     virtuoso                          2.547705                          2.584726\n",
      "\n",
      "        word 1      word 2  concat_19k_v2_old_cossim (df1)  concat_19k_v2_old_cossim (df2)\n",
      "206      drink       mouth                        2.773593                        2.530386\n",
      "227     dollar         yen                        2.087983                        2.008970\n",
      "20       movie     popcorn                        3.311935                        3.258708\n",
      "79     alcohol   chemistry                        2.906985                        2.879210\n",
      "68       money        bank                        2.261778                        2.170577\n",
      "5      brother        monk                        2.898300                        2.885898\n",
      "244        day        dawn                        2.534123                        2.479610\n",
      "95   territory   kilometer                        2.971132                        2.876901\n",
      "220   morality  importance                        2.272562                        2.446757\n",
      "145       mile   kilometer                        1.745435                        1.754050\n",
      "\n",
      "        word 1      word 2  transe_19k_old_cossim (df1)  transe_19k_old_cossim (df2)\n",
      "274   computer    software                     2.565704                     2.726328\n",
      "226     dollar      profit                     3.304597                     2.980368\n",
      "146     reason   criterion                     2.613928                     2.658933\n",
      "52     attempt       peace                     3.261064                     2.864466\n",
      "38        king     cabbage                     3.215956                     3.158342\n",
      "45   Jerusalem      Israel                     3.234195                     2.342065\n",
      "289     nature         man                     3.436439                     2.786551\n",
      "3         skin         eye                     2.542363                     2.497693\n",
      "260     planet  astronomer                     3.539713                     2.584489\n",
      "87    Maradona    football                     3.030156                     3.701092\n",
      "\n",
      "           word 1       word 2  transe_19k_1_new_cossim (df1)  transe_19k_1_new_cossim (df2)\n",
      "261        planet       people                       3.716617                       3.716617\n",
      "12         energy    secretary                       2.865451                       2.865451\n",
      "143  registration  arrangement                       1.933719                       1.933719\n",
      "293        street        block                       2.904156                       2.904156\n",
      "71          money      deposit                       2.837495                       2.837495\n",
      "\n",
      "       word 1       word 2 category (df1) category (df2)\n",
      "195      tool    implement              I              M\n",
      "33      stock           CD              U              M\n",
      "178  practice  institution              M              U\n",
      "292      cell        phone              I              M\n",
      "\n",
      "         word 1   word 2  concat_probase_19k_v1_old_cossim (df1)  concat_probase_19k_v1_old_cossim (df2)\n",
      "283    minority    peace                                3.204190                                3.038929\n",
      "266       focus     life                                3.119772                                3.283904\n",
      "6        report     gain                                3.961394                                3.738704\n",
      "45    Jerusalem   Israel                                2.978292                                2.383538\n",
      "19        movie  theater                                3.142667                                2.827856\n",
      "138        bank    money                                2.669802                                2.487401\n",
      "338  psychology     mind                                2.554919                                2.247923\n",
      "16         game   series                                2.841292                                2.739770\n",
      "328       coast     hill                                3.416477                                2.800309\n",
      "157        wood   forest                                3.144257                                2.612681\n",
      "\n",
      "         word 1     word 2  abstract_firstsent_19k_2_new_cossim (df1)  abstract_firstsent_19k_2_new_cossim (df2)\n",
      "337  psychology       fear                                   2.679016                                   2.679016\n",
      "237    investor    earning                                   1.998387                                   1.998387\n",
      "258     country    citizen                                   2.307399                                   2.307399\n",
      "189       vodka        gin                                   1.848263                                   1.848263\n",
      "137         oil      stock                                   2.875288                                   2.875288\n",
      "50    discovery      space                                   2.952799                                   2.952799\n",
      "19        movie    theater                                   2.390347                                   2.390347\n",
      "54   deployment  departure                                   1.826386                                   1.826386\n",
      "\n",
      "            word 1       word 2  concat_probase_19k_v2_old_cossim (df1)  concat_probase_19k_v2_old_cossim (df2)\n",
      "96          victim    emergency                                2.386991                                2.451999\n",
      "126  investigation       effort                                2.433542                                2.365526\n",
      "237       investor      earning                                2.568087                                2.553099\n",
      "243           book      library                                2.568339                                2.180713\n",
      "140       consumer   confidence                                2.645215                                2.694362\n",
      "227         dollar          yen                                2.087983                                2.008970\n",
      "299      secretary       senate                                2.716612                                2.726418\n",
      "100      precedent  information                                2.862093                                2.806086\n",
      "247        century       nation                                3.025727                                3.021246\n",
      "173           love          sex                                2.429363                                2.471889\n",
      "\n",
      "         word 1      word 2  concat_probase_19k_v1_2_new_cossim (df1)  concat_probase_19k_v1_2_new_cossim (df2)\n",
      "68        money        bank                                  2.667501                                  2.484540\n",
      "160      bishop       rabbi                                  2.281893                                  2.632298\n",
      "310         cup      coffee                                  2.832361                                  2.556135\n",
      "263      planet        moon                                  2.530613                                  2.184833\n",
      "281  production        hike                                  2.662743                                  2.755305\n",
      "345        baby      mother                                  2.434417                                  2.342222\n",
      "319      family    planning                                  3.217886                                  3.085772\n",
      "165         lad     brother                                  2.885448                                  2.868957\n",
      "93      concert    virtuoso                                  3.224431                                  3.179484\n",
      "74        money  withdrawal                                  3.105806                                  2.802084\n",
      "\n",
      "           word 1      word 2  complex_probase_2_new_cossim (df1)  complex_probase_2_new_cossim (df2)\n",
      "171  impartiality    interest                            2.323327                            2.323327\n",
      "339    psychology  psychiatry                            1.826092                            1.826092\n",
      "225        dollar        buck                            2.733086                            2.733086\n",
      "342        Mexico      Brazil                            1.921104                            1.921104\n",
      "287         bread      butter                            1.926594                            1.926594\n",
      "70          money      dollar                            2.733086                            2.733086\n",
      "183        Arafat      terror                            3.103668                            3.103668\n",
      "248      Japanese    American                            2.408249                            2.408249\n",
      "\n",
      "       word 1       word 2  complex_19k_old_cossim (df1)  complex_19k_old_cossim (df2)\n",
      "79    alcohol    chemistry                      3.176835                      3.093510\n",
      "196  cemetery     woodland                      3.520304                      3.065562\n",
      "21      movie         star                      3.837976                      3.932198\n",
      "178  practice  institution                      3.327239                      2.809190\n",
      "293    street        block                      3.234272                      2.501191\n",
      "286      OPEC      country                      2.995334                      3.035374\n",
      "258   country      citizen                      3.875955                      2.677162\n",
      "264    planet         star                      2.586230                      2.320493\n",
      "295    street       avenue                      2.832952                      1.925452\n",
      "212    forest    graveyard                      3.320053                      2.661537\n",
      "\n",
      "         word 1      word 2  transe_probase_old_cossim (df1)  transe_probase_old_cossim (df2)\n",
      "197      doctor   liability                         3.659816                         3.123944\n",
      "234       start        year                         3.245463                         2.958541\n",
      "326       coast      forest                         3.334863                         2.824467\n",
      "38         king     cabbage                         3.215956                         3.158342\n",
      "194      school      center                         3.932067                         3.469016\n",
      "306         cup      entity                         3.153058                         2.423347\n",
      "339  psychology  psychiatry                         2.015927                         1.835693\n",
      "333  psychology   cognition                         2.691795                         2.200548\n",
      "118       tiger      animal                         2.880296                         2.335659\n",
      "254     lobster        wine                         3.406161                         2.862333\n",
      "\n",
      "        word 1      word 2  text_7props_19k_2_new_cossim (df1)  text_7props_19k_2_new_cossim (df2)\n",
      "222   governor   interview                            2.651640                            2.651640\n",
      "48        line   insurance                            2.691916                            2.691916\n",
      "1        space       world                            2.109041                            2.109041\n",
      "7       luxury         car                            2.942098                            2.942098\n",
      "237   investor     earning                            1.902240                            1.902240\n",
      "258    country     citizen                            1.942392                            1.942392\n",
      "31       stock       phone                            2.963663                            2.963663\n",
      "55      summer     drought                            2.687325                            2.687325\n",
      "104  precedent  antecedent                            1.844509                            1.844509\n",
      "140   consumer  confidence                            2.239074                            2.239074\n",
      "\n",
      "           word 1      word 2  text_2props_19k_2_new_cossim (df1)  text_2props_19k_2_new_cossim (df2)\n",
      "87       Maradona    football                            2.351065                            2.351065\n",
      "1           space       world                            1.993016                            1.993016\n",
      "342        Mexico      Brazil                            1.950233                            1.950233\n",
      "241  announcement  production                            1.866451                            1.866451\n",
      "12         energy   secretary                            2.803514                            2.803514\n",
      "268      fighting   defeating                            1.940122                            1.940122\n",
      "325         train         car                            1.998965                            1.998965\n",
      "\n",
      "           word 1      word 2  transe_probase_19k_1_new_cossim (df1)  transe_probase_19k_1_new_cossim (df2)\n",
      "200         death         row                               2.710230                               2.710230\n",
      "241  announcement  production                               2.203522                               2.203522\n",
      "75            car  automobile                               1.000000                               1.000000\n",
      "25         change    attitude                               2.033291                               2.033291\n",
      "168     president       medal                               3.076084                               3.076084\n",
      "339    psychology  psychiatry                               1.720621                               1.720621\n",
      "262        planet      galaxy                               1.905751                               1.905751\n",
      "227        dollar         yen                               1.923429                               1.923429\n",
      "34          stock      jaguar                               2.580758                               2.580758\n",
      "223      governor      office                               2.480715                               2.480715\n",
      "\n",
      "         word 1      word 2  abstract_19k_old_cossim (df1)  abstract_19k_old_cossim (df2)\n",
      "286        OPEC     country                       3.042327                       3.042327\n",
      "155    football      tennis                       2.518421                       2.518421\n",
      "295      street      avenue                       2.281843                       2.281843\n",
      "166         lad      wizard                       3.334772                       3.334772\n",
      "248    Japanese    American                       3.292768                       3.292768\n",
      "180       media     trading                       3.108796                       3.108796\n",
      "40   disability       death                       2.746255                       2.746255\n",
      "263      planet        moon                       1.920149                       1.920149\n",
      "132   situation  conclusion                       1.808156                       1.808156\n",
      "\n",
      "      word 1       word 2  complex_probase_old_cossim (df1)  complex_probase_old_cossim (df2)\n",
      "230     bird         cock                          2.481055                          2.343609\n",
      "325    train          car                          2.864601                          2.477597\n",
      "209  physics       proton                          3.802075                          2.800635\n",
      "115    tiger       feline                          2.593871                          2.486227\n",
      "67     money       wealth                          3.063866                          2.657174\n",
      "297  listing    proximity                          2.814837                          2.606451\n",
      "7     luxury          car                          3.150901                          2.977136\n",
      "295   street       avenue                          2.832952                          1.925452\n",
      "190  hundred      percent                          2.493823                          2.563090\n",
      "192   chance  credibility                          2.291870                          2.505301\n",
      "\n",
      "           word 1      word 2  abstract_firstsent_19k_old_cossim (df1)  abstract_firstsent_19k_old_cossim (df2)\n",
      "248      Japanese    American                                 2.728319                                 2.728319\n",
      "40     disability       death                                 3.016865                                 3.016865\n",
      "132     situation  conclusion                                 1.808156                                 1.808156\n",
      "77   preservation       world                                 3.234863                                 3.234863\n",
      "80       magician      wizard                                 1.909871                                 1.909871\n",
      "172         lover     quarrel                                 3.157233                                 3.157233\n",
      "205         drink      mother                                 3.128050                                 3.128050\n",
      "270     precedent         law                                 1.878214                                 1.878214\n",
      "\n",
      "           word 1       word 2  transe_probase_19k_old_cossim (df1)  transe_probase_19k_old_cossim (df2)\n",
      "113         tiger        tiger                             1.000000                             1.000000\n",
      "207      marathon       sprint                             2.798142                             2.347854\n",
      "263        planet         moon                             2.892147                             2.372832\n",
      "344         video      archive                             3.219152                             2.407191\n",
      "322        tennis       racket                             3.036550                             2.602735\n",
      "36        exhibit  memorabilia                             2.675041                             2.932891\n",
      "77   preservation        world                             2.716450                             2.483704\n",
      "151        profit      warning                             2.433602                             2.363151\n",
      "162          life       lesson                             2.747317                             2.699579\n",
      "243          book      library                             3.701910                             2.539030\n",
      "\n",
      "         word 1      word 2  complex_probase_19k_old_cossim (df1)  complex_probase_19k_old_cossim (df2)\n",
      "70        money      dollar                              2.565087                              2.748494\n",
      "175        size  prominence                              2.326263                              2.939136\n",
      "78       canyon   landscape                              3.173792                              2.564538\n",
      "251     journey      voyage                              2.338671                              2.527748\n",
      "72        money        cash                              2.256395                              1.954309\n",
      "311         cup   tableware                              2.124012                              1.954043\n",
      "32        stock        life                              2.786081                              3.267855\n",
      "281  production        hike                              2.530452                              2.673632\n",
      "206       drink       mouth                              3.561134                              2.831515\n",
      "321         man    governor                              3.873069                              3.169743\n",
      "\n",
      "        word 1    word 2  concat_19k_v1_old_cossim (df1)  concat_19k_v1_old_cossim (df2)\n",
      "168  president     medal                        3.240338                        3.700159\n",
      "211        bed    closet                        2.695093                        2.548202\n",
      "254    lobster      wine                        3.459359                        3.096807\n",
      "207   marathon    sprint                        2.856164                        2.555972\n",
      "218     gender  equality                        2.786607                        2.746860\n",
      "98     network  hardware                        2.800852                        2.471308\n",
      "160     bishop     rabbi                        2.287452                        2.650377\n",
      "128      delay    racism                        3.037041                        2.943246\n",
      "253    lobster      food                        2.919241                        2.752955\n",
      "56      summer    nature                        2.934935                        2.693939\n",
      "\n",
      "           word 1    word 2  transe_probase_1_new_cossim (df1)  transe_probase_1_new_cossim (df2)\n",
      "239  announcement   warning                           1.930855                           1.930855\n",
      "304           cup      food                           2.657233                           2.657233\n",
      "221      morality  marriage                           2.173908                           2.173908\n",
      "309           cup  artifact                           2.065621                           2.065621\n",
      "203         drink       eat                           2.334188                           2.334188\n",
      "334    psychology   science                           1.840069                           1.840069\n",
      "174        boxing     round                           3.527058                           3.527058\n",
      "261        planet    people                           3.392578                           3.392578\n",
      "52        attempt     peace                           2.624155                           2.624155\n",
      "\n",
      "         word 1         word 2  text_7props_19k_old_cossim (df1)  text_7props_19k_old_cossim (df2)\n",
      "336  psychology     depression                          1.948810                          1.948810\n",
      "344       video        archive                          1.948662                          1.948662\n",
      "170      credit           card                          1.834364                          1.834364\n",
      "22        movie         critic                          2.872865                          2.872865\n",
      "8     telephone  communication                          2.269291                          2.269291\n",
      "25       change       attitude                          1.894075                          1.894075\n",
      "274    computer       software                          1.918968                          1.918968\n",
      "\n",
      "          word 1        word 2  abstract_19k_2_new_cossim (df1)  abstract_19k_2_new_cossim (df2)\n",
      "245          day        summer                         1.820569                         1.820569\n",
      "100    precedent   information                         2.768309                         2.768309\n",
      "271     computer      keyboard                         1.977226                         1.977226\n",
      "191     disaster          area                         3.350219                         3.350219\n",
      "54    deployment     departure                         1.826386                         1.826386\n",
      "43     professor        doctor                         2.462181                         2.462181\n",
      "323    admission        ticket                         2.890691                         2.890691\n",
      "109  observation  architecture                         2.541219                         2.541219\n",
      "\n",
      "         word 1     word 2  concat_probase_19k_v2_2_new_cossim (df1)  concat_probase_19k_v2_2_new_cossim (df2)\n",
      "317       smart     stupid                                  2.682869                                  2.607989\n",
      "263      planet       moon                                  2.255580                                  2.082990\n",
      "7        luxury        car                                  3.044579                                  2.986149\n",
      "128       delay     racism                                  3.152806                                  3.106165\n",
      "167         boy        lad                                  1.000000                                  1.000000\n",
      "108     seafood    lobster                                  1.997874                                  1.955596\n",
      "197      doctor  liability                                  3.199142                                  3.020511\n",
      "144   volunteer      motto                                  2.913664                                  2.915718\n",
      "158  television       film                                  2.567072                                  2.340704\n",
      "323   admission     ticket                                  2.659475                                  2.743919\n",
      "\n",
      "Sample Rows Only in df1 (First 10 Columns)\n",
      "------------------------------------------\n",
      "\n",
      "   word 1      word 2  avg word1_kg_id word2_kg_id category  text_7props_19k_old_cossim  text_7props_19k_2_new_cossim  text_2props_19k_old_cossim  text_2props_19k_2_new_cossim\n",
      "65  money    property  3.0       Q1368    Q1400881        M                    1.974774                      1.963229                    1.948088                      1.935276\n",
      "63  money  possession  3.6       Q1368    Q1400881        U                    1.974774                      1.963229                    1.948088                      1.935276\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(compare.report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "common-vietnam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1_kg_id</th>\n",
       "      <th>word2_kg_id</th>\n",
       "      <th>word 1</th>\n",
       "      <th>word 2</th>\n",
       "      <th>id</th>\n",
       "      <th>h_sim</th>\n",
       "      <th>h_dim</th>\n",
       "      <th>f_sim</th>\n",
       "      <th>f_dim</th>\n",
       "      <th>n_sim</th>\n",
       "      <th>...</th>\n",
       "      <th>concat_19k_v2_word2_new</th>\n",
       "      <th>concat_19k_v2_old_cossim</th>\n",
       "      <th>concat_19k_v2_2_new_cossim</th>\n",
       "      <th>concat_probase_19k_v2_word1_old</th>\n",
       "      <th>concat_probase_19k_v2_word2_old</th>\n",
       "      <th>concat_probase_19k_v2_word1_new</th>\n",
       "      <th>concat_probase_19k_v2_word2_new</th>\n",
       "      <th>concat_probase_19k_v2_old_cossim</th>\n",
       "      <th>concat_probase_19k_v2_2_new_cossim</th>\n",
       "      <th>avg_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q106106</td>\n",
       "      <td>Q11460</td>\n",
       "      <td>closet</td>\n",
       "      <td>clothes</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0014151543049584102, 0.003161483781535701, ...</td>\n",
       "      <td>2.697022</td>\n",
       "      <td>2.652559</td>\n",
       "      <td>[0.013902607489678993, 0.013241494756981564, -...</td>\n",
       "      <td>[0.0014224480432097992, 0.0031547764732941653,...</td>\n",
       "      <td>[0.01371531560905985, 0.013126875633706597, -0...</td>\n",
       "      <td>[0.0014206775968733409, 0.0031581452887393872,...</td>\n",
       "      <td>2.697022</td>\n",
       "      <td>2.683318</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q107</td>\n",
       "      <td>Q16502</td>\n",
       "      <td>space</td>\n",
       "      <td>world</td>\n",
       "      <td>293</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.0031782974877087693, 0.003973805776938075,...</td>\n",
       "      <td>2.485859</td>\n",
       "      <td>2.347308</td>\n",
       "      <td>[0.00027019944749503126, 0.005353652289998999,...</td>\n",
       "      <td>[-0.0032792710227188605, 0.0036472880832864947...</td>\n",
       "      <td>[0.00027492382990721006, 0.0053545622809597, -...</td>\n",
       "      <td>[-0.0032450374860671267, 0.0036673577053825254...</td>\n",
       "      <td>2.485859</td>\n",
       "      <td>2.481352</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q107</td>\n",
       "      <td>Q2329</td>\n",
       "      <td>space</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>292</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.015268952851071075, -0.0024137893437008715,...</td>\n",
       "      <td>2.798788</td>\n",
       "      <td>2.782963</td>\n",
       "      <td>[0.00027019944749503126, 0.005353652289998999,...</td>\n",
       "      <td>[0.015322423107720673, -0.0024500099720118624,...</td>\n",
       "      <td>[0.00027492382990721006, 0.0053545622809597, -...</td>\n",
       "      <td>[0.015281665873653082, -0.002421165402091456, ...</td>\n",
       "      <td>2.798788</td>\n",
       "      <td>2.795047</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1074</td>\n",
       "      <td>Q7364</td>\n",
       "      <td>skin</td>\n",
       "      <td>eye</td>\n",
       "      <td>288</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.002992664951436964, 0.013922942027531155, -...</td>\n",
       "      <td>2.355813</td>\n",
       "      <td>2.314417</td>\n",
       "      <td>[-0.0026976204618851985, 0.001541600665881322,...</td>\n",
       "      <td>[0.0033640181667058486, 0.014044398230441645, ...</td>\n",
       "      <td>[-0.002678224125439186, 0.0015598357892553907,...</td>\n",
       "      <td>[0.0033484286344994184, 0.014002864550517797, ...</td>\n",
       "      <td>2.355813</td>\n",
       "      <td>2.350603</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1079023</td>\n",
       "      <td>Q500834</td>\n",
       "      <td>championship</td>\n",
       "      <td>tournament</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.00920825730356781, 0.011965374832474578, 0....</td>\n",
       "      <td>1.868699</td>\n",
       "      <td>1.865663</td>\n",
       "      <td>[-0.0008601077391385219, 0.005201185839222482,...</td>\n",
       "      <td>[0.00923153244996602, 0.011960544533439752, 0....</td>\n",
       "      <td>[-0.0008458279784483333, 0.005209858282773185,...</td>\n",
       "      <td>[0.009207264410626997, 0.011951895965764294, 0...</td>\n",
       "      <td>1.868699</td>\n",
       "      <td>1.866785</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  word1_kg_id word2_kg_id        word 1      word 2   id  h_sim h_dim  f_sim  \\\n",
       "0     Q106106      Q11460        closet     clothes   42      3     H      3   \n",
       "1        Q107      Q16502         space       world  293      3     L      3   \n",
       "2        Q107       Q2329         space   chemistry  292      4   NaN      4   \n",
       "3       Q1074       Q7364          skin         eye  288      3     H      3   \n",
       "4    Q1079023     Q500834  championship  tournament   38      1   NaN      1   \n",
       "\n",
       "  f_dim  n_sim  ...                            concat_19k_v2_word2_new  \\\n",
       "0     H      3  ...  [0.0014151543049584102, 0.003161483781535701, ...   \n",
       "1     S      3  ...  [-0.0031782974877087693, 0.003973805776938075,...   \n",
       "2   NaN      4  ...  [0.015268952851071075, -0.0024137893437008715,...   \n",
       "3     H      3  ...  [0.002992664951436964, 0.013922942027531155, -...   \n",
       "4   NaN      2  ...  [0.00920825730356781, 0.011965374832474578, 0....   \n",
       "\n",
       "   concat_19k_v2_old_cossim concat_19k_v2_2_new_cossim  \\\n",
       "0                  2.697022                   2.652559   \n",
       "1                  2.485859                   2.347308   \n",
       "2                  2.798788                   2.782963   \n",
       "3                  2.355813                   2.314417   \n",
       "4                  1.868699                   1.865663   \n",
       "\n",
       "                     concat_probase_19k_v2_word1_old  \\\n",
       "0  [0.013902607489678993, 0.013241494756981564, -...   \n",
       "1  [0.00027019944749503126, 0.005353652289998999,...   \n",
       "2  [0.00027019944749503126, 0.005353652289998999,...   \n",
       "3  [-0.0026976204618851985, 0.001541600665881322,...   \n",
       "4  [-0.0008601077391385219, 0.005201185839222482,...   \n",
       "\n",
       "                     concat_probase_19k_v2_word2_old  \\\n",
       "0  [0.0014224480432097992, 0.0031547764732941653,...   \n",
       "1  [-0.0032792710227188605, 0.0036472880832864947...   \n",
       "2  [0.015322423107720673, -0.0024500099720118624,...   \n",
       "3  [0.0033640181667058486, 0.014044398230441645, ...   \n",
       "4  [0.00923153244996602, 0.011960544533439752, 0....   \n",
       "\n",
       "                     concat_probase_19k_v2_word1_new  \\\n",
       "0  [0.01371531560905985, 0.013126875633706597, -0...   \n",
       "1  [0.00027492382990721006, 0.0053545622809597, -...   \n",
       "2  [0.00027492382990721006, 0.0053545622809597, -...   \n",
       "3  [-0.002678224125439186, 0.0015598357892553907,...   \n",
       "4  [-0.0008458279784483333, 0.005209858282773185,...   \n",
       "\n",
       "                     concat_probase_19k_v2_word2_new  \\\n",
       "0  [0.0014206775968733409, 0.0031581452887393872,...   \n",
       "1  [-0.0032450374860671267, 0.0036673577053825254...   \n",
       "2  [0.015281665873653082, -0.002421165402091456, ...   \n",
       "3  [0.0033484286344994184, 0.014002864550517797, ...   \n",
       "4  [0.009207264410626997, 0.011951895965764294, 0...   \n",
       "\n",
       "   concat_probase_19k_v2_old_cossim  concat_probase_19k_v2_2_new_cossim  \\\n",
       "0                          2.697022                            2.683318   \n",
       "1                          2.485859                            2.481352   \n",
       "2                          2.798788                            2.795047   \n",
       "3                          2.355813                            2.350603   \n",
       "4                          1.868699                            1.866785   \n",
       "\n",
       "  avg_old  \n",
       "0     3.0  \n",
       "1     3.2  \n",
       "2     4.0  \n",
       "3     3.0  \n",
       "4     1.2  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "rising-platform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20519776]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(np.array([float(val1) for val1 in wordSim353AnnotDF_New_Merged_DF.iloc[0]['concat_19k_v2_word1_new'][1:-1].split(\",\")]).reshape(1,-1), np.array([float(val1) for val1 in wordSim353AnnotDF_New_Merged_DF.iloc[0]['concat_19k_v2_word2_new'][1:-1].split(\",\")]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "governing-offer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Word 1', 'Word 2', 'ID', 'H_Sim', 'H_Dim', 'F_Sim', 'F_Dim', 'N_Sim',\n",
       "       'N_Dim', 'D_Sim',\n",
       "       ...\n",
       "       'concat_19k_v2_word1_new', 'concat_19k_v2_word2_new',\n",
       "       'concat_19k_v2_old_cosSim', 'concat_19k_v2_2_new_cosSim',\n",
       "       'concat_probase_19k_v2_word1_old', 'concat_probase_19k_v2_word2_old',\n",
       "       'concat_probase_19k_v2_word1_new', 'concat_probase_19k_v2_word2_new',\n",
       "       'concat_probase_19k_v2_old_cosSim',\n",
       "       'concat_probase_19k_v2_2_new_cosSim'],\n",
       "      dtype='object', length=104)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "rough-february",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_7props_19k_old_cosSim',\n",
       " 'text_7props_19k_2_new_cosSim',\n",
       " 'text_2props_19k_old_cosSim',\n",
       " 'text_2props_19k_2_new_cosSim',\n",
       " 'complex_19k_old_cosSim',\n",
       " 'complex_19k_2_new_cosSim',\n",
       " 'transe_19k_old_cosSim',\n",
       " 'transe_19k_1_new_cosSim',\n",
       " 'abstract_19k_old_cosSim',\n",
       " 'abstract_19k_2_new_cosSim',\n",
       " 'abstract_firstSent_19k_old_cosSim',\n",
       " 'abstract_firstSent_19k_2_new_cosSim',\n",
       " 'complex_probase_old_cosSim',\n",
       " 'complex_probase_2_new_cosSim',\n",
       " 'transe_probase_old_cosSim',\n",
       " 'transe_probase_1_new_cosSim',\n",
       " 'complex_probase_19k_old_cosSim',\n",
       " 'complex_probase_19k_2_new_cosSim',\n",
       " 'transe_probase_19k_old_cosSim',\n",
       " 'transe_probase_19k_1_new_cosSim',\n",
       " 'concat_19k_v1_old_cosSim',\n",
       " 'concat_19k_v1_2_new_cosSim',\n",
       " 'concat_probase_19k_v1_old_cosSim',\n",
       " 'concat_probase_19k_v1_2_new_cosSim',\n",
       " 'concat_19k_v2_old_cosSim',\n",
       " 'concat_19k_v2_2_new_cosSim',\n",
       " 'concat_probase_19k_v2_old_cosSim',\n",
       " 'concat_probase_19k_v2_2_new_cosSim']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda p: 'cosSim' in p, wordSim353AnnotDF_New_Merged_DF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "hired-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "extraordinary-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_pairs = [('text_7props_19k', 'text_7props_19k_2'),\n",
    "             ('text_2props_19k', 'text_2props_19k_2'),\n",
    "             ('complex_19k', 'complex_19k_2'),\n",
    "             ('transe_19k', 'transe_19k_1'),\n",
    "             ('abstract_19k', 'abstract_19k_2'),\n",
    "             ('abstract_firstSent_19k', 'abstract_firstSent_19k_2'),\n",
    "             ('complex_probase', 'complex_probase_2'),\n",
    "             ('transe_probase', 'transe_probase_1'),\n",
    "             ('complex_probase_19k', 'complex_probase_19k_2'),\n",
    "             ('transe_probase_19k', 'transe_probase_19k_1'),\n",
    "             ('concat_19k_v1', 'concat_19k_v1_2'),\n",
    "             ('concat_probase_19k_v1', 'concat_probase_19k_v1_2'),\n",
    "             ('concat_19k_v2', 'concat_19k_v2_2'),\n",
    "             ('concat_probase_19k_v2', 'concat_probase_19k_v2_2')]\n",
    "colMappers = {p[0]+'_old_cosSim': p[1]+'_new_cosSim' for p in emb_pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "political-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldColList = list(filter(lambda p: 'old_cosSim' in p, wordSim353AnnotDF_New_Merged_DF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "flexible-booking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_7props_19k_old_cosSim',\n",
       " 'text_2props_19k_old_cosSim',\n",
       " 'complex_19k_old_cosSim',\n",
       " 'transe_19k_old_cosSim',\n",
       " 'abstract_19k_old_cosSim',\n",
       " 'abstract_firstSent_19k_old_cosSim',\n",
       " 'complex_probase_old_cosSim',\n",
       " 'transe_probase_old_cosSim',\n",
       " 'complex_probase_19k_old_cosSim',\n",
       " 'transe_probase_19k_old_cosSim',\n",
       " 'concat_19k_v1_old_cosSim',\n",
       " 'concat_probase_19k_v1_old_cosSim',\n",
       " 'concat_19k_v2_old_cosSim',\n",
       " 'concat_probase_19k_v2_old_cosSim']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldColList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "radio-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "recent-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oldColList, [colMappers[col] for col in oldColList]\n",
    "t1234 = []\n",
    "t4567 = []\n",
    "for col in oldColList:\n",
    "    t1234.append(accuracy_score(wordSim353AnnotDF_New_Merged_DF.Avg.apply(labelSamples), wordSim353AnnotDF_New_Merged_DF[col].apply(labelSamples)))\n",
    "    t4567.append(accuracy_score(wordSim353AnnotDF_New_Merged_DF.Avg.apply(labelSamples), wordSim353AnnotDF_New_Merged_DF[colMappers[col]].apply(labelSamples)))\n",
    "                 \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "opening-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1234 = list(zip(indNames,t1234, t4567))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "settled-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1234 = pd.DataFrame(t1234, columns=['Type', 'Accuracy (in %) of old embeddings compared to annotated category', 'Accuracy (in %) of new embeddings compared to annotated category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "young-heath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - 19k</td>\n",
       "      <td>0.679191</td>\n",
       "      <td>0.684971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>0.679191</td>\n",
       "      <td>0.679191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Complex - Probase-19k</td>\n",
       "      <td>0.598266</td>\n",
       "      <td>0.661850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complex - 19k</td>\n",
       "      <td>0.598266</td>\n",
       "      <td>0.658960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Complex - Probase</td>\n",
       "      <td>0.598266</td>\n",
       "      <td>0.656069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transe - 19k</td>\n",
       "      <td>0.598266</td>\n",
       "      <td>0.653179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>0.650289</td>\n",
       "      <td>0.653179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transe - Probase</td>\n",
       "      <td>0.598266</td>\n",
       "      <td>0.644509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Transe - Probase-19k</td>\n",
       "      <td>0.598266</td>\n",
       "      <td>0.641618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract - 19k</td>\n",
       "      <td>0.627168</td>\n",
       "      <td>0.627168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6 embeddings - Probase-19k</td>\n",
       "      <td>0.624277</td>\n",
       "      <td>0.627168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6 embeddings - 19k</td>\n",
       "      <td>0.624277</td>\n",
       "      <td>0.624277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text 7 props - 19k</td>\n",
       "      <td>0.572254</td>\n",
       "      <td>0.569364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text 2 props - 19k</td>\n",
       "      <td>0.566474</td>\n",
       "      <td>0.554913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Type  \\\n",
       "10          Complex-Transe-AbsFirstSent - 19k   \n",
       "11  Complex-Transe-AbsFirstSent - Probase-19k   \n",
       "8                       Complex - Probase-19k   \n",
       "2                               Complex - 19k   \n",
       "6                           Complex - Probase   \n",
       "3                                Transe - 19k   \n",
       "5               Abstract First Sentence - 19k   \n",
       "7                            Transe - Probase   \n",
       "9                        Transe - Probase-19k   \n",
       "4                              Abstract - 19k   \n",
       "13                 6 embeddings - Probase-19k   \n",
       "12                         6 embeddings - 19k   \n",
       "0                          Text 7 props - 19k   \n",
       "1                          Text 2 props - 19k   \n",
       "\n",
       "    Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "10                                           0.679191                  \n",
       "11                                           0.679191                  \n",
       "8                                            0.598266                  \n",
       "2                                            0.598266                  \n",
       "6                                            0.598266                  \n",
       "3                                            0.598266                  \n",
       "5                                            0.650289                  \n",
       "7                                            0.598266                  \n",
       "9                                            0.598266                  \n",
       "4                                            0.627168                  \n",
       "13                                           0.624277                  \n",
       "12                                           0.624277                  \n",
       "0                                            0.572254                  \n",
       "1                                            0.566474                  \n",
       "\n",
       "    Accuracy (in %) of new embeddings compared to annotated category  \n",
       "10                                           0.684971                 \n",
       "11                                           0.679191                 \n",
       "8                                            0.661850                 \n",
       "2                                            0.658960                 \n",
       "6                                            0.656069                 \n",
       "3                                            0.653179                 \n",
       "5                                            0.653179                 \n",
       "7                                            0.644509                 \n",
       "9                                            0.641618                 \n",
       "4                                            0.627168                 \n",
       "13                                           0.627168                 \n",
       "12                                           0.624277                 \n",
       "0                                            0.569364                 \n",
       "1                                            0.554913                 "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1234.sort_values(by=['Accuracy (in %) of new embeddings compared to annotated category'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "accompanied-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ,\n",
    "#  'concat_19k_v1_old_cosSim',\n",
    "#  'concat_19k_v2_old_cosSim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "beneficial-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndGenerateAccuracies(wordSim353AnnotDF_New_Merged_DF, colList):\n",
    "    X = wordSim353AnnotDF_New_Merged_DF[colList]\n",
    "    Y = wordSim353AnnotDF_New_Merged_DF['category']\n",
    "\n",
    "    N_SPLITS = 10\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, random_state=19, shuffle=True)\n",
    "    X_train_splits, X_test_splits, Y_train_splits, Y_test_splits = [], [], [], []\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        X_train_splits.append(X.iloc[train_index])\n",
    "        X_test_splits.append(X.iloc[test_index])\n",
    "        Y_train_splits.append(Y.iloc[train_index])\n",
    "        Y_test_splits.append(Y.iloc[test_index])\n",
    "\n",
    "    preds = []\n",
    "    for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=100))\n",
    "        clf.fit(X_train1, Y_train1)\n",
    "        preds.append(clf.predict(X_test1))\n",
    "\n",
    "    tempVals = []\n",
    "\n",
    "    acc = 0\n",
    "    for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "        acc += accuracy_score(pred, Y_test1)\n",
    "\n",
    "    tempVals.append(acc/N_SPLITS)\n",
    "\n",
    "    for col in colList:\n",
    "        preds = []\n",
    "        for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "            clf1 = make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=100))\n",
    "            clf1.fit(X_train1[[col]], Y_train1)\n",
    "            preds.append(clf1.predict(X_test1[[col]]))\n",
    "        acc = 0\n",
    "        for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "            acc += accuracy_score(pred, Y_test1)\n",
    "        tempVals.append(acc/N_SPLITS)\n",
    "    return tempVals\n",
    "\n",
    "def compareEmbeddings(wordSim353AnnotDF_New_Merged_DF, oldColList, newColList, indNames):\n",
    "    tempVals1 = trainAndGenerateAccuracies(wordSim353AnnotDF_New_Merged_DF, oldColList)\n",
    "    tempVals2 = trainAndGenerateAccuracies(wordSim353AnnotDF_New_Merged_DF, newColList)\n",
    "    summ = (pd.DataFrame(list(zip(tempVals1, tempVals2)), index = ['Combined'] + indNames, columns = ['Accuracy (in %) of old embeddings compared to annotated category', 'Accuracy (in %) of new embeddings compared to annotated category']) * 100)\n",
    "    summ['Increase'] = summ['Accuracy (in %) of new embeddings compared to annotated category'] - summ['Accuracy (in %) of old embeddings compared to annotated category']\n",
    "    return summ.sort_values(by=['Increase'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "intensive-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndFindAccuracy(wordSim353AnnotDF_New_Merged_DF, colList):\n",
    "    X = wordSim353AnnotDF_New_Merged_DF[colList]\n",
    "    Y = wordSim353AnnotDF_New_Merged_DF['category']\n",
    "\n",
    "    N_SPLITS = 10\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, random_state=19, shuffle=True)\n",
    "    X_train_splits, X_test_splits, Y_train_splits, Y_test_splits = [], [], [], []\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        X_train_splits.append(X.iloc[train_index])\n",
    "        X_test_splits.append(X.iloc[test_index])\n",
    "        Y_train_splits.append(Y.iloc[train_index])\n",
    "        Y_test_splits.append(Y.iloc[test_index])\n",
    "\n",
    "    preds = []\n",
    "    for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=100))\n",
    "        clf.fit(X_train1, Y_train1)\n",
    "        preds.append(clf.predict(X_test1))\n",
    "\n",
    "    tempVals = []\n",
    "\n",
    "    acc = 0\n",
    "    for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "        acc += accuracy_score(pred, Y_test1)\n",
    "\n",
    "    return acc/N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "significant-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndFindAccuracyRF(wordSim353AnnotDF_New_Merged_DF, colList):\n",
    "    X = wordSim353AnnotDF_New_Merged_DF[colList]\n",
    "    Y = wordSim353AnnotDF_New_Merged_DF['category']\n",
    "\n",
    "    N_SPLITS = 10\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, random_state=19, shuffle=True)\n",
    "    X_train_splits, X_test_splits, Y_train_splits, Y_test_splits = [], [], [], []\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        X_train_splits.append(X.iloc[train_index])\n",
    "        X_test_splits.append(X.iloc[test_index])\n",
    "        Y_train_splits.append(Y.iloc[train_index])\n",
    "        Y_test_splits.append(Y.iloc[test_index])\n",
    "\n",
    "    preds = []\n",
    "    for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "        clf = RandomForestClassifier(max_depth=max(2 * len(colList) // 3,3), random_state=100)\n",
    "        clf.fit(X_train1, Y_train1)\n",
    "        preds.append(clf.predict(X_test1))\n",
    "\n",
    "    tempVals = []\n",
    "\n",
    "    acc = 0\n",
    "    for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "        acc += accuracy_score(pred, Y_test1)\n",
    "\n",
    "    return acc/N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fitting-jurisdiction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Transe - 19k</th>\n",
       "      <td>64.168067</td>\n",
       "      <td>65.890756</td>\n",
       "      <td>1.722689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Complex - 19k</th>\n",
       "      <td>64.168067</td>\n",
       "      <td>65.596639</td>\n",
       "      <td>1.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combined</th>\n",
       "      <td>68.470588</td>\n",
       "      <td>69.890756</td>\n",
       "      <td>1.420168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 2 props - 19k</th>\n",
       "      <td>64.462185</td>\n",
       "      <td>65.042017</td>\n",
       "      <td>0.579832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abstract - 19k</th>\n",
       "      <td>67.890756</td>\n",
       "      <td>68.176471</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 7 props - 19k</th>\n",
       "      <td>66.176471</td>\n",
       "      <td>66.453782</td>\n",
       "      <td>0.277311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abstract First Sentence - 19k</th>\n",
       "      <td>71.605042</td>\n",
       "      <td>70.747899</td>\n",
       "      <td>-0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "Transe - 19k                                                           64.168067                  \n",
       "Complex - 19k                                                          64.168067                  \n",
       "Combined                                                               68.470588                  \n",
       "Text 2 props - 19k                                                     64.462185                  \n",
       "Abstract - 19k                                                         67.890756                  \n",
       "Text 7 props - 19k                                                     66.176471                  \n",
       "Abstract First Sentence - 19k                                          71.605042                  \n",
       "\n",
       "                               Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "Transe - 19k                                                           65.890756                  \n",
       "Complex - 19k                                                          65.596639                  \n",
       "Combined                                                               69.890756                  \n",
       "Text 2 props - 19k                                                     65.042017                  \n",
       "Abstract - 19k                                                         68.176471                  \n",
       "Text 7 props - 19k                                                     66.453782                  \n",
       "Abstract First Sentence - 19k                                          70.747899                  \n",
       "\n",
       "                               Increase  \n",
       "Transe - 19k                   1.722689  \n",
       "Complex - 19k                  1.428571  \n",
       "Combined                       1.420168  \n",
       "Text 2 props - 19k             0.579832  \n",
       "Abstract - 19k                 0.285714  \n",
       "Text 7 props - 19k             0.277311  \n",
       "Abstract First Sentence - 19k -0.857143  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldColList = ['text_7props_19k_old_cosSim',\n",
    "'text_2props_19k_old_cosSim',\n",
    " 'complex_19k_old_cosSim',\n",
    " 'transe_19k_old_cosSim',\n",
    " 'abstract_19k_old_cosSim',\n",
    " 'abstract_firstSent_19k_old_cosSim']\n",
    "indNames = ['Text 7 props - 19k', 'Text 2 props - 19k', 'Complex - 19k', \n",
    "            'Transe - 19k', 'Abstract - 19k', 'Abstract First Sentence - 19k']\n",
    "compareEmbeddings(wordSim353AnnotDF_New_Merged_DF, oldColList, [colMappers[col] for col in oldColList], indNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "loose-cuisine",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Complex + Transe + Abstract FirstSent 19k</th>\n",
       "      <td>66.176471</td>\n",
       "      <td>66.462185</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combined</th>\n",
       "      <td>68.756303</td>\n",
       "      <td>69.033613</td>\n",
       "      <td>0.277311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text7, Text2, Complex, Transe, Abstract, Abstract FirstSent</th>\n",
       "      <td>69.630252</td>\n",
       "      <td>69.327731</td>\n",
       "      <td>-0.302521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "Complex + Transe + Abstract FirstSent 19k                                                   66.176471                  \n",
       "Combined                                                                                    68.756303                  \n",
       "Text7, Text2, Complex, Transe, Abstract, Abstra...                                          69.630252                  \n",
       "\n",
       "                                                    Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "Complex + Transe + Abstract FirstSent 19k                                                   66.462185                  \n",
       "Combined                                                                                    69.033613                  \n",
       "Text7, Text2, Complex, Transe, Abstract, Abstra...                                          69.327731                  \n",
       "\n",
       "                                                    Increase  \n",
       "Complex + Transe + Abstract FirstSent 19k           0.285714  \n",
       "Combined                                            0.277311  \n",
       "Text7, Text2, Complex, Transe, Abstract, Abstra... -0.302521  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldColList = ['concat_19k_v1_old_cosSim',\n",
    "'concat_19k_v2_old_cosSim']\n",
    "indNames = ['Complex + Transe + Abstract FirstSent 19k', 'Text7, Text2, Complex, Transe, Abstract, Abstract FirstSent']\n",
    "compareEmbeddings(wordSim353AnnotDF_New_Merged_DF, oldColList, [colMappers[col] for col in oldColList], indNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "second-lightning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_7props_19k_old_cosSim',\n",
       " 'text_2props_19k_old_cosSim',\n",
       " 'complex_19k_old_cosSim',\n",
       " 'transe_19k_old_cosSim',\n",
       " 'abstract_19k_old_cosSim',\n",
       " 'abstract_firstSent_19k_old_cosSim',\n",
       " 'complex_probase_old_cosSim',\n",
       " 'transe_probase_old_cosSim',\n",
       " 'complex_probase_19k_old_cosSim',\n",
       " 'transe_probase_19k_old_cosSim',\n",
       " 'concat_19k_v1_old_cosSim',\n",
       " 'concat_probase_19k_v1_old_cosSim',\n",
       " 'concat_19k_v2_old_cosSim',\n",
       " 'concat_probase_19k_v2_old_cosSim']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda p: 'old_cosSim' in p, wordSim353AnnotDF_New_Merged_DF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "institutional-gamma",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oldColList = ['text_7props_19k_old_cosSim',\n",
    " 'text_2props_19k_old_cosSim',\n",
    " 'complex_19k_old_cosSim',\n",
    " 'transe_19k_old_cosSim',\n",
    " 'abstract_19k_old_cosSim',\n",
    " 'abstract_firstSent_19k_old_cosSim',\n",
    " 'complex_probase_old_cosSim',\n",
    " 'transe_probase_old_cosSim',\n",
    " 'complex_probase_19k_old_cosSim',\n",
    " 'transe_probase_19k_old_cosSim',\n",
    " 'concat_19k_v1_old_cosSim',\n",
    " 'concat_probase_19k_v1_old_cosSim',\n",
    " 'concat_19k_v2_old_cosSim',\n",
    " 'concat_probase_19k_v2_old_cosSim']\n",
    "indNames = ['Text 7 props - 19k', 'Text 2 props - 19k', 'Complex - 19k', 'Transe - 19k', \n",
    "            'Abstract - 19k', 'Abstract First Sentence - 19k', 'Complex - Probase', 'Transe - Probase', \n",
    "            'Complex - Probase-19k', 'Transe - Probase-19k', 'Complex-Transe-AbsFirstSent - 19k',\n",
    "            'Complex-Transe-AbsFirstSent - Probase-19k', '6 embeddings - 19k',\n",
    "            '6 embeddings - Probase-19k']\n",
    "compareEmbeddings(wordSim353AnnotDF_New_Merged_DF, oldColList, [colMappers[col] for col in oldColList], indNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-store",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "processed-reynolds",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oldColList = ['text_7props_19k_old_cosSim',\n",
    " 'text_2props_19k_old_cosSim',\n",
    " 'complex_19k_old_cosSim',\n",
    " 'transe_19k_old_cosSim',\n",
    " 'abstract_19k_old_cosSim',\n",
    " 'abstract_firstSent_19k_old_cosSim',\n",
    " 'complex_probase_old_cosSim',\n",
    " 'transe_probase_old_cosSim',\n",
    " 'complex_probase_19k_old_cosSim',\n",
    " 'transe_probase_19k_old_cosSim',\n",
    " 'concat_19k_v1_old_cosSim',\n",
    " 'concat_probase_19k_v1_old_cosSim',\n",
    " 'concat_19k_v2_old_cosSim',\n",
    " 'concat_probase_19k_v2_old_cosSim']\n",
    "indNames = ['Text 7 props - 19k', 'Text 2 props - 19k', 'Complex - 19k', 'Transe - 19k', \n",
    "            'Abstract - 19k', 'Abstract First Sentence - 19k', 'Complex - Probase', 'Transe - Probase', \n",
    "            'Complex - Probase-19k', 'Transe - Probase-19k', 'Complex-Transe-AbsFirstSent - 19k',\n",
    "            'Complex-Transe-AbsFirstSent - Probase-19k', '6 embeddings - 19k',\n",
    "            '6 embeddings - Probase-19k']\n",
    "oldColPairs = list(zip(oldColList, indNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "forced-dining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 7 props - 19k\n",
      "Text 2 props - 19k\n",
      "Complex - 19k\n",
      "Transe - 19k\n",
      "Abstract - 19k\n",
      "Abstract First Sentence - 19k\n",
      "Complex - Probase\n",
      "Transe - Probase\n",
      "Complex - Probase-19k\n",
      "Transe - Probase-19k\n",
      "Complex-Transe-AbsFirstSent - 19k\n",
      "Complex-Transe-AbsFirstSent - Probase-19k\n",
      "6 embeddings - 19k\n",
      "6 embeddings - Probase-19k\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(indNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "permanent-comfort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb(len(oldColPairs), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "quantitative-japanese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**(len(oldColPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accs = []\n",
    "# for r in tqdm(range(1,len(oldColPairs)+1)):\n",
    "#     for comb in tqdm(combinations(oldColPairs, r)):\n",
    "#         print(len(comb))\n",
    "# #         oldAcc = trainAndFindAccuracy(wordSim353AnnotDF_New_Merged_DF, [col[0] for col in comb])\n",
    "# #         newAcc = trainAndFindAccuracy(wordSim353AnnotDF_New_Merged_DF, [colMappers[col[0]] for col in comb])\n",
    "#         print(\" & \".join([col[1] for col in comb]).count(\"&\"))\n",
    "# #         accs.append((indName, oldAcc, newAcc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "fatal-publicity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77739ea8b6bf4cfb933f406e6e9699a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def generateCombAccuracies(oldColPairs, r):\n",
    "    accs = []\n",
    "    for comb in tqdm(combinations(oldColPairs, r)):\n",
    "        assert len(comb) == r\n",
    "        oldAcc = trainAndFindAccuracy(wordSim353AnnotDF_New_Merged_DF, [col[0] for col in comb])\n",
    "        newAcc = trainAndFindAccuracy(wordSim353AnnotDF_New_Merged_DF, [colMappers[col[0]] for col in comb])\n",
    "        indName = \" & \".join([col[1] for col in comb])\n",
    "        accs.append((indName, oldAcc, newAcc))\n",
    "    return accs\n",
    "    \n",
    "results = Parallel(n_jobs=14)(delayed(generateCombAccuracies)(oldColPairs, i) for i in tqdm(range(1,len(oldColPairs)+1)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "documentary-production",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# def generateCombAccuracies(oldColPairs, r):\n",
    "#     accs = []\n",
    "#     for comb in tqdm(combinations(oldColPairs, r)):\n",
    "#         assert len(comb) == r\n",
    "#         oldAcc = trainAndFindAccuracyRF(wordSim353AnnotDF_New_Merged_DF, [col[0] for col in comb])\n",
    "#         newAcc = trainAndFindAccuracyRF(wordSim353AnnotDF_New_Merged_DF, [colMappers[col[0]] for col in comb])\n",
    "#         indName = \" & \".join([col[1] for col in comb])\n",
    "#         accs.append((indName, oldAcc, newAcc))\n",
    "#     return accs\n",
    "    \n",
    "# results = Parallel(n_jobs=14)(delayed(generateCombAccuracies)(oldColPairs, i) for i in tqdm(range(1,len(oldColPairs)+1)))\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "necessary-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_flat = [item for sublist in results for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "divided-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_flat == results_flat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "large-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs = (pd.DataFrame(results_flat, columns = ['Combination','Accuracy (in %) of old embeddings compared to annotated category', 'Accuracy (in %) of new embeddings compared to annotated category']).set_index('Combination') * 100).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "moved-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs['Increase'] = allCombs['Accuracy (in %) of new embeddings compared to annotated category'] - allCombs['Accuracy (in %) of old embeddings compared to annotated category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "biological-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs['count'] = allCombs['Combination'].apply(lambda p: p.count(\"&\")+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "artificial-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs.to_csv('../data/wordsim353_all_combinations_SVM_accuracies.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "restricted-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs = pd.read_csv('../data/wordsim353_all_combinations_SVM_accuracies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "palestinian-sharp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text 7 props - 19k</td>\n",
       "      <td>65.428571</td>\n",
       "      <td>65.126050</td>\n",
       "      <td>-0.302521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text 2 props - 19k</td>\n",
       "      <td>64.554622</td>\n",
       "      <td>63.680672</td>\n",
       "      <td>-0.873950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complex - 19k</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>65.445378</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transe - 19k</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>66.890756</td>\n",
       "      <td>2.310924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract - 19k</td>\n",
       "      <td>67.739496</td>\n",
       "      <td>68.050420</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Combination  \\\n",
       "0  Text 7 props - 19k   \n",
       "1  Text 2 props - 19k   \n",
       "2       Complex - 19k   \n",
       "3        Transe - 19k   \n",
       "4      Abstract - 19k   \n",
       "\n",
       "   Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "0                                          65.428571                  \n",
       "1                                          64.554622                  \n",
       "2                                          64.579832                  \n",
       "3                                          64.579832                  \n",
       "4                                          67.739496                  \n",
       "\n",
       "   Accuracy (in %) of new embeddings compared to annotated category  Increase  \\\n",
       "0                                          65.126050                -0.302521   \n",
       "1                                          63.680672                -0.873950   \n",
       "2                                          65.445378                 0.865546   \n",
       "3                                          66.890756                 2.310924   \n",
       "4                                          68.050420                 0.310924   \n",
       "\n",
       "   count  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "congressional-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined accuracies of 16383 combinations of embedding scores based on the length 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Determined accuracies of {len(allCombs)} combinations of embedding scores based on the length {len(oldColPairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "single-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "sharp-tunisia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>72.705882</td>\n",
       "      <td>71.537815</td>\n",
       "      <td>-1.168067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>71.840336</td>\n",
       "      <td>70.966387</td>\n",
       "      <td>-0.873950</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>71.840336</td>\n",
       "      <td>70.378151</td>\n",
       "      <td>-1.462185</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>71.840336</td>\n",
       "      <td>71.848739</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Abstract - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>71.546218</td>\n",
       "      <td>71.243697</td>\n",
       "      <td>-0.302521</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12350</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>69.504202</td>\n",
       "      <td>-1.470588</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>70.075630</td>\n",
       "      <td>-0.899160</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12154</th>\n",
       "      <td>Text 2 props - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>70.084034</td>\n",
       "      <td>-0.890756</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11944</th>\n",
       "      <td>Text 2 props - 19k &amp; Complex - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>69.781513</td>\n",
       "      <td>-1.193277</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12349</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase-19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>69.210084</td>\n",
       "      <td>-1.764706</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                         Combination  \\\n",
       "5      Abstract First Sentence - 19k                                                                                                                                                                                                   \n",
       "30     Text 2 props - 19k & Abstract First Sentence - 19k                                                                                                                                                                              \n",
       "204    Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k                                                                                                                                                             \n",
       "18     Text 7 props - 19k & Abstract First Sentence - 19k                                                                                                                                                                              \n",
       "60     Abstract - 19k & Abstract First Sentence - 19k                                                                                                                                                                                  \n",
       "12350  Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Transe - Probase-19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k    \n",
       "12329  Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex - Probase & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k       \n",
       "12154  Text 2 props - 19k & Transe - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k            \n",
       "11944  Text 2 props - 19k & Complex - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k           \n",
       "12349  Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex - Probase-19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k   \n",
       "\n",
       "       Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "5      72.705882                                                          \n",
       "30     71.840336                                                          \n",
       "204    71.840336                                                          \n",
       "18     71.840336                                                          \n",
       "60     71.546218                                                          \n",
       "12350  70.974790                                                          \n",
       "12329  70.974790                                                          \n",
       "12154  70.974790                                                          \n",
       "11944  70.974790                                                          \n",
       "12349  70.974790                                                          \n",
       "\n",
       "       Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "5      71.537815                                                          \n",
       "30     70.966387                                                          \n",
       "204    70.378151                                                          \n",
       "18     71.848739                                                          \n",
       "60     71.243697                                                          \n",
       "12350  69.504202                                                          \n",
       "12329  70.075630                                                          \n",
       "12154  70.084034                                                          \n",
       "11944  69.781513                                                          \n",
       "12349  69.210084                                                          \n",
       "\n",
       "       Increase  count  \n",
       "5     -1.168067  1      \n",
       "30    -0.873950  2      \n",
       "204   -1.462185  3      \n",
       "18     0.008403  2      \n",
       "60    -0.302521  2      \n",
       "12350 -1.470588  8      \n",
       "12329 -0.899160  8      \n",
       "12154 -0.890756  8      \n",
       "11944 -1.193277  8      \n",
       "12349 -1.764706  8      "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs.sort_values(by=['Accuracy (in %) of old embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "federal-timing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>71.840336</td>\n",
       "      <td>71.848739</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.394958</td>\n",
       "      <td>71.546218</td>\n",
       "      <td>1.151261</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>72.705882</td>\n",
       "      <td>71.537815</td>\n",
       "      <td>-1.168067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Transe - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>68.630252</td>\n",
       "      <td>71.521008</td>\n",
       "      <td>2.890756</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>69.210084</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>2.042017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>70.084034</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>1.168067</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.092437</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>1.159664</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7049</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.386555</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>Text 7 props - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>69.798319</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>1.453782</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11327</th>\n",
       "      <td>Text 7 props - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.100840</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>1.151261</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                Combination  \\\n",
       "18     Text 7 props - 19k & Abstract First Sentence - 19k                                                                                                                                                     \n",
       "5318   Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex - Probase & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - Probase-19k                                       \n",
       "5      Abstract First Sentence - 19k                                                                                                                                                                          \n",
       "51     Transe - 19k & Abstract First Sentence - 19k                                                                                                                                                           \n",
       "108    Text 7 props - 19k & Text 2 props - 19k & Abstract First Sentence - 19k                                                                                                                                \n",
       "694    Text 7 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k & 6 embeddings - 19k                                                                                            \n",
       "8035   Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Transe - Probase & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k                   \n",
       "7049   Text 7 props - 19k & Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Transe - Probase & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - Probase-19k                   \n",
       "1916   Text 7 props - 19k & Transe - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k                                                                     \n",
       "11327  Text 7 props - 19k & Transe - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex - Probase & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k   \n",
       "\n",
       "       Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "18     71.840336                                                          \n",
       "5318   70.394958                                                          \n",
       "5      72.705882                                                          \n",
       "51     68.630252                                                          \n",
       "108    69.210084                                                          \n",
       "694    70.084034                                                          \n",
       "8035   70.092437                                                          \n",
       "7049   70.386555                                                          \n",
       "1916   69.798319                                                          \n",
       "11327  70.100840                                                          \n",
       "\n",
       "       Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "18     71.848739                                                          \n",
       "5318   71.546218                                                          \n",
       "5      71.537815                                                          \n",
       "51     71.521008                                                          \n",
       "108    71.252101                                                          \n",
       "694    71.252101                                                          \n",
       "8035   71.252101                                                          \n",
       "7049   71.252101                                                          \n",
       "1916   71.252101                                                          \n",
       "11327  71.252101                                                          \n",
       "\n",
       "       Increase  count  \n",
       "18     0.008403  2      \n",
       "5318   1.151261  6      \n",
       "5     -1.168067  1      \n",
       "51     2.890756  2      \n",
       "108    2.042017  3      \n",
       "694    1.168067  4      \n",
       "8035   1.159664  7      \n",
       "7049   0.865546  7      \n",
       "1916   1.453782  5      \n",
       "11327  1.151261  8      "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs.sort_values(by=['Accuracy (in %) of new embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "known-basement",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase-19k &amp; Transe - Probase-19k</td>\n",
       "      <td>66.285714</td>\n",
       "      <td>69.193277</td>\n",
       "      <td>2.907563</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Transe - Probase &amp; Complex - Probase-19k</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>68.613445</td>\n",
       "      <td>2.899160</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Transe - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>68.630252</td>\n",
       "      <td>71.521008</td>\n",
       "      <td>2.890756</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9440</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Transe - Probase &amp; Complex - Probase-19k &amp; Transe - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>66.563025</td>\n",
       "      <td>69.184874</td>\n",
       "      <td>2.621849</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>Complex - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Complex - Probase-19k &amp; Transe - Probase-19k</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>68.327731</td>\n",
       "      <td>2.613445</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Transe - Probase &amp; Complex - Probase-19k</td>\n",
       "      <td>66.285714</td>\n",
       "      <td>68.899160</td>\n",
       "      <td>2.613445</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Transe - Probase-19k</td>\n",
       "      <td>66.285714</td>\n",
       "      <td>68.899160</td>\n",
       "      <td>2.613445</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>Complex - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Complex - Probase-19k</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>68.319328</td>\n",
       "      <td>2.605042</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Complex - Probase-19k &amp; Transe - Probase-19k</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>68.319328</td>\n",
       "      <td>2.605042</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>68.647059</td>\n",
       "      <td>71.226891</td>\n",
       "      <td>2.579832</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            Combination  \\\n",
       "1041  Complex - 19k & Abstract - 19k & Complex - Probase-19k & Transe - Probase-19k                                                                       \n",
       "2828  Complex - 19k & Abstract - 19k & Complex - Probase & Transe - Probase & Complex - Probase-19k                                                       \n",
       "51    Transe - 19k & Abstract First Sentence - 19k                                                                                                        \n",
       "9440  Complex - 19k & Abstract - 19k & Complex - Probase & Transe - Probase & Complex - Probase-19k & Transe - Probase-19k & 6 embeddings - Probase-19k   \n",
       "2701  Complex - 19k & Transe - 19k & Abstract - 19k & Complex - Probase-19k & Transe - Probase-19k                                                        \n",
       "1035  Complex - 19k & Abstract - 19k & Transe - Probase & Complex - Probase-19k                                                                           \n",
       "1030  Complex - 19k & Abstract - 19k & Complex - Probase & Transe - Probase-19k                                                                           \n",
       "2689  Complex - 19k & Transe - 19k & Abstract - 19k & Complex - Probase & Complex - Probase-19k                                                           \n",
       "2834  Complex - 19k & Abstract - 19k & Complex - Probase & Complex - Probase-19k & Transe - Probase-19k                                                   \n",
       "1026  Complex - 19k & Abstract - 19k & Abstract First Sentence - 19k & 6 embeddings - 19k                                                                 \n",
       "\n",
       "      Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "1041  66.285714                                                          \n",
       "2828  65.714286                                                          \n",
       "51    68.630252                                                          \n",
       "9440  66.563025                                                          \n",
       "2701  65.714286                                                          \n",
       "1035  66.285714                                                          \n",
       "1030  66.285714                                                          \n",
       "2689  65.714286                                                          \n",
       "2834  65.714286                                                          \n",
       "1026  68.647059                                                          \n",
       "\n",
       "      Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "1041  69.193277                                                          \n",
       "2828  68.613445                                                          \n",
       "51    71.521008                                                          \n",
       "9440  69.184874                                                          \n",
       "2701  68.327731                                                          \n",
       "1035  68.899160                                                          \n",
       "1030  68.899160                                                          \n",
       "2689  68.319328                                                          \n",
       "2834  68.319328                                                          \n",
       "1026  71.226891                                                          \n",
       "\n",
       "      Increase  count  \n",
       "1041  2.907563  4      \n",
       "2828  2.899160  5      \n",
       "51    2.890756  2      \n",
       "9440  2.621849  7      \n",
       "2701  2.613445  5      \n",
       "1035  2.613445  4      \n",
       "1030  2.613445  4      \n",
       "2689  2.605042  5      \n",
       "2834  2.605042  5      \n",
       "1026  2.579832  4      "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs.sort_values(by=['Increase'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "private-conditions",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>72.705882</td>\n",
       "      <td>71.537815</td>\n",
       "      <td>-1.168067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6 embeddings - 19k</td>\n",
       "      <td>70.092437</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>1.159664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6 embeddings - Probase-19k</td>\n",
       "      <td>70.092437</td>\n",
       "      <td>70.672269</td>\n",
       "      <td>0.579832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract - 19k</td>\n",
       "      <td>67.739496</td>\n",
       "      <td>68.050420</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>67.470588</td>\n",
       "      <td>67.176471</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - 19k</td>\n",
       "      <td>67.470588</td>\n",
       "      <td>66.899160</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transe - 19k</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>66.890756</td>\n",
       "      <td>2.310924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Transe - Probase-19k</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>66.890756</td>\n",
       "      <td>2.310924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transe - Probase</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>66.596639</td>\n",
       "      <td>2.016807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Complex - Probase-19k</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>65.445378</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Combination  \\\n",
       "5   Abstract First Sentence - 19k               \n",
       "12  6 embeddings - 19k                          \n",
       "13  6 embeddings - Probase-19k                  \n",
       "4   Abstract - 19k                              \n",
       "11  Complex-Transe-AbsFirstSent - Probase-19k   \n",
       "10  Complex-Transe-AbsFirstSent - 19k           \n",
       "3   Transe - 19k                                \n",
       "9   Transe - Probase-19k                        \n",
       "7   Transe - Probase                            \n",
       "8   Complex - Probase-19k                       \n",
       "\n",
       "    Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "5   72.705882                                                          \n",
       "12  70.092437                                                          \n",
       "13  70.092437                                                          \n",
       "4   67.739496                                                          \n",
       "11  67.470588                                                          \n",
       "10  67.470588                                                          \n",
       "3   64.579832                                                          \n",
       "9   64.579832                                                          \n",
       "7   64.579832                                                          \n",
       "8   64.579832                                                          \n",
       "\n",
       "    Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "5   71.537815                                                          \n",
       "12  71.252101                                                          \n",
       "13  70.672269                                                          \n",
       "4   68.050420                                                          \n",
       "11  67.176471                                                          \n",
       "10  66.899160                                                          \n",
       "3   66.890756                                                          \n",
       "9   66.890756                                                          \n",
       "7   66.596639                                                          \n",
       "8   65.445378                                                          \n",
       "\n",
       "    Increase  count  \n",
       "5  -1.168067  1      \n",
       "12  1.159664  1      \n",
       "13  0.579832  1      \n",
       "4   0.310924  1      \n",
       "11 -0.294118  1      \n",
       "10 -0.571429  1      \n",
       "3   2.310924  1      \n",
       "9   2.310924  1      \n",
       "7   2.016807  1      \n",
       "8   0.865546  1      "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs[allCombs['count'] == 1].sort_values(by=['Accuracy (in %) of new embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-think",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "trying-liabilities",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123c20d4e60b4e3e8b09c0e0e46efc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def generateCombAccuracies(oldColPairs, r):\n",
    "    accs = []\n",
    "    for comb in tqdm(combinations(oldColPairs, r)):\n",
    "        assert len(comb) == r\n",
    "        oldAcc = trainAndFindAccuracyRF(wordSim353AnnotDF_New_Merged_DF, [col[0] for col in comb])\n",
    "        newAcc = trainAndFindAccuracyRF(wordSim353AnnotDF_New_Merged_DF, [colMappers[col[0]] for col in comb])\n",
    "        indName = \" & \".join([col[1] for col in comb])\n",
    "        accs.append((indName, oldAcc, newAcc))\n",
    "    return accs\n",
    "    \n",
    "results1 = Parallel(n_jobs=14)(delayed(generateCombAccuracies)(oldColPairs, i) for i in tqdm(range(1,len(oldColPairs)+1)))\n",
    "print(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "competitive-liverpool",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results == results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "accredited-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_flat1 = [item for sublist in results1 for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "specialized-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs1 = (pd.DataFrame(results_flat1, columns = ['Combination','Accuracy (in %) of old embeddings compared to annotated category', 'Accuracy (in %) of new embeddings compared to annotated category']).set_index('Combination') * 100).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "published-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs1['Increase'] = allCombs1['Accuracy (in %) of new embeddings compared to annotated category'] - allCombs['Accuracy (in %) of old embeddings compared to annotated category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "nominated-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs1['count'] = allCombs1['Combination'].apply(lambda p: p.count(\"&\")+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "alleged-fruit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text 7 props - 19k</td>\n",
       "      <td>65.126050</td>\n",
       "      <td>63.672269</td>\n",
       "      <td>-1.453782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text 2 props - 19k</td>\n",
       "      <td>61.899160</td>\n",
       "      <td>63.344538</td>\n",
       "      <td>1.445378</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complex - 19k</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>64.277311</td>\n",
       "      <td>-2.336134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transe - 19k</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>66.310924</td>\n",
       "      <td>-0.302521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract - 19k</td>\n",
       "      <td>68.899160</td>\n",
       "      <td>66.008403</td>\n",
       "      <td>-2.890756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Combination  \\\n",
       "0  Text 7 props - 19k   \n",
       "1  Text 2 props - 19k   \n",
       "2  Complex - 19k        \n",
       "3  Transe - 19k         \n",
       "4  Abstract - 19k       \n",
       "\n",
       "   Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "0  65.126050                                                          \n",
       "1  61.899160                                                          \n",
       "2  66.613445                                                          \n",
       "3  66.613445                                                          \n",
       "4  68.899160                                                          \n",
       "\n",
       "   Accuracy (in %) of new embeddings compared to annotated category  Increase  \\\n",
       "0  63.672269                                                        -1.453782   \n",
       "1  63.344538                                                         1.445378   \n",
       "2  64.277311                                                        -2.336134   \n",
       "3  66.310924                                                        -0.302521   \n",
       "4  66.008403                                                        -2.890756   \n",
       "\n",
       "   count  \n",
       "0  1      \n",
       "1  1      \n",
       "2  1      \n",
       "3  1      \n",
       "4  1      "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "increased-indonesian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined accuracies of 16383 combinations of embedding scores based on the length 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Determined accuracies of {len(allCombs1)} combinations of embedding scores based on the length {len(oldColPairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "english-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fantastic-narrow",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>73.285714</td>\n",
       "      <td>70.075630</td>\n",
       "      <td>-3.210084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Abstract - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>72.117647</td>\n",
       "      <td>68.327731</td>\n",
       "      <td>-3.789916</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>72.100840</td>\n",
       "      <td>70.361345</td>\n",
       "      <td>-1.739496</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k</td>\n",
       "      <td>71.831933</td>\n",
       "      <td>70.378151</td>\n",
       "      <td>-1.453782</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>71.831933</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>-0.579832</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>71.815126</td>\n",
       "      <td>69.789916</td>\n",
       "      <td>-2.025210</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>71.815126</td>\n",
       "      <td>69.798319</td>\n",
       "      <td>-2.016807</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>71.815126</td>\n",
       "      <td>70.378151</td>\n",
       "      <td>-1.436975</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>71.815126</td>\n",
       "      <td>69.495798</td>\n",
       "      <td>-2.319328</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>71.815126</td>\n",
       "      <td>69.487395</td>\n",
       "      <td>-2.327731</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           Combination  \\\n",
       "5     Abstract First Sentence - 19k                                                                                                                      \n",
       "60    Abstract - 19k & Abstract First Sentence - 19k                                                                                                     \n",
       "138   Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k                                                                                \n",
       "151   Text 7 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k                                                             \n",
       "152   Text 7 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k                                                     \n",
       "2114  Text 7 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k   \n",
       "2001  Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - Probase-19k       \n",
       "2000  Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k               \n",
       "1999  Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k & 6 embeddings - Probase-19k               \n",
       "1998  Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k & 6 embeddings - 19k                       \n",
       "\n",
       "      Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "5     73.285714                                                          \n",
       "60    72.117647                                                          \n",
       "138   72.100840                                                          \n",
       "151   71.831933                                                          \n",
       "152   71.831933                                                          \n",
       "2114  71.815126                                                          \n",
       "2001  71.815126                                                          \n",
       "2000  71.815126                                                          \n",
       "1999  71.815126                                                          \n",
       "1998  71.815126                                                          \n",
       "\n",
       "      Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "5     70.075630                                                          \n",
       "60    68.327731                                                          \n",
       "138   70.361345                                                          \n",
       "151   70.378151                                                          \n",
       "152   71.252101                                                          \n",
       "2114  69.789916                                                          \n",
       "2001  69.798319                                                          \n",
       "2000  70.378151                                                          \n",
       "1999  69.495798                                                          \n",
       "1998  69.487395                                                          \n",
       "\n",
       "      Increase  count  \n",
       "5    -3.210084  1      \n",
       "60   -3.789916  2      \n",
       "138  -1.739496  3      \n",
       "151  -1.453782  3      \n",
       "152  -0.579832  3      \n",
       "2114 -2.025210  5      \n",
       "2001 -2.016807  5      \n",
       "2000 -1.436975  5      \n",
       "1999 -2.319328  5      \n",
       "1998 -2.327731  5      "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs1.sort_values(by=['Accuracy (in %) of old embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "brown-punishment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>70.663866</td>\n",
       "      <td>71.260504</td>\n",
       "      <td>0.596639</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>71.226891</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>71.235294</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>71.831933</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>-0.579832</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase-19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>68.310924</td>\n",
       "      <td>71.235294</td>\n",
       "      <td>2.924370</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Text 7 props - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>69.764706</td>\n",
       "      <td>71.235294</td>\n",
       "      <td>1.470588</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k</td>\n",
       "      <td>71.226891</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>-0.252101</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Text 7 props - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>71.529412</td>\n",
       "      <td>70.966387</td>\n",
       "      <td>-0.563025</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>68.605042</td>\n",
       "      <td>70.966387</td>\n",
       "      <td>2.361345</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>70.663866</td>\n",
       "      <td>70.966387</td>\n",
       "      <td>0.302521</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      Combination  \\\n",
       "681   Text 7 props - 19k & Abstract First Sentence - 19k & Transe - Probase & Complex-Transe-AbsFirstSent - Probase-19k                                                                                             \n",
       "218   Text 2 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k                                                                                                                \n",
       "1575  Text 7 props - 19k & Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k                                                                          \n",
       "152   Text 7 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k                                                                                                                \n",
       "3884  Text 7 props - 19k & Text 2 props - 19k & Abstract First Sentence - 19k & Complex - Probase-19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k                                              \n",
       "129   Text 7 props - 19k & Transe - 19k & Abstract First Sentence - 19k                                                                                                                                             \n",
       "217   Text 2 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k                                                                                                                        \n",
       "604   Text 7 props - 19k & Transe - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k                                                                                                 \n",
       "7207  Text 7 props - 19k & Text 2 props - 19k & Abstract First Sentence - 19k & Transe - Probase-19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - Probase-19k   \n",
       "690   Text 7 props - 19k & Abstract First Sentence - 19k & Transe - Probase-19k & Complex-Transe-AbsFirstSent - Probase-19k                                                                                         \n",
       "\n",
       "      Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "681   70.663866                                                          \n",
       "218   71.226891                                                          \n",
       "1575  71.235294                                                          \n",
       "152   71.831933                                                          \n",
       "3884  68.310924                                                          \n",
       "129   69.764706                                                          \n",
       "217   71.226891                                                          \n",
       "604   71.529412                                                          \n",
       "7207  68.605042                                                          \n",
       "690   70.663866                                                          \n",
       "\n",
       "      Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "681   71.260504                                                          \n",
       "218   71.252101                                                          \n",
       "1575  71.252101                                                          \n",
       "152   71.252101                                                          \n",
       "3884  71.235294                                                          \n",
       "129   71.235294                                                          \n",
       "217   70.974790                                                          \n",
       "604   70.966387                                                          \n",
       "7207  70.966387                                                          \n",
       "690   70.966387                                                          \n",
       "\n",
       "      Increase  count  \n",
       "681   0.596639  4      \n",
       "218   0.025210  3      \n",
       "1575  0.016807  5      \n",
       "152  -0.579832  3      \n",
       "3884  2.924370  6      \n",
       "129   1.470588  3      \n",
       "217  -0.252101  3      \n",
       "604  -0.563025  4      \n",
       "7207  2.361345  7      \n",
       "690   0.302521  4      "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs1.sort_values(by=['Accuracy (in %) of new embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "considerable-syndication",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13048</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Transe - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>64.252101</td>\n",
       "      <td>70.352941</td>\n",
       "      <td>6.100840</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13084</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>64.252101</td>\n",
       "      <td>69.210084</td>\n",
       "      <td>4.957983</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14022</th>\n",
       "      <td>Text 7 props - 19k &amp; Complex - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>64.529412</td>\n",
       "      <td>69.176471</td>\n",
       "      <td>4.647059</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13861</th>\n",
       "      <td>Text 7 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>64.243697</td>\n",
       "      <td>68.890756</td>\n",
       "      <td>4.647059</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7551</th>\n",
       "      <td>Text 7 props - 19k &amp; Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Complex - Probase-19k &amp; Transe - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>63.092437</td>\n",
       "      <td>67.722689</td>\n",
       "      <td>4.630252</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13058</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Complex - Probase-19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>64.252101</td>\n",
       "      <td>68.605042</td>\n",
       "      <td>4.352941</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Complex - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>63.689076</td>\n",
       "      <td>68.033613</td>\n",
       "      <td>4.344538</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>Text 7 props - 19k &amp; Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Transe - Probase &amp; Complex - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>63.092437</td>\n",
       "      <td>67.436975</td>\n",
       "      <td>4.344538</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>Text 7 props - 19k &amp; Complex - 19k &amp; Abstract - 19k &amp; Transe - Probase &amp; Complex - Probase-19k &amp; Transe - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>63.092437</td>\n",
       "      <td>67.428571</td>\n",
       "      <td>4.336134</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Complex - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>63.689076</td>\n",
       "      <td>68.025210</td>\n",
       "      <td>4.336134</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                          Combination  \\\n",
       "13048  Text 7 props - 19k & Text 2 props - 19k & Complex - 19k & Transe - 19k & Abstract First Sentence - 19k & Complex - Probase & Transe - Probase & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k                                   \n",
       "13084  Text 7 props - 19k & Text 2 props - 19k & Complex - 19k & Transe - 19k & Abstract First Sentence - 19k & Transe - Probase & Transe - Probase-19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k                                \n",
       "14022  Text 7 props - 19k & Complex - 19k & Abstract First Sentence - 19k & Transe - Probase & Transe - Probase-19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k   \n",
       "13861  Text 7 props - 19k & Complex - 19k & Transe - 19k & Abstract First Sentence - 19k & Complex - Probase & Transe - Probase-19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k                       \n",
       "7551   Text 7 props - 19k & Complex - 19k & Abstract - 19k & Complex - Probase & Complex - Probase-19k & Transe - Probase-19k & 6 embeddings - Probase-19k                                                                                              \n",
       "13058  Text 7 props - 19k & Text 2 props - 19k & Complex - 19k & Transe - 19k & Abstract First Sentence - 19k & Complex - Probase & Complex - Probase-19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k                              \n",
       "6500   Text 7 props - 19k & Text 2 props - 19k & Complex - 19k & Transe - 19k & Abstract - 19k & Complex - Probase-19k & 6 embeddings - Probase-19k                                                                                                     \n",
       "7537   Text 7 props - 19k & Complex - 19k & Abstract - 19k & Complex - Probase & Transe - Probase & Complex - Probase-19k & 6 embeddings - Probase-19k                                                                                                  \n",
       "7570   Text 7 props - 19k & Complex - 19k & Abstract - 19k & Transe - Probase & Complex - Probase-19k & Transe - Probase-19k & 6 embeddings - 19k                                                                                                       \n",
       "6499   Text 7 props - 19k & Text 2 props - 19k & Complex - 19k & Transe - 19k & Abstract - 19k & Complex - Probase-19k & 6 embeddings - 19k                                                                                                             \n",
       "\n",
       "       Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "13048  64.252101                                                          \n",
       "13084  64.252101                                                          \n",
       "14022  64.529412                                                          \n",
       "13861  64.243697                                                          \n",
       "7551   63.092437                                                          \n",
       "13058  64.252101                                                          \n",
       "6500   63.689076                                                          \n",
       "7537   63.092437                                                          \n",
       "7570   63.092437                                                          \n",
       "6499   63.689076                                                          \n",
       "\n",
       "       Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "13048  70.352941                                                          \n",
       "13084  69.210084                                                          \n",
       "14022  69.176471                                                          \n",
       "13861  68.890756                                                          \n",
       "7551   67.722689                                                          \n",
       "13058  68.605042                                                          \n",
       "6500   68.033613                                                          \n",
       "7537   67.436975                                                          \n",
       "7570   67.428571                                                          \n",
       "6499   68.025210                                                          \n",
       "\n",
       "       Increase  count  \n",
       "13048  6.100840  9      \n",
       "13084  4.957983  9      \n",
       "14022  4.647059  9      \n",
       "13861  4.647059  9      \n",
       "7551   4.630252  7      \n",
       "13058  4.352941  9      \n",
       "6500   4.344538  7      \n",
       "7537   4.344538  7      \n",
       "7570   4.336134  7      \n",
       "6499   4.336134  7      "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs1.sort_values(by=['Increase'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "binary-committee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>70.042017</td>\n",
       "      <td>70.630252</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>73.285714</td>\n",
       "      <td>70.075630</td>\n",
       "      <td>-3.210084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - 19k</td>\n",
       "      <td>70.042017</td>\n",
       "      <td>68.302521</td>\n",
       "      <td>-1.739496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6 embeddings - Probase-19k</td>\n",
       "      <td>68.907563</td>\n",
       "      <td>68.042017</td>\n",
       "      <td>-0.865546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6 embeddings - 19k</td>\n",
       "      <td>68.907563</td>\n",
       "      <td>66.857143</td>\n",
       "      <td>-2.050420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Complex - Probase</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>66.596639</td>\n",
       "      <td>-0.016807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transe - Probase</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>66.596639</td>\n",
       "      <td>-0.016807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transe - 19k</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>66.310924</td>\n",
       "      <td>-0.302521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Transe - Probase-19k</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>66.008403</td>\n",
       "      <td>-0.605042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract - 19k</td>\n",
       "      <td>68.899160</td>\n",
       "      <td>66.008403</td>\n",
       "      <td>-2.890756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Combination  \\\n",
       "11  Complex-Transe-AbsFirstSent - Probase-19k   \n",
       "5   Abstract First Sentence - 19k               \n",
       "10  Complex-Transe-AbsFirstSent - 19k           \n",
       "13  6 embeddings - Probase-19k                  \n",
       "12  6 embeddings - 19k                          \n",
       "6   Complex - Probase                           \n",
       "7   Transe - Probase                            \n",
       "3   Transe - 19k                                \n",
       "9   Transe - Probase-19k                        \n",
       "4   Abstract - 19k                              \n",
       "\n",
       "    Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "11  70.042017                                                          \n",
       "5   73.285714                                                          \n",
       "10  70.042017                                                          \n",
       "13  68.907563                                                          \n",
       "12  68.907563                                                          \n",
       "6   66.613445                                                          \n",
       "7   66.613445                                                          \n",
       "3   66.613445                                                          \n",
       "9   66.613445                                                          \n",
       "4   68.899160                                                          \n",
       "\n",
       "    Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "11  70.630252                                                          \n",
       "5   70.075630                                                          \n",
       "10  68.302521                                                          \n",
       "13  68.042017                                                          \n",
       "12  66.857143                                                          \n",
       "6   66.596639                                                          \n",
       "7   66.596639                                                          \n",
       "3   66.310924                                                          \n",
       "9   66.008403                                                          \n",
       "4   66.008403                                                          \n",
       "\n",
       "    Increase  count  \n",
       "11  0.588235  1      \n",
       "5  -3.210084  1      \n",
       "10 -1.739496  1      \n",
       "13 -0.865546  1      \n",
       "12 -2.050420  1      \n",
       "6  -0.016807  1      \n",
       "7  -0.016807  1      \n",
       "3  -0.302521  1      \n",
       "9  -0.605042  1      \n",
       "4  -2.890756  1      "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs1[allCombs1['count'] == 1].sort_values(by=['Accuracy (in %) of new embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-event",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-spider",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-thought",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "western-easter",
   "metadata": {},
   "source": [
    "# Generate Embeddings Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "nervous-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = pd.concat([wordSim353AnnotDF_New2[['word1_kg_id', 'Word 1']], wordSim353AnnotDF_New2[['word2_kg_id', 'Word 2']].rename(columns={'Word 2': 'Word 1', 'word2_kg_id': 'word1_kg_id'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "neither-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = wordList[~wordList.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "welsh-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList['word1_kg_id'].apply(lambda p: \"\\t\".join([str(p1) for p1 in embedDict[p].tolist()])).to_csv('../data/wordsim353_embeddings.tsv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "processed-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList['word1_kg_id'].apply(lambda p: \"\\t\".join([str(p1) for p1 in newEmbedDict[p].tolist()])).to_csv('../data/wordsim353_embeddings_new_attempt1.tsv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "psychological-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList['Word 1'].to_csv('../data/wordsim353_embeddings_words.tsv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-munich",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-appliance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-textbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-orlando",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-qatar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-brick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-kernel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-atlas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-means",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-fever",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-baker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-charm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgtkEnv",
   "language": "python",
   "name": "kgtkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
