{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dynamic-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations\n",
    "from math import comb\n",
    "from time import time\n",
    "from datetime import date\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, plot_confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-orleans",
   "metadata": {},
   "source": [
    "# Retrofitting Pre-Req Class Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-meeting",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ultimate-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    \"\"\"\n",
    "    This contains all the utility functions needed by any part of retrofitting\n",
    "    \"\"\"\n",
    "    _today = date.today()\n",
    "    today_date = _today.strftime(\"%b_%d_%Y\")\n",
    "    LABELS = ['I','U','M']\n",
    "    \n",
    "    @classmethod\n",
    "    def normalize(cls, embed_dict):\n",
    "        for key, val in embed_dict.items():\n",
    "            temp = np.array([float(val1) for val1 in val])\n",
    "            temp2 = temp**2\n",
    "            embed_dict[key] = temp / np.sqrt((temp2.sum() + 1e-6))\n",
    "        return embed_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def fetch_embeddings(cls, df):\n",
    "        embed_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            embed_dict[row.node] = row.value\n",
    "        return normalize(embed_dict)\n",
    "    \n",
    "    @classmethod\n",
    "    def fill_coverage(cls, embed_dict):\n",
    "        # TODO: Coverage for all datasets\n",
    "        wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')\n",
    "        wordSim353AnnotDF_set = set(wordSim353AnnotDF_New['word1_kg_id'].to_list() + wordSim353AnnotDF_New['word2_kg_id'].to_list())\n",
    "        embed_size = len(embed_dict[next(iter(embed_dict))])\n",
    "        count = 0\n",
    "        for word in wordSim353AnnotDF_set:\n",
    "            if word not in embed_dict:\n",
    "                embed_dict[word] = np.zeros((embed_size))\n",
    "                count += 1\n",
    "        print(f\"Added {count} corrections\")\n",
    "        return embed_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def check_coverage(cls, embed_dict):\n",
    "        wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')\n",
    "        wordSim353AnnotDF_set = set(wordSim353AnnotDF_New['word1_kg_id'].to_list() + wordSim353AnnotDF_New['word2_kg_id'].to_list())\n",
    "        embed_size = len(embed_dict[next(iter(embed_dict))])\n",
    "        count = 0\n",
    "        for word in wordSim353AnnotDF_set:\n",
    "            if word not in embed_dict:\n",
    "                count += 1\n",
    "        return (len(wordSim353AnnotDF_New) - count)\n",
    "    \n",
    "    @classmethod\n",
    "    def determine_distances(cls, embed_dict, new_embed_dict):\n",
    "        dist = []\n",
    "        for word in embed_dict.keys():\n",
    "            dist.append(euclidean_distances([embed_dict[word]], [new_embed_dict[word]])[0][0])\n",
    "        return dist\n",
    "    \n",
    "    @classmethod\n",
    "    def serialize_embedding_dict(cls, embed_dict):\n",
    "        for key2 in embed_dict.keys():\n",
    "            embed_dict[key2] = embed_dict[key2].tolist() if type(embed_dict[key2]) != list else embed_dict[key2]\n",
    "        return embed_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def deserialize_embedding_dict(cls, embed_dict):\n",
    "        for key2 in embed_dict.keys():\n",
    "            embed_dict[key2] = np.array(embed_dict[key2])\n",
    "        return embed_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def label_samples(cls, score):\n",
    "        return 'I' if score <= 1.75 else 'U' if score >= 3.5 else 'M'\n",
    "    \n",
    "    @classmethod\n",
    "    def determine_cos_sim(cls, emb1, emb2):\n",
    "        return cosine_similarity(\n",
    "                np.array(emb1).reshape(1,-1), \n",
    "                np.array(emb2).reshape(1,-1)\n",
    "            )[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-rebate",
   "metadata": {},
   "source": [
    "## InputEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hollywood-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings:\n",
    "    \"\"\"\n",
    "    Instance variables:\n",
    "        - embed_dict_master - holds all qnode to embedding mappings as a dictionary\n",
    "        - embedding_names - list of all keys of the above dictionary\n",
    "    \"\"\"\n",
    "    def __init__(self, has_embeddings_include: bool = False):\n",
    "        self.embed_dict_master = {}\n",
    "        self.embedding_names = ['text_7_props', 'text_2_props', 'complex', 'transe', 'abstract', 'abstract_first_sent']\n",
    "        if has_embeddings_include: # TODO\n",
    "            self.embedding_names += ['h', 'a', 's']\n",
    "        self.embedding_lengths = {}\n",
    "        \n",
    "        for emb_key in tqdm(self.embedding_names, desc='Input Embeddings'):\n",
    "            self.embed_dict_master[emb_key] = self.fetch_embedding(emb_key)\n",
    "            \n",
    "        self.fetch_embedding_stats()\n",
    "        print(\"Fetched all input embeddings\")\n",
    "\n",
    "    def fetch_embedding(self, emb_key):\n",
    "        return Utils.fill_coverage(\n",
    "                Utils.deserialize_embedding_dict(\n",
    "                    json.load(open('../data/Master_P279_dataset/embeddings/'+emb_key+'_orig_embedding_dict_updated.json'))\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def fetch_embedding_stats(self):\n",
    "        for emb_name in embed_dict_master.keys():\n",
    "            embedding_lengths[emb_name] = len(next(iter(embedDictMaster[emb_name].values())))\n",
    "            print(f\"Embedding: {emb_name}, Length: {embedding_lengths[emb_name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-exhaust",
   "metadata": {},
   "source": [
    "## NeighborDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "saving-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborDatasets:\n",
    "    \"\"\"\n",
    "    Instance variables:\n",
    "        - neighbors_dict_master - holds all qnode to neighbor qnode mappings as a dictionary\n",
    "        - basis_list - list of all keys of the above dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, class_datasets_fetch: bool = False, probase_datasets_fetch: bool = False):\n",
    "        self.neighbors_dict_master = {}\n",
    "        \n",
    "        pbar = tqdm(desc='Neighbor Datasets', total = \n",
    "                    3 \n",
    "                    + (3 if class_datasets_fetch else 0) \n",
    "                    + (2 if probase_datasets_fetch else 0) \n",
    "                   )\n",
    "        \n",
    "        bert_P279_child_par_df = pd.read_csv('../data/Master_P279_dataset/P279ChildPar_transP279_filtered.csv')\n",
    "        bert_P279_siblings_df = pd.read_csv('../data/Master_P279_dataset/P279Siblings_transP279_filtered_min_cols_with_desc_dups_removed.csv')\n",
    "        \n",
    "        self.neighbors_dict_master['bert_child_par'] = self.fetch_neighbours(bert_P279_child_par_df)\n",
    "        pbar.update(1)\n",
    "        self.neighbors_dict_master['bert_siblings'] = self.fetch_neighbours(bert_P279_siblings_df)\n",
    "        pbar.update(1)\n",
    "        self.neighbors_dict_master['bert_all'] = self.fetch_neighbours(pd.concat([\n",
    "                bert_P279_child_par_df, bert_P279_siblings_df\n",
    "            ]))\n",
    "        pbar.update(1)\n",
    "            \n",
    "        if class_datasets_fetch:\n",
    "            class_P279_child_par_df = pd.read_csv('../data/Master_P279_dataset/P279ChildPar_transP279_filtered_w_classSim.csv')\n",
    "            class_P279_child_par_df['similarity_value'] = class_P279_child_par_df['classSim']\n",
    "            \n",
    "            class_P279_siblings_df = pd.read_csv('../data/Master_P279_dataset/P279Siblings_transP279_filtered_w_classSim.csv')\n",
    "            class_P279_siblings_df['similarity_value'] = class_P279_siblings_df['classSim']\n",
    "            \n",
    "            self.neighbors_dict_master['class_child_par'] = self.fetch_neighbours(class_P279_child_par_df)\n",
    "            pbar.update(1)\n",
    "            self.neighbors_dict_master['class_siblings'] = self.fetch_neighbours(class_P279_siblings_df)\n",
    "            pbar.update(1)\n",
    "            self.neighbors_dict_master['class_all'] = self.fetch_neighbours(pd.concat([\n",
    "                    class_P279_child_par_df, class_P279_siblings_df\n",
    "                ]))\n",
    "            pbar.update(1)\n",
    "\n",
    "        if probase_datasets_fetch:\n",
    "            probase_df = self.fetch_probase('../data/probase/probase_WQnodes_subset_and_sim.csv')\n",
    "            \n",
    "            self.neighbors_dict_master['probase'] = self.fetch_neighbours(probase_df)\n",
    "            pbar.update(1)\n",
    "            self.neighbors_dict_master['probase+bert_all'] = self.fetch_neighbours(pd.concat([\n",
    "                    bert_P279_child_par_df, bert_P279_siblings_df, probase_df\n",
    "                ]))\n",
    "            pbar.update(1)\n",
    "        \n",
    "        self.basis_list = list(neighbors_dict_master.keys())\n",
    "        \n",
    "        pbar.close()\n",
    "\n",
    "        print(f\"Fetched neighbour datasets: {self.basis_list}\")\n",
    "    \n",
    "    def process_probase(self, probase_file_path):\n",
    "        probase_df = pd.read_csv(probase_file_path)\n",
    "        probase_df = probase_df.rename(columns={'n1_final_qnode': 'node1', 'n2_final_qnode': 'node2', 'sim': 'similarity_value'})\n",
    "        probase_df['similarity_value'] = 0.5 + 0.5 * probase_df['similarity_value']\n",
    "        \n",
    "        return probase_df\n",
    "        \n",
    "    def fetch_neighbours(self, df):\n",
    "        neighbours_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            if row.node1 not in neighbours_dict:\n",
    "                neighbours_dict[row.node1] = []\n",
    "            neighbours_dict[row.node1].append((row.node2, row.bert2SentSim))\n",
    "\n",
    "            if row.node2 not in neighbours_dict:\n",
    "                neighbours_dict[row.node2] = []\n",
    "            neighbours_dict[row.node2].append((row.node1, row.bert2SentSim))\n",
    "#         print(max([len(neigh) for neigh in neighbours_dict.values()]))\n",
    "        \n",
    "        return neighbours_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-pitch",
   "metadata": {},
   "source": [
    "## EvaluationDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rough-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationDatasets:\n",
    "    def __init__(self):\n",
    "        self.wordsim_df = pd.read_csv('../data/wordsim353_with_r3.csv')\n",
    "        self.fetch_distribution_stats(\"Wordsim-353\", self.wordsim_df)\n",
    "        \n",
    "        self.wiki_cs_df = pd.read_csv('../data/wikidata-cs_categorized.csv')\n",
    "        self.fetch_distribution_stats(\"Wikidata CS\", self.wiki_cs_df)\n",
    "        \n",
    "        self.concept_net_df = pd.read_csv('../data/kgtk_conceptnet_evaluation.csv')\n",
    "        self.fetch_distribution_stats(\"Concept Net\", self.concept_net_df)\n",
    "        \n",
    "    def fetch_distribution_stats(self, name, dataset):\n",
    "        print(f\"Dataset: {name}\")\n",
    "        print(dataset.category.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-color",
   "metadata": {},
   "source": [
    "## ResultMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "returning-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultMetrics:\n",
    "    \n",
    "    @classmethod\n",
    "    def compute_classification_results(\n",
    "            embed_dict, \n",
    "            eval_dataset,\n",
    "            get_output_values: bool,\n",
    "            old_accuracy = None\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - embed_dict - dictionary of qnodes with node embeddings as its values\n",
    "            - eval_dataset - evaluation dataset as pandas dataframe that must have the \n",
    "                following columns for this function to work correctly:\n",
    "                * word1_kg_id - Qnode of node1 in the evaluation pair\n",
    "                * word2_kg_id - Qnode of node2 in the evaluation pair\n",
    "                * category - Category of the evaluation pair. One of the labels: I/U/M\n",
    "        Outputs:\n",
    "            - response_dict - Returns a dictionary with the following keys:\n",
    "                * covered_pairs - Indicates the number of pairs of the evaluation dataset that the \n",
    "                    embedding dictionary can cover\n",
    "                \n",
    "        \"\"\"\n",
    "        response_dict = {}\n",
    "        \n",
    "        eval_dataset = eval_dataset.copy()\n",
    "\n",
    "        missing_words_set = set(\n",
    "            eval_dataset[eval_dataset.word1_kg_id.apply(lambda p: p not in embed_dict)].word1_kg_id.to_list() \n",
    "            + eval_dataset[eval_dataset.word2_kg_id.apply(lambda p: p not in embed_dict)].word2_kg_id.to_list()\n",
    "        )\n",
    "        \n",
    "        response_dict['covered_pairs'] = len(eval_dataset)\n",
    "\n",
    "        eval_dataset['embedding_cos_sim'] = eval_dataset.apply(lambda p: determine_cos_sim(embed_dict[p['word1_kg_id']], embed_dict[p['word2_kg_id']]) \n",
    "                                                   if p['word1_kg_id'] in embed_dict and p['word2_kg_id'] in embed_dict \n",
    "                                                   else None, axis=1)\n",
    "        \n",
    "        eval_dataset['embedding_cos_sim'].fillna(eval_dataset['embedding_cos_sim'].mean(skipna=True), inplace=True)\n",
    "        \n",
    "        # Scale abs value of cosine similarities to 1,4 strictly\n",
    "        eval_dataset['embedding_cos_sim'] = eval_dataset['embedding_cos_sim'].apply(lambda p: 4 - 3 * abs(p))\n",
    "\n",
    "#         response_dict['KT_old_vs_Avg'] = stats.kendalltau(wordSim353AnnotDF_New['textOld'], wordSim353AnnotDF_New['Avg'])\n",
    "#         response_dict['KT_new_vs_Avg'] = stats.kendalltau(wordSim353AnnotDF_New['textNew'], wordSim353AnnotDF_New['Avg'])\n",
    "#         response_dict['KT_old_vs_Human'] = stats.kendalltau(wordSim353AnnotDF_New['textOld'], wordSim353AnnotDF_New['H_reversed'])\n",
    "#         response_dict['KT_new_vs_Human'] = stats.kendalltau(wordSim353AnnotDF_New['textNew'], wordSim353AnnotDF_New['H_reversed'])\n",
    "        response_dict['accuracy'] = 100 * accuracy_score(\n",
    "                eval_dataset['category'],\n",
    "                eval_dataset['embedding_cos_sim'].apply(label_samples)\n",
    "            )\n",
    "    \n",
    "        response_dict['classification_report'] = classification_report(\n",
    "                eval_dataset['category'], \n",
    "                eval_dataset['embedding_cos_sim'].apply(label_samples), \n",
    "                output_dict=True\n",
    "            )\n",
    "\n",
    "        response_dict['conf_matrix'] = confusion_matrix(\n",
    "                eval_dataset['category'], \n",
    "                eval_dataset['embedding_cos_sim'].apply(label_samples), \n",
    "                labels=LABELS\n",
    "            )\n",
    "        \n",
    "        if old_accuracy is not None:\n",
    "            response_dict['increase_acc'] = response_dict['accuracy'] - old_accuracy\n",
    "        else:\n",
    "            response_dict['increase_acc'] = None\n",
    "        \n",
    "        if get_output_values:\n",
    "            response_dict['preds'] = eval_dataset['embedding_cos_sim'].apply(label_samples)\n",
    "\n",
    "        return response_dict, \\\n",
    "                (response_dict['covered_pairs'],  \\\n",
    "                 response_dict['accuracy'], \\\n",
    "                 response_dict['increase_acc'], \\\n",
    "                 \n",
    "                 response_dict['classification_report']['I']['precision'],  \\\n",
    "                 response_dict['classification_report']['I']['recall'],  \\\n",
    "                 response_dict['classification_report']['I']['f1-score'],   \\\n",
    "                 \n",
    "                 response_dict['classification_report']['M']['precision'],  \\\n",
    "                 response_dict['classification_report']['M']['recall'],  \\\n",
    "                 response_dict['classification_report']['M']['f1-score'], \\\n",
    "                 \n",
    "                 response_dict['classification_report']['U']['precision'],  \\\n",
    "                 response_dict['classification_report']['U']['recall'],  \\\n",
    "                 response_dict['classification_report']['U']['f1-score'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-raleigh",
   "metadata": {},
   "source": [
    "## RetrofittingProcedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interior-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrofittingProcedures:\n",
    "    \n",
    "    np_label_samples = np.vectorize(Utils.label_samples)\n",
    "    \n",
    "    @classmethod\n",
    "    def retrofit(embed_dict, neighbors_dict, weight_case, weight_assignment=False):\n",
    "        new_embed_dict = {}\n",
    "        for word in embed_dict.keys():\n",
    "            if word in neighbors_dict:\n",
    "                neighbs = neighbors_dict[word]\n",
    "                neighbs = list(filter(lambda p: p[0] in embed_dict, neighbs))\n",
    "                if len(neighbs) == 0:\n",
    "                    new_embed_dict[word] = embed_dict[word]\n",
    "                    continue\n",
    "                if weight_assignment:\n",
    "                    sum_of_sims = sum([neighb[1] for neighb in neighbs])\n",
    "                    sum_of_embs = sum([embed_dict[neighb[0]] * float(neighb[1]) for neighb in neighbs])\n",
    "                else:\n",
    "                    sum_of_sims = sum([1 for neighb in neighbs])\n",
    "                    sum_of_embs = sum([embed_dict[neighb[0]] for neighb in neighbs])\n",
    "\n",
    "                if weight_case == 1:\n",
    "                    new_embed_dict[word] = (embed_dict[word] * (len(neighbs)) + sum_of_embs) / ((len(neighbs)) + sum_of_sims)\n",
    "                elif weight_case == 2:\n",
    "                    new_embed_dict[word] = (embed_dict[word] * (len(neighbs))**2 + sum_of_embs) / ((len(neighbs))**2 + sum_of_sims)\n",
    "                elif weight_case == 0.5:\n",
    "                    new_embed_dict[word] = (embed_dict[word] * (len(neighbs))**0.5 + sum_of_embs) / ((len(neighbs))**0.5 + sum_of_sims)\n",
    "                else:\n",
    "                    raise\n",
    "            else:\n",
    "                new_embed_dict[word] = embed_dict[word]\n",
    "        return new_embed_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def execute_all_unsupervised_scenarios(\n",
    "                emb_list, basis_list, \n",
    "                embed_dict_master, neigh_dict_master,\n",
    "                eval_dataset,\n",
    "                scenario_name: str,\n",
    "                num_of_iterations: int = 3, \n",
    "                weightedness_list: list = [True],\n",
    "                weight_cases_list: list = [1,2],\n",
    "                get_output_values: bool = False\n",
    "            ):\n",
    "        \n",
    "        new_embed_dict_master = {}\n",
    "        responses_dict_master = {}\n",
    "        results = []\n",
    "        \n",
    "        for basis in tqdm(basis_list, desc='Basis', leave=False):\n",
    "            for emb in tqdm(emb_list, desc='Embedding', leave=False):\n",
    "                for weightedness in weightedness_list:\n",
    "                    for weight_case in tqdm(weight_cases_list, desc='Weight Case', leave=False):\n",
    "                        # Base Reference Initializations and Calculations\n",
    "                        embed_dict = embed_dict_master[emb]\n",
    "                        responses_dict, result_values = compute_classification_results(\n",
    "                            embed_dict, eval_dataset, get_output_values=get_output_values, old_accuracy=None)\n",
    "                        results.append(emb, basis, weight_case, weightedness, 0, 'base', *result_values)\n",
    "                        old_accuracy = responses_dict['accuracy']\n",
    "                        \n",
    "                        for iter_num in tqdm(range(1,num_of_iterations+1), desc='Iteration', leave=False):\n",
    "                            start_time = time()\n",
    "                            \n",
    "                            case_name = emb + '_' + basis + '_' + str(weight_case) + ('_weighted' if weightedness else '_unweighted')\n",
    "                            \n",
    "                            new_embed_dict = retrofit(embed_dict[weight_case], neigh_dict_master[basis], weight_case, weightedness)\n",
    "                            \n",
    "                            responses_dict, result_values = compute_classification_results(\n",
    "                                new_embed_dict, eval_dataset, get_output_values=get_output_values, old_accuracy=old_accuracy)\n",
    "                            \n",
    "                            results.append([emb, basis, weight_case, weightedness, iter_num, case_name, \\\n",
    "                                                *result_values, \\\n",
    "                                                time() - start_time\n",
    "                                            ])\n",
    "                            \n",
    "                            new_embed_dict_master[case_name] = embed_dict = new_embed_dict\n",
    "                            responses_dict_master[case_name] = responses_dict\n",
    "\n",
    "        #                     if iter_num == num_of_iterations and highestOne:\n",
    "        #                         case_name = gR[0] + '_' + gR[1] + '_' + str(gR[2]) + '_weighted'\n",
    "        #                         new_embed_dict_master[case_name] = serializeEmbeddingDict(new_embed_dict_master[case_name])\n",
    "        #                         highestOne = False\n",
    "        #                         json.dump(new_embed_dict_master[case_name],open('../data/Master_P279_dataset/embeddings/new_embedding_dict_'+case_name+'.json','w'))\n",
    "        #                         new_embed_dict_master[case_name] = deserializeEmbeddingDict(new_embed_dict_master[case_name])\n",
    "        resultsDF = pd.DataFrame(results, columns=['Embedding', 'Basis', 'Weight Case', 'Weightedness', \n",
    "                                                   'Iteration Num', 'Case Name', \\\n",
    "                                                   'No. of Pairs Covered', 'Accuracy', 'Increase in Accuracy', \\\n",
    "                                                   'I Precision', 'I Recall', 'I F1-Score', \\\n",
    "                                                   'M Precision', 'M Recall', 'M F1-Score', \\\n",
    "                                                   'U Precision', 'U Recall', 'U F1-Score', \\\n",
    "                                                   'Time to Retrofit'])\n",
    "        resultsDF.to_csv('../data/retrofitting/retro_results.' + scenario_name + '.'+ Utils.today_date +'.csv', index=False)\n",
    "        \n",
    "        return new_embed_dict_master, responses_dict_master\n",
    "    \n",
    "    @classmethod\n",
    "    def execute_supervised_scenario(\n",
    "                eval_dataset, case, embed_dict_master, new_embed_dict_master, \n",
    "                num_of_splits = 10, \n",
    "                concat_mode: bool = False, SVC_or_SVR: str = 'SVC'\n",
    "            ):\n",
    "        \n",
    "        X = []        \n",
    "        \n",
    "        ################\n",
    "        # 2 Approaches based on argument: `concat_mode`\n",
    "        ################\n",
    "        \n",
    "        if concat_mode: ########## CONCAT MODE CODE ####################\n",
    "            case_name = \" & \".join(case['emb']) + '_' + case['basis'] + '_' + str(case['weight_case']) + ('_weighted' if case['weightedness'] else '_unweighted')\n",
    "            \n",
    "            for _, row in eval_dataset.iterrows():\n",
    "                if case['svm_input'] == 'emb':\n",
    "                    tempX = []\n",
    "                    for individual_emb in case['emb']:\n",
    "                        ind_case_name = individual_emb + '_' + case['basis'] + '_' + str(case['weight_case']) + ('_weighted' if case['weightedness'] else '_unweighted')\n",
    "                        if case['iter_num'] != 0 and ind_case_name not in new_embed_dict_master:\n",
    "                            return case_name, case, None\n",
    "                        if case['iter_num'] == 0:\n",
    "                            tempX += embed_dict_master[individual_emb][row['word1_kg_id']].tolist() + embedDictMaster[individual_emb][row['word2_kg_id']].tolist()\n",
    "                        else:\n",
    "                            tempX += new_embed_dict_master[ind_case_name][row['word1_kg_id']].tolist() + newEmbedDictMaster[ind_case_name][row['word2_kg_id']].tolist()\n",
    "                    X.append(tempX)\n",
    "                else:\n",
    "                    tempX = []\n",
    "                    for individual_emb in case['emb']:\n",
    "                        ind_case_name = individual_emb + '_' + case['basis'] + '_' + str(case['weight_case']) + ('_weighted' if case['weightedness'] else '_unweighted')\n",
    "                        if case['iter_num'] != 0 and ind_case_name not in new_embed_dict_master:\n",
    "                            return case_name, case, None\n",
    "                        if case['iter_num'] == 0:\n",
    "                            tempX.append(abs(Utils.determine_cos_sim(\n",
    "                                embed_dict_master[individual_emb][row['word1_kg_id']], \n",
    "                                embed_dict_master[individual_emb][row['word2_kg_id']]\n",
    "                            )))\n",
    "                        else:\n",
    "                            tempX.append(abs(Utils.determine_cos_sim(\n",
    "                                new_embed_dict_master[ind_case_name][row['word1_kg_id']],\n",
    "                                new_embed_dict_master[ind_case_name][row['word2_kg_id']]\n",
    "                            )))\n",
    "                    X.append(tempX)\n",
    "\n",
    "        else: ########## NON-CONCAT MODE CODE ####################\n",
    "            case_name = case['emb'] + '_' + case['basis'] + '_' + str(case['weight_case']) + ('_weighted' if case['weightedness'] else '_unweighted')\n",
    "            if case['iter_num'] != 0 and case_name not in new_embed_dict_master:\n",
    "                return case_name, case, None\n",
    "            for _, row in eval_dataset.iterrows():\n",
    "                if case['svm_input'] == 'emb':\n",
    "                    if case['iter_num'] == 0:\n",
    "                        X.append(embed_dict_master[case['emb']][row['word1_kg_id']].tolist() + embed_dict_master[case['emb']][row['word2_kg_id']].tolist())\n",
    "                    else:\n",
    "                        X.append(new_embed_dict_master[case_name][row['word1_kg_id']].tolist() + new_embed_dict_master[case_name][row['word2_kg_id']].tolist())\n",
    "                else:\n",
    "                    if case['iter_num'] == 0:\n",
    "                        X.append(abs(Utils.determine_cos_sim(\n",
    "                                embed_dict_master[case['emb']][row['word1_kg_id']], \n",
    "                                embed_dict_master[case['emb']][row['word2_kg_id']]\n",
    "                            )))\n",
    "                    else:\n",
    "                        X.append(abs(Utils.determine_cos_sim(\n",
    "                                new_embed_dict_master[case_name][row['word1_kg_id']],\n",
    "                                new_embed_dict_master[case_name][row['word2_kg_id']]\n",
    "                            )))\n",
    "                    \n",
    "        X = pd.DataFrame(X)\n",
    "        \n",
    "        ################\n",
    "        # 2 Approaches based on argument: `SVC_or_SVR`\n",
    "        ################\n",
    "        \n",
    "        # Target split depending on SVC or SVM\n",
    "        if SVC_or_SVR == 'SVC':\n",
    "            Y = eval_dataset['category']\n",
    "        elif SVC_or_SVR == 'SVR':\n",
    "            if 'Avg' not in eval_dataset.columns:\n",
    "                raise ValueError(\"Avg column not present in the provided eval_dataset\")\n",
    "            Y = (eval_dataset['Avg'] - 1) / 3\n",
    "        else:\n",
    "            raise ValueError(\"Invalid SVC_or_SVR provided\")\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=num_of_splits, random_state=19, shuffle=True)\n",
    "        X_train_splits, X_test_splits, Y_train_splits, Y_test_splits = [], [], [], []\n",
    "        for train_index, test_index in skf.split(X, Y):\n",
    "            X_train_splits.append(X.iloc[train_index])\n",
    "            X_test_splits.append(X.iloc[test_index])\n",
    "            Y_train_splits.append(Y.iloc[train_index])\n",
    "            Y_test_splits.append(Y.iloc[test_index])\n",
    "\n",
    "        preds = []\n",
    "        tempVals = []\n",
    "        \n",
    "        # Classifier/Regressor training depending on SVC or SVM\n",
    "        if SVC_or_SVR == 'SVC':\n",
    "            for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "                clf = make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=100, max_iter=100))\n",
    "                clf.fit(X_train1, Y_train1)\n",
    "                preds.append(clf.predict(X_test1))\n",
    "                \n",
    "            acc = 0\n",
    "            for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "                acc += accuracy_score(pred, Y_test1)\n",
    "\n",
    "            return case_name, *list(case.values()), acc/num_of_splits\n",
    "        \n",
    "        elif SVC_or_SVR == 'SVR':\n",
    "            for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "                clf = make_pipeline(StandardScaler(), SVR(gamma='auto', max_iter=100))\n",
    "                clf.fit(X_train1, Y_train1)\n",
    "                preds.append(clf.predict(X_test1))\n",
    "            \n",
    "            acc = 0\n",
    "            for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "                acc += mean_squared_error(pred * 3 + 1, Y_test1 * 3 + 1)\n",
    "                \n",
    "            return case_name, *list(case.values()), acc/num_of_splits\n",
    "    \n",
    "    @classmethod\n",
    "    def execute_all_supervised_scenarios(\n",
    "                eval_dataset, case, embed_dict_master, new_embed_dict_master,\n",
    "                num_of_splits = 10,\n",
    "                concat_mode: bool = False, SVC_or_SVR: str = 'SVC'\n",
    "            ):\n",
    "\n",
    "\n",
    "        results = Parallel(n_jobs=3)(delayed(execute_supervised_scenario)(\n",
    "                eval_dataset, caseDict, embed_dict_master, \n",
    "                new_embed_dict_master,num_of_spli,\n",
    "                concat_mode, SVC_or_SVR\n",
    "            ) for caseDict in tqdm(svmCasesList))\n",
    "        # print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-projector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caring-hamilton",
   "metadata": {},
   "source": [
    "# The Master Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-moscow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5fa2d2cf8f4f799e107c1f1c6c4574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Input Embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 11 corrections\n",
      "Added 11 corrections\n",
      "Added 0 corrections\n",
      "Added 0 corrections\n"
     ]
    }
   ],
   "source": [
    "inp = InputEmbeddings()\n",
    "basis = NeighborDatasets()\n",
    "evalD = EvaluationDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-commissioner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hundred-virus",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "limited-hormone",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bioDF = pd.read_csv('../data/pedersen2007measures_table1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alien-happiness",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term1</th>\n",
       "      <th>Term1_kg_id</th>\n",
       "      <th>Term1_kg_label</th>\n",
       "      <th>Term1_description</th>\n",
       "      <th>Term2</th>\n",
       "      <th>Term2_kg_id</th>\n",
       "      <th>Term2_kg_label</th>\n",
       "      <th>Term2_description</th>\n",
       "      <th>Physician</th>\n",
       "      <th>Coder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Renal failure</td>\n",
       "      <td>Q476921</td>\n",
       "      <td>kidney failure</td>\n",
       "      <td>disease where the kidneys fail to adequately f...</td>\n",
       "      <td>Kidney failure</td>\n",
       "      <td>Q476921</td>\n",
       "      <td>kidney failure</td>\n",
       "      <td>disease where the kidneys fail to adequately f...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Q1072</td>\n",
       "      <td>heart</td>\n",
       "      <td>organ for the circulation of blood in animal c...</td>\n",
       "      <td>Myocardium</td>\n",
       "      <td>Q84133</td>\n",
       "      <td>myocardium</td>\n",
       "      <td>middle layer of the heart wall, which consists...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stroke</td>\n",
       "      <td>Q12202</td>\n",
       "      <td>stroke</td>\n",
       "      <td>problem with the arteries supplying blood to t...</td>\n",
       "      <td>Infarct</td>\n",
       "      <td>Q207550</td>\n",
       "      <td>infarction</td>\n",
       "      <td>tissue death caused by a local lack of oxygen,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abortion</td>\n",
       "      <td>Q8452</td>\n",
       "      <td>abortion</td>\n",
       "      <td>intentional ending of a pregnancy</td>\n",
       "      <td>Miscarriage</td>\n",
       "      <td>Q28693</td>\n",
       "      <td>miscarriage</td>\n",
       "      <td>natural death of an embryo or fetus before it ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delusion</td>\n",
       "      <td>Q189643</td>\n",
       "      <td>delusion</td>\n",
       "      <td>firm and fixed belief based on inadequate grou...</td>\n",
       "      <td>Schizophrenia</td>\n",
       "      <td>Q41112</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>psychotic disorder characterized by emotional ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Term1 Term1_kg_id  Term1_kg_label  \\\n",
       "0  Renal failure     Q476921  kidney failure   \n",
       "1          Heart       Q1072           heart   \n",
       "2         Stroke      Q12202          stroke   \n",
       "3       Abortion       Q8452        abortion   \n",
       "4       Delusion     Q189643        delusion   \n",
       "\n",
       "                                   Term1_description           Term2  \\\n",
       "0  disease where the kidneys fail to adequately f...  Kidney failure   \n",
       "1  organ for the circulation of blood in animal c...      Myocardium   \n",
       "2  problem with the arteries supplying blood to t...         Infarct   \n",
       "3                  intentional ending of a pregnancy     Miscarriage   \n",
       "4  firm and fixed belief based on inadequate grou...   Schizophrenia   \n",
       "\n",
       "  Term2_kg_id  Term2_kg_label  \\\n",
       "0     Q476921  kidney failure   \n",
       "1      Q84133      myocardium   \n",
       "2     Q207550      infarction   \n",
       "3      Q28693     miscarriage   \n",
       "4      Q41112   schizophrenia   \n",
       "\n",
       "                                   Term2_description  Physician  Coder  \n",
       "0  disease where the kidneys fail to adequately f...        4.0    4.0  \n",
       "1  middle layer of the heart wall, which consists...        3.3    3.0  \n",
       "2  tissue death caused by a local lack of oxygen,...        3.0    2.8  \n",
       "3  natural death of an embryo or fetus before it ...        3.0    3.3  \n",
       "4  psychotic disorder characterized by emotional ...        3.0    2.2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bioDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "parental-event",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bioDFNodesSet = set(bioDF.Term1_kg_id.to_list() + bioDF.Term2_kg_id.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wicked-proportion",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "P279childParNodesSet = set(p279WordSimSeededDF_wabs_text.node1.to_list() + p279WordSimSeededDF_wabs_text.node2.to_list())\n",
    "P279siblingsNodesSet = set(p279Seeded_SiblingsDF3_wabs_text.node1.to_list() + p279Seeded_SiblingsDF3_wabs_text.node2.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pediatric-tomato",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bioDF.Term1_kg_id.apply(lambda p: p in P279childParNodesSet or p in P279siblingsNodesSet)), \\\n",
    "sum(bioDF.Term2_kg_id.apply(lambda p: p in P279childParNodesSet or p in P279siblingsNodesSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "transparent-diversity",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 25)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probaseNodesSet = set(probDF_Qnodes_DF_WQnodes1_subset.node1.to_list() + probDF_Qnodes_DF_WQnodes1_subset.node2.to_list())\n",
    "\n",
    "sum(bioDF.Term1_kg_id.apply(lambda p: p in probaseNodesSet)), \\\n",
    "sum(bioDF.Term2_kg_id.apply(lambda p: p in probaseNodesSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-civilian",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-logic",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "incoming-calvin",
   "metadata": {},
   "source": [
    "# Correlation Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-bacon",
   "metadata": {},
   "source": [
    "# Dataset-Target Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-forth",
   "metadata": {},
   "source": [
    "## Retrofitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-ecuador",
   "metadata": {},
   "source": [
    "### Retrofitting using combination of input and basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-finding",
   "metadata": {},
   "source": [
    "### Retrofitting using combination - selected few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "naked-artist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Weightedness</th>\n",
       "      <th>Iteration Num</th>\n",
       "      <th>Old Acc</th>\n",
       "      <th>New Acc</th>\n",
       "      <th>Increase</th>\n",
       "      <th>Pairs Covered</th>\n",
       "      <th>Old I Precision</th>\n",
       "      <th>...</th>\n",
       "      <th>Old U F1-Score</th>\n",
       "      <th>New I Precision</th>\n",
       "      <th>New I Recall</th>\n",
       "      <th>New I F1-Score</th>\n",
       "      <th>New U Precision</th>\n",
       "      <th>New U Recall</th>\n",
       "      <th>New U F1-Score</th>\n",
       "      <th>Avg F1-Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>19k_class_childPar</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>63.953488</td>\n",
       "      <td>64.244186</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>344</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>0.459021</td>\n",
       "      <td>2.365892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abstract_first_sent</td>\n",
       "      <td>19k_class_siblings</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>65.697674</td>\n",
       "      <td>65.697674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>344</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.067961</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.485447</td>\n",
       "      <td>10.267434</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complex</td>\n",
       "      <td>19k_childPar</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>68.023256</td>\n",
       "      <td>67.732558</td>\n",
       "      <td>-0.290698</td>\n",
       "      <td>344</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463158</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.443243</td>\n",
       "      <td>0.652007</td>\n",
       "      <td>15.403201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text_2_props</td>\n",
       "      <td>19k_2_class</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>56.686047</td>\n",
       "      <td>56.104651</td>\n",
       "      <td>-0.581395</td>\n",
       "      <td>344</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.389309</td>\n",
       "      <td>45.090151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text_7_props</td>\n",
       "      <td>19k_class_childPar</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>57.267442</td>\n",
       "      <td>56.976744</td>\n",
       "      <td>-0.290698</td>\n",
       "      <td>344</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.403457</td>\n",
       "      <td>7.334071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>transe</td>\n",
       "      <td>19k_class_childPar</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>65.406977</td>\n",
       "      <td>65.406977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>344</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.564948</td>\n",
       "      <td>16.995019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Embedding               Basis  Weight  Weightedness  \\\n",
       "0             abstract  19k_class_childPar       2          True   \n",
       "1  abstract_first_sent  19k_class_siblings       2          True   \n",
       "2              complex        19k_childPar       1          True   \n",
       "3         text_2_props         19k_2_class       2          True   \n",
       "4         text_7_props  19k_class_childPar       2          True   \n",
       "5               transe  19k_class_childPar       1          True   \n",
       "\n",
       "   Iteration Num    Old Acc    New Acc  Increase  Pairs Covered  \\\n",
       "0              1  63.953488  64.244186  0.290698            344   \n",
       "1              1  65.697674  65.697674  0.000000            344   \n",
       "2              4  68.023256  67.732558 -0.290698            344   \n",
       "3              1  56.686047  56.104651 -0.581395            344   \n",
       "4              1  57.267442  56.976744 -0.290698            344   \n",
       "5              4  65.406977  65.406977  0.000000            344   \n",
       "\n",
       "   Old I Precision  ...  Old U F1-Score  New I Precision  New I Recall  \\\n",
       "0         0.461538  ...        0.089286         0.468750          0.75   \n",
       "1         0.500000  ...        0.155172         0.520000          0.65   \n",
       "2         0.923077  ...        0.463158         0.923077          0.60   \n",
       "3         0.292683  ...        0.065574         0.288889          0.65   \n",
       "4         0.325000  ...        0.065574         0.340909          0.75   \n",
       "5         0.652174  ...        0.231884         0.640000          0.80   \n",
       "\n",
       "   New I F1-Score  New U Precision  New U Recall  New U F1-Score  \\\n",
       "0        0.576923         0.666667      0.038835        0.073394   \n",
       "1        0.577778         0.700000      0.067961        0.123894   \n",
       "2        0.727273         0.500000      0.398058        0.443243   \n",
       "3        0.400000         0.210526      0.038835        0.065574   \n",
       "4        0.468750         0.166667      0.029126        0.049587   \n",
       "5        0.711111         0.454545      0.145631        0.220588   \n",
       "\n",
       "   Avg F1-Score       Time  Rank  \n",
       "0      0.459021   2.365892     0  \n",
       "1      0.485447  10.267434     0  \n",
       "2      0.652007  15.403201     0  \n",
       "3      0.389309  45.090151     0  \n",
       "4      0.403457   7.334071     0  \n",
       "5      0.564948  16.995019     0  \n",
       "\n",
       "[6 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "choice-brazilian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['abstract_19k_class_childPar_2_weighted', 'abstract_first_sent_19k_class_siblings_2_weighted', 'complex_19k_childPar_1_weighted', 'text_2_props_19k_2_class_2_weighted', 'text_7_props_19k_class_childPar_2_weighted', 'transe_19k_class_childPar_1_weighted'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responsesDictMaster.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "naughty-soccer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13,   0,   7],\n",
       "       [  0,   7,  96],\n",
       "       [ 12,   3, 206]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responsesDictMaster['abstract_first_sent_19k_class_siblings_2_weighted']['cm_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "common-certificate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'BERT abstract_first_sent confusion matrix')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "sns.heatmap(responsesDictMaster['abstract_first_sent_19k_class_siblings_2_weighted']['cm_new'], xticklabels=['I', 'U', 'M'], yticklabels=['I', 'U', 'M'], annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('BERT abstract_first_sent confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bearing-retail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'BERT text_7_props confusion matrix')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "sns.heatmap(responsesDictMaster['text_7_props_19k_class_childPar_2_weighted']['cm_new'], xticklabels=['I', 'U', 'M'], yticklabels=['I', 'U', 'M'], annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('BERT text_7_props confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "approximate-showcase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'BERT complex confusion matrix')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "sns.heatmap(responsesDictMaster['complex_19k_childPar_1_weighted']['cm_new'], xticklabels=['I', 'U', 'M'], yticklabels=['I', 'U', 'M'], annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('BERT complex confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-treatment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "stable-shark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9331395348837209"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(responsesDictMaster['abstract_19k_class_childPar_2_weighted']['newOP'], responsesDictMaster['abstract_first_sent_19k_class_siblings_2_weighted']['newOP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "appointed-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7877906976744186"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(responsesDictMaster['complex_19k_childPar_1_weighted']['newOP'], responsesDictMaster['transe_19k_class_childPar_1_weighted']['newOP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "affiliated-wholesale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7005813953488372"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(responsesDictMaster['complex_19k_childPar_1_weighted']['newOP'], responsesDictMaster['abstract_first_sent_19k_class_siblings_2_weighted']['newOP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "hawaiian-worker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_19k_class_childPar_2_weighted</th>\n",
       "      <th>abstract_first_sent_19k_class_siblings_2_weighted</th>\n",
       "      <th>complex_19k_childPar_1_weighted</th>\n",
       "      <th>text_2_props_19k_2_class_2_weighted</th>\n",
       "      <th>text_7_props_19k_class_childPar_2_weighted</th>\n",
       "      <th>transe_19k_class_childPar_1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abstract_19k_class_childPar_2_weighted</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933140</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.857558</td>\n",
       "      <td>0.880814</td>\n",
       "      <td>0.811047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_first_sent_19k_class_siblings_2_weighted</th>\n",
       "      <td>0.933140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700581</td>\n",
       "      <td>0.834302</td>\n",
       "      <td>0.845930</td>\n",
       "      <td>0.816860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex_19k_childPar_1_weighted</th>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.700581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619186</td>\n",
       "      <td>0.630814</td>\n",
       "      <td>0.787791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_2_props_19k_2_class_2_weighted</th>\n",
       "      <td>0.857558</td>\n",
       "      <td>0.834302</td>\n",
       "      <td>0.619186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959302</td>\n",
       "      <td>0.735465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_7_props_19k_class_childPar_2_weighted</th>\n",
       "      <td>0.880814</td>\n",
       "      <td>0.845930</td>\n",
       "      <td>0.630814</td>\n",
       "      <td>0.959302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.747093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transe_19k_class_childPar_1_weighted</th>\n",
       "      <td>0.811047</td>\n",
       "      <td>0.816860</td>\n",
       "      <td>0.787791</td>\n",
       "      <td>0.735465</td>\n",
       "      <td>0.747093</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   abstract_19k_class_childPar_2_weighted  \\\n",
       "abstract_19k_class_childPar_2_weighted                                           1.000000   \n",
       "abstract_first_sent_19k_class_siblings_2_weighted                                0.933140   \n",
       "complex_19k_childPar_1_weighted                                                  0.697674   \n",
       "text_2_props_19k_2_class_2_weighted                                              0.857558   \n",
       "text_7_props_19k_class_childPar_2_weighted                                       0.880814   \n",
       "transe_19k_class_childPar_1_weighted                                             0.811047   \n",
       "\n",
       "                                                   abstract_first_sent_19k_class_siblings_2_weighted  \\\n",
       "abstract_19k_class_childPar_2_weighted                                                      0.933140   \n",
       "abstract_first_sent_19k_class_siblings_2_weighted                                           1.000000   \n",
       "complex_19k_childPar_1_weighted                                                             0.700581   \n",
       "text_2_props_19k_2_class_2_weighted                                                         0.834302   \n",
       "text_7_props_19k_class_childPar_2_weighted                                                  0.845930   \n",
       "transe_19k_class_childPar_1_weighted                                                        0.816860   \n",
       "\n",
       "                                                   complex_19k_childPar_1_weighted  \\\n",
       "abstract_19k_class_childPar_2_weighted                                    0.697674   \n",
       "abstract_first_sent_19k_class_siblings_2_weighted                         0.700581   \n",
       "complex_19k_childPar_1_weighted                                           1.000000   \n",
       "text_2_props_19k_2_class_2_weighted                                       0.619186   \n",
       "text_7_props_19k_class_childPar_2_weighted                                0.630814   \n",
       "transe_19k_class_childPar_1_weighted                                      0.787791   \n",
       "\n",
       "                                                   text_2_props_19k_2_class_2_weighted  \\\n",
       "abstract_19k_class_childPar_2_weighted                                        0.857558   \n",
       "abstract_first_sent_19k_class_siblings_2_weighted                             0.834302   \n",
       "complex_19k_childPar_1_weighted                                               0.619186   \n",
       "text_2_props_19k_2_class_2_weighted                                           1.000000   \n",
       "text_7_props_19k_class_childPar_2_weighted                                    0.959302   \n",
       "transe_19k_class_childPar_1_weighted                                          0.735465   \n",
       "\n",
       "                                                   text_7_props_19k_class_childPar_2_weighted  \\\n",
       "abstract_19k_class_childPar_2_weighted                                               0.880814   \n",
       "abstract_first_sent_19k_class_siblings_2_weighted                                    0.845930   \n",
       "complex_19k_childPar_1_weighted                                                      0.630814   \n",
       "text_2_props_19k_2_class_2_weighted                                                  0.959302   \n",
       "text_7_props_19k_class_childPar_2_weighted                                           1.000000   \n",
       "transe_19k_class_childPar_1_weighted                                                 0.747093   \n",
       "\n",
       "                                                   transe_19k_class_childPar_1_weighted  \n",
       "abstract_19k_class_childPar_2_weighted                                         0.811047  \n",
       "abstract_first_sent_19k_class_siblings_2_weighted                              0.816860  \n",
       "complex_19k_childPar_1_weighted                                                0.787791  \n",
       "text_2_props_19k_2_class_2_weighted                                            0.735465  \n",
       "text_7_props_19k_class_childPar_2_weighted                                     0.747093  \n",
       "transe_19k_class_childPar_1_weighted                                           1.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrAccMatrix = []\n",
    "for x in responsesDictMaster.keys():\n",
    "    temp = []\n",
    "    for y in responsesDictMaster.keys():\n",
    "        temp.append(accuracy_score(responsesDictMaster[x]['newOP'], responsesDictMaster[y]['newOP']))\n",
    "    corrAccMatrix.append(temp)\n",
    "pd.DataFrame(corrAccMatrix, index=responsesDictMaster.keys(), columns=responsesDictMaster.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-quarter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dirty-magic",
   "metadata": {},
   "source": [
    "### Retrofitting using concatenation of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "twenty-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def generateConcatenatedEmbeddingDict(embedDictMaster, key_comb, embedding_lengths):\n",
    "    embedDict = defaultdict(list)\n",
    "    masterKeySet = set()\n",
    "    for key in key_comb:\n",
    "        for qnode in embedDictMaster[key]:\n",
    "            masterKeySet.add(qnode)\n",
    "    for qnode in masterKeySet:\n",
    "        for key in key_comb:\n",
    "            if qnode in embedDictMaster[key]:\n",
    "                embedDict[qnode] = embedDict[qnode] + (embedDictMaster[key][qnode].tolist())\n",
    "            else:\n",
    "                embedDict[qnode] = embedDict[qnode] + [0]*embedding_lengths[key]\n",
    "        embedDict[qnode] = np.array(embedDict[qnode])\n",
    "    return dict(embedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cooperative-reference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 5.4 s, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedDictMaster['text_7-text_2-comp-tran-abs-abs_first'] = generateConcatenatedEmbeddingDict(embedDictMaster, \n",
    "                ['text_7_props', 'text_2_props', 'complex', 'transe', 'abstract', 'abstract_first_sent'], \n",
    "                embedding_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-discrimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c060d3c04441008eb1631416aa2a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880c54ab554f47c3bd423f4cd96a9652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782a811c6d614335a86eaadac0ce6766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cfda2280d3482d8923fd4093acfe6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "newEmbedDictMaster = {}\n",
    "responsesDictMaster = {}\n",
    "\n",
    "results = []\n",
    "NUM_ITERS = 2\n",
    "for basis in tqdm(basisList):\n",
    "    for weightedNess in [True]:\n",
    "        for i in tqdm(range(2,len(embList)+1)):\n",
    "            for embComb in tqdm(combinations(embList, i)):\n",
    "                emb = '-'.join(embComb)\n",
    "                start_time = time()\n",
    "                embedDict = {}\n",
    "                embedDict[1] = embedDict[2] = generateConcatenatedEmbeddingDict(embedDictMaster,embComb, embedding_lengths)\n",
    "                \n",
    "                for weightCase in [1,2]:\n",
    "                    oldAcc = 0\n",
    "#                     groupResults = []\n",
    "                    for iterNum in range(1,NUM_ITERS+1):\n",
    "                        if weightedNess:\n",
    "                            caseName = emb + '_' + basis + '_' + str(weightCase) + '_weighted'\n",
    "                        else:\n",
    "                            caseName = emb + '_' + basis + '_' + str(weightCase) + '_unweighted'\n",
    "                        newEmbedDict = retrofit(embedDict[weightCase], neighDictMaster[basis], weightCase, weightedNess)\n",
    "            #             dists = determine_distances(embedDict, newEmbedDict)\n",
    "                        responsesDict = fetchCorrelationResults(embedDict[weightCase], newEmbedDict)\n",
    "            #                 print(responsesDict.keys())\n",
    "                        if iterNum == 1:\n",
    "                            oldAcc = responsesDict['old_acc']*100\n",
    "                            groupResults.append([emb, basis, weightCase, weightedNess, iterNum, \\\n",
    "                                        -1, \\\n",
    "                                        responsesDict['old_acc']*100, \\\n",
    "                                        0, \\\n",
    "                                        responsesDict['coveredPairs'], \\\n",
    "                                         responsesDict['class_rep_old']['I']['precision'], \\\n",
    "                                         responsesDict['class_rep_old']['I']['recall'], \\\n",
    "                                         responsesDict['class_rep_old']['I']['f1-score'], \\\n",
    "                                         responsesDict['class_rep_old']['U']['precision'], \\\n",
    "                                         responsesDict['class_rep_old']['U']['recall'], \\\n",
    "                                         responsesDict['class_rep_old']['U']['f1-score'], \\\n",
    "                                         responsesDict['class_rep_new']['I']['precision'], \\\n",
    "                                         responsesDict['class_rep_new']['I']['recall'], \\\n",
    "                                         responsesDict['class_rep_new']['I']['f1-score'], \\\n",
    "                                         responsesDict['class_rep_new']['U']['precision'], \\\n",
    "                                         responsesDict['class_rep_new']['U']['recall'], \\\n",
    "                                         responsesDict['class_rep_new']['U']['f1-score'], \\\n",
    "                                         i, \\\n",
    "                                         time() - start_time\n",
    "                                        ])\n",
    "                        results.append([emb, basis, weightCase, weightedNess, iterNum, \\\n",
    "                                        -1, \\\n",
    "                                        responsesDict['new_acc']*100, \\\n",
    "                                        (responsesDict['new_acc'] - oldAcc)*100, \\\n",
    "                                        responsesDict['coveredPairs'], \\\n",
    "                                         responsesDict['class_rep_old']['I']['precision'], \\\n",
    "                                         responsesDict['class_rep_old']['I']['recall'], \\\n",
    "                                         responsesDict['class_rep_old']['I']['f1-score'], \\\n",
    "                                         responsesDict['class_rep_old']['U']['precision'], \\\n",
    "                                         responsesDict['class_rep_old']['U']['recall'], \\\n",
    "                                         responsesDict['class_rep_old']['U']['f1-score'], \\\n",
    "                                         responsesDict['class_rep_new']['I']['precision'], \\\n",
    "                                         responsesDict['class_rep_new']['I']['recall'], \\\n",
    "                                         responsesDict['class_rep_new']['I']['f1-score'], \\\n",
    "                                         responsesDict['class_rep_new']['U']['precision'], \\\n",
    "                                         responsesDict['class_rep_new']['U']['recall'], \\\n",
    "                                         responsesDict['class_rep_new']['U']['f1-score'], \\\n",
    "                                         i, \\\n",
    "                                         time() - start_time\n",
    "                                        ])\n",
    "                        embedDict[weightCase] = newEmbedDict\n",
    "\n",
    "                        newEmbedDictMaster[caseName] = newEmbedDict\n",
    "                        responsesDictMaster[caseName] = responsesDict\n",
    "                        if responsesDict['new_acc']*100 < oldAcc:\n",
    "                            break\n",
    "#                 results.append(gr)\n",
    "#                     highestOne = True\n",
    "#                     for gR, rank in zip(groupResults, np.argsort([-p[6] for p in groupResults])):\n",
    "#                         results.append(gR+[rank])\n",
    "#                     if iterNum == NUM_ITERS and highestOne:\n",
    "#                         caseName = gR[0] + '_' + gR[1] + '_' + str(gR[2]) + '_weighted'\n",
    "#                         newEmbedDictMaster[caseName] = serializeEmbeddingDict(newEmbedDictMaster[caseName])\n",
    "#                         highestOne = False\n",
    "#                         json.dump(newEmbedDictMaster[caseName],open('../data/Master_P279_dataset/embeddings/new_embedding_dict_'+caseName+'.json','w'))\n",
    "#                         newEmbedDictMaster[caseName] = deserializeEmbeddingDict(newEmbedDictMaster[caseName])\n",
    "resultsDF = pd.DataFrame(results, columns=['Embedding', 'Basis', 'Weight', 'Weightedness', 'Iteration Num', 'Old Acc', 'New Acc', 'Increase', 'Pairs Covered', \\\n",
    "                                           'Old I Precision', 'Old I Recall', 'Old I F1-Score', \\\n",
    "                                           'Old U Precision', 'Old U Recall', 'Old U F1-Score', \\\n",
    "                                           'New I Precision', 'New I Recall', 'New I F1-Score', \\\n",
    "                                           'New U Precision', 'New U Recall', 'New U F1-Score', \\\n",
    "                                           'No. of embeddings', \\\n",
    "                                           'Time'])\n",
    "resultsDF.to_csv('../data/retrofitting/retro_concat_'+ today_date +'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-console",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "korean-albania",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "golden-melissa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aca6f0bfc654b178bd71a5c7cfe22d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svmCasesList = []\n",
    "for basis in tqdm(basisList):\n",
    "    for emb in embList:\n",
    "        for weightedNess in [True]:\n",
    "            for iterNum in range(0,NUM_ITERS+1):\n",
    "                for weightCase in [1,2]:\n",
    "                    for svm_input in ['emb','score']:\n",
    "                        temp_dict = {'basis': basis, 'emb': emb, 'weightedNess': weightedNess, \n",
    "                                    'iterNum': iterNum, 'weightCase': weightCase, 'svm_input': svm_input}\n",
    "                        svmCasesList.append(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "renewable-selling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "broadband-column",
   "metadata": {},
   "source": [
    "### SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "swedish-bride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basis': '19k_2',\n",
       " 'emb': 'text_7_props',\n",
       " 'weightedNess': True,\n",
       " 'iterNum': 0,\n",
       " 'weightCase': 1,\n",
       " 'svm_input': 'emb'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmCasesList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-planet",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainAndFindAccuracy(wordSim353AnnotDF_New, svmCasesList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-darwin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "accompanied-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results, columns=['caseName','basis','emb','weightedNess', 'iteration', 'weightCase', 'technique','accuracy']).to_csv('../data/retrofitting/retro_SVM_test_'+ today_date +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "immediate-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndFindAccuracyCombs(wordSim353AnnotDF_New_Merged_DF, case):\n",
    "    X = []\n",
    "    \n",
    "    if case['svm_input'] == 'emb':\n",
    "        for _, row in wordSim353AnnotDF_New_Merged_DF.iterrows():\n",
    "            tempX = []\n",
    "            for emb in case['emb']:\n",
    "                caseName = emb + '_' + case['basis'] + '_' + str(case['weightCase']) + ('_weighted' if case['weightedNess'] else '_unweighted')\n",
    "                # Guard check conditions\n",
    "                if case['iterNum'] != 0 and caseName not in newEmbedDictMaster:\n",
    "                    return caseName, case, None\n",
    "                if case['iterNum'] == 0:\n",
    "                    tempX += embedDictMaster[emb][row['word1_kg_id']].tolist() + embedDictMaster[emb][row['word2_kg_id']].tolist()\n",
    "                else:\n",
    "                    tempX += newEmbedDictMaster[caseName][row['word1_kg_id']].tolist() + newEmbedDictMaster[caseName][row['word2_kg_id']].tolist()\n",
    "            X.append(tempX)\n",
    "    else:\n",
    "        for _, row in wordSim353AnnotDF_New_Merged_DF.iterrows():\n",
    "            tempX = []\n",
    "            for emb in case['emb']:\n",
    "                caseName = emb + '_' + case['basis'] + '_' + str(case['weightCase']) + ('_weighted' if case['weightedNess'] else '_unweighted')\n",
    "                # Guard check conditions\n",
    "                if case['iterNum'] != 0 and caseName not in newEmbedDictMaster:\n",
    "                    return caseName, case, None\n",
    "                if case['iterNum'] == 0:\n",
    "                    tempX += [(abs(cosine_similarity(embedDictMaster[emb][row['word1_kg_id']].reshape(1,-1), embedDictMaster[emb][row['word2_kg_id']].reshape(1,-1))[0][0]))]\n",
    "                else:\n",
    "                    tempX += [(abs(cosine_similarity(newEmbedDictMaster[caseName][row['word1_kg_id']].reshape(1,-1), newEmbedDictMaster[caseName][row['word2_kg_id']].reshape(1,-1))[0][0]))]\n",
    "            X.append(tempX)\n",
    "#     X = wordSim353AnnotDF_New_Merged_DF[colList]\n",
    "    X = pd.DataFrame(X)\n",
    "    Y = wordSim353AnnotDF_New_Merged_DF['category']\n",
    "\n",
    "    N_SPLITS = 10\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, random_state=19, shuffle=True)\n",
    "    X_train_splits, X_test_splits, Y_train_splits, Y_test_splits = [], [], [], []\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        X_train_splits.append(X.iloc[train_index])\n",
    "        X_test_splits.append(X.iloc[test_index])\n",
    "        Y_train_splits.append(Y.iloc[train_index])\n",
    "        Y_test_splits.append(Y.iloc[test_index])\n",
    "\n",
    "    preds = []\n",
    "    for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=100))\n",
    "        clf.fit(X_train1, Y_train1)\n",
    "        preds.append(clf.predict(X_test1))\n",
    "\n",
    "    tempVals = []\n",
    "\n",
    "    acc = 0\n",
    "    for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "        acc += accuracy_score(pred, Y_test1)\n",
    "\n",
    "    return caseName, *list(case.values()), acc/N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "insured-escape",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'basisList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f8d710c8d206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvmCombCasesList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbasis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasisList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mweightedNess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0miterNum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_ITERS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mweightCase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'basisList' is not defined"
     ]
    }
   ],
   "source": [
    "svmCombCasesList = []\n",
    "for basis in tqdm(basisList):\n",
    "        for weightedNess in [True]:\n",
    "            for iterNum in range(0,NUM_ITERS+1):\n",
    "                for weightCase in [1,2]:\n",
    "                    for svm_input in ['score']:\n",
    "                        for i in range(1,len(embList)+1):\n",
    "                            for embComb in combinations(embList, i):\n",
    "                                temp_dict = {'basis': basis, 'emb': embComb, 'weightedNess': weightedNess, \n",
    "                                            'iterNum': iterNum, 'weightCase': weightCase, 'svm_input': svm_input}\n",
    "                                svmCombCasesList.append(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ahead-letters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3024"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svmCombCasesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "chicken-computer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 7s, sys: 24.6 s, total: 18min 32s\n",
      "Wall time: 18min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')\n",
    "    \n",
    "results = Parallel(n_jobs=1)(delayed(trainAndFindAccuracyCombs)(wordSim353AnnotDF_New, caseDict,) for caseDict in tqdm(svmCombCasesList))\n",
    "resDF = pd.DataFrame(results, columns=['caseName','basis','emb_comb','weightedNess', 'iteration', 'weightCase', 'technique','accuracy'])\n",
    "resDF['emb_comb'] = resDF['emb_comb'].apply(lambda p: \" & \".join(p))\n",
    "resDF.to_csv('../data/retrofitting/retro_SVM_comb_test_'+ today_date +'.csv', index=False)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-blast",
   "metadata": {},
   "source": [
    "### SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "photographic-mileage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>ID</th>\n",
       "      <th>H_Sim</th>\n",
       "      <th>H_Dim</th>\n",
       "      <th>F_Sim</th>\n",
       "      <th>F_Dim</th>\n",
       "      <th>N_Sim</th>\n",
       "      <th>N_Dim</th>\n",
       "      <th>D_Sim</th>\n",
       "      <th>D_Dim</th>\n",
       "      <th>P_Sim</th>\n",
       "      <th>P_Dim</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Stdev</th>\n",
       "      <th>H_orig</th>\n",
       "      <th>H_reversed</th>\n",
       "      <th>word1_kg_id</th>\n",
       "      <th>word2_kg_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>2.1250</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>Q34211</td>\n",
       "      <td>Q454</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>3.0625</td>\n",
       "      <td>6.9375</td>\n",
       "      <td>Q34211</td>\n",
       "      <td>Q13648784</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>4.0625</td>\n",
       "      <td>5.9375</td>\n",
       "      <td>Q8333</td>\n",
       "      <td>Q178022</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>3.0</td>\n",
       "      <td>u</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>4.9375</td>\n",
       "      <td>Q8333</td>\n",
       "      <td>Q21004260</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>s</td>\n",
       "      <td>2.0</td>\n",
       "      <td>s</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>4.8750</td>\n",
       "      <td>5.1250</td>\n",
       "      <td>Q13371</td>\n",
       "      <td>Q49112</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word 1         Word 2   ID  H_Sim H_Dim  F_Sim F_Dim  N_Sim N_Dim  D_Sim  \\\n",
       "0   Arafat          peace    8      3     D      4   NaN      3     U      4   \n",
       "1   Arafat         terror    9      3     D      4   NaN      3     U      4   \n",
       "2      FBI    fingerprint  109      3     D      4   NaN      4   NaN      3   \n",
       "3      FBI  investigation  110      3     U      3     U      3     U      3   \n",
       "4  Harvard           Yale  137      2     S      3     S      2     S      2   \n",
       "\n",
       "  D_Dim  P_Sim P_Dim  Avg     Stdev  H_orig  H_reversed word1_kg_id  \\\n",
       "0   NaN    4.0   NaN  3.6  0.547723  2.1250      7.8750      Q34211   \n",
       "1   NaN    4.0   NaN  3.6  0.547723  3.0625      6.9375      Q34211   \n",
       "2     u    4.0   NaN  3.6  0.547723  4.0625      5.9375       Q8333   \n",
       "3     u    3.0     u  3.0  0.000000  5.0625      4.9375       Q8333   \n",
       "4     s    2.0     s  2.2  0.447214  4.8750      5.1250      Q13371   \n",
       "\n",
       "  word2_kg_id category  \n",
       "0        Q454        U  \n",
       "1   Q13648784        U  \n",
       "2     Q178022        U  \n",
       "3   Q21004260        M  \n",
       "4      Q49112        M  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "pediatric-intelligence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5e0e7ad7fb4e5589d10aaaf55783a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')\n",
    "    \n",
    "results = Parallel(n_jobs=1)(delayed(trainAndFindRegressionAccuracy)(wordSim353AnnotDF_New, caseDict,) for caseDict in tqdm(svmCasesList))\n",
    "pd.DataFrame(results, columns=['caseName','basis','emb','weightedNess', 'iteration', 'weightCase', 'technique','Acc']).to_csv('../data/retrofitting/retro_SVM_Reg_test_'+ today_date +'.csv', index=False)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "painted-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndFindRegressionAccuracyCombs(wordSim353AnnotDF_New_Merged_DF, case):\n",
    "    X = []\n",
    "    \n",
    "    if case['svm_input'] == 'emb':\n",
    "        for _, row in wordSim353AnnotDF_New_Merged_DF.iterrows():\n",
    "            tempX = []\n",
    "            for emb in case['emb']:\n",
    "                caseName = emb + '_' + case['basis'] + '_' + str(case['weightCase']) + ('_weighted' if case['weightedNess'] else '_unweighted')\n",
    "                # Guard check conditions\n",
    "                if case['iterNum'] != 0 and caseName not in newEmbedDictMaster:\n",
    "                    return caseName, case, None\n",
    "                if case['iterNum'] == 0:\n",
    "                    tempX += embedDictMaster[emb][row['word1_kg_id']].tolist() + embedDictMaster[emb][row['word2_kg_id']].tolist()\n",
    "                else:\n",
    "                    tempX += newEmbedDictMaster[caseName][row['word1_kg_id']].tolist() + newEmbedDictMaster[caseName][row['word2_kg_id']].tolist()\n",
    "            X.append(tempX)\n",
    "    else:\n",
    "        for _, row in wordSim353AnnotDF_New_Merged_DF.iterrows():\n",
    "            tempX = []\n",
    "            for emb in case['emb']:\n",
    "                caseName = emb + '_' + case['basis'] + '_' + str(case['weightCase']) + ('_weighted' if case['weightedNess'] else '_unweighted')\n",
    "                # Guard check conditions\n",
    "                if case['iterNum'] != 0 and caseName not in newEmbedDictMaster:\n",
    "                    return caseName, case, None\n",
    "                if case['iterNum'] == 0:\n",
    "                    tempX += [(abs(cosine_similarity(embedDictMaster[emb][row['word1_kg_id']].reshape(1,-1), embedDictMaster[emb][row['word2_kg_id']].reshape(1,-1))[0][0]))]\n",
    "                else:\n",
    "                    tempX += [(abs(cosine_similarity(newEmbedDictMaster[caseName][row['word1_kg_id']].reshape(1,-1), newEmbedDictMaster[caseName][row['word2_kg_id']].reshape(1,-1))[0][0]))]\n",
    "            X.append(tempX)\n",
    "#     X = wordSim353AnnotDF_New_Merged_DF[colList]\n",
    "    X = pd.DataFrame(X)\n",
    "    Y = (wordSim353AnnotDF_New_Merged_DF['Avg'] - 1) / 3\n",
    "\n",
    "    N_SPLITS = 10\n",
    "\n",
    "    skf = KFold(n_splits=N_SPLITS, random_state=19, shuffle=True)\n",
    "    X_train_splits, X_test_splits, Y_train_splits, Y_test_splits = [], [], [], []\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        X_train_splits.append(X.iloc[train_index])\n",
    "        X_test_splits.append(X.iloc[test_index])\n",
    "        Y_train_splits.append(Y.iloc[train_index])\n",
    "        Y_test_splits.append(Y.iloc[test_index])\n",
    "\n",
    "    preds = []\n",
    "    for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "        clf = make_pipeline(StandardScaler(), SVR(gamma='auto'))\n",
    "        clf.fit(X_train1, Y_train1)\n",
    "        preds.append(clf.predict(X_test1))\n",
    "\n",
    "    tempVals = []\n",
    "\n",
    "    acc = 0\n",
    "    for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "        acc += accuracy_score(np_label_samples(pred * 3 + 1), np_label_samples(Y_test1 * 3 + 1))\n",
    "#         acc += mean_squared_error(pred * 3 + 1, Y_test1 * 3 + 1)\n",
    "\n",
    "    return caseName, *list(case.values()), acc/N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "circular-marine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0704145482e94140a701edcd9d8c0a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 14s, sys: 18.4 s, total: 17min 32s\n",
      "Wall time: 17min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')\n",
    "    \n",
    "results = Parallel(n_jobs=1)(delayed(trainAndFindRegressionAccuracyCombs)(wordSim353AnnotDF_New, caseDict,) for caseDict in tqdm(svmCombCasesList))\n",
    "resDF = pd.DataFrame(results, columns=['caseName','basis','emb_comb','weightedNess', 'iteration', 'weightCase', 'technique','accuracy'])\n",
    "resDF['emb_comb'] = resDF['emb_comb'].apply(lambda p: \" & \".join(p))\n",
    "resDF.to_csv('../data/retrofitting/retro_SVM_Reg_comb_test_'+ today_date +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-department",
   "metadata": {},
   "source": [
    "# Determine Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-graphics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "moderate-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "centered-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldEmbedDictKey = 'transe'\n",
    "newEmbedDictKey = 'transe_19k_childPar_1_weighted'\n",
    "wordSim353AnnotDF_New['textOld'] = wordSim353AnnotDF_New.apply(lambda p: 4 - 3 * abs(cosine_similarity(np.array(embedDictMaster[oldEmbedDictKey][p['word1_kg_id']]).reshape(1,-1), np.array(embedDictMaster[oldEmbedDictKey][p['word2_kg_id']]).reshape(1,-1))[0][0]) if p['word1_kg_id'] in embedDictMaster[oldEmbedDictKey] and p['word2_kg_id'] in embedDictMaster[oldEmbedDictKey] else -1, axis=1)\n",
    "wordSim353AnnotDF_New['textNew'] = wordSim353AnnotDF_New.apply(lambda p: 4 - 3 * abs(cosine_similarity(np.array(newEmbedDictMaster[newEmbedDictKey][p['word1_kg_id']]).reshape(1,-1), np.array(newEmbedDictMaster[newEmbedDictKey][p['word2_kg_id']]).reshape(1,-1))[0][0]) if p['word1_kg_id'] in embedDictMaster[oldEmbedDictKey] and p['word2_kg_id'] in embedDictMaster[oldEmbedDictKey] else -1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "suspended-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New['old_diff'] = abs(wordSim353AnnotDF_New['textOld'] - wordSim353AnnotDF_New['Avg'])\n",
    "wordSim353AnnotDF_New['new_diff'] = abs(wordSim353AnnotDF_New['textNew'] - wordSim353AnnotDF_New['Avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "another-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "metallic-smith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    344.000000\n",
       "mean       0.506079\n",
       "std        0.388162\n",
       "min        0.000000\n",
       "25%        0.201136\n",
       "50%        0.430653\n",
       "75%        0.744341\n",
       "max        1.969069\n",
       "Name: old_diff, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New.sort_values(by=['old_diff'],ascending=False)['old_diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "designed-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    344.000000\n",
       "mean       0.587435\n",
       "std        0.440362\n",
       "min        0.000000\n",
       "25%        0.237281\n",
       "50%        0.494043\n",
       "75%        0.880977\n",
       "max        1.900974\n",
       "Name: new_diff, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New.sort_values(by=['new_diff'],ascending=False)['new_diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "facial-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineFarNessOfOld(val1):\n",
    "    if 0.000000 <= val1 < 0.506079:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def determineFarNessOfNew(val1):\n",
    "    if 0 <= val1 < 0.587435:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "wordSim353AnnotDF_New['Old_Diff_Cat'] = wordSim353AnnotDF_New['old_diff'].apply(determineFarNessOfOld)\n",
    "wordSim353AnnotDF_New['New_Diff_Cat'] = wordSim353AnnotDF_New['new_diff'].apply(determineFarNessOfNew)\n",
    "wordSim353AnnotDF_New['correct_category'] = wordSim353AnnotDF_New.Avg.apply(label_samples)\n",
    "wordSim353AnnotDF_New['old_predicted_category'] = wordSim353AnnotDF_New.textOld.apply(label_samples)\n",
    "wordSim353AnnotDF_New['new_predicted_category'] = wordSim353AnnotDF_New.textNew.apply(label_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "lightweight-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF = wordSim353AnnotDF_New[['Word 1', 'Word 2', 'Avg', 'textOld', 'textNew', 'old_diff', 'new_diff', 'Old_Diff_Cat', 'New_Diff_Cat', 'correct_category', 'old_predicted_category', 'new_predicted_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "american-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Avg</th>\n",
       "      <th>textOld</th>\n",
       "      <th>textNew</th>\n",
       "      <th>old_diff</th>\n",
       "      <th>new_diff</th>\n",
       "      <th>Old_Diff_Cat</th>\n",
       "      <th>New_Diff_Cat</th>\n",
       "      <th>correct_category</th>\n",
       "      <th>old_predicted_category</th>\n",
       "      <th>new_predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.909414</td>\n",
       "      <td>3.837159</td>\n",
       "      <td>0.309414</td>\n",
       "      <td>0.237159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.646852</td>\n",
       "      <td>3.593611</td>\n",
       "      <td>0.046852</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.470644</td>\n",
       "      <td>3.470644</td>\n",
       "      <td>0.129356</td>\n",
       "      <td>0.129356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.674395</td>\n",
       "      <td>3.625026</td>\n",
       "      <td>0.674395</td>\n",
       "      <td>0.625026</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.514591</td>\n",
       "      <td>2.514591</td>\n",
       "      <td>0.314591</td>\n",
       "      <td>0.314591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>war</td>\n",
       "      <td>troops</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.877362</td>\n",
       "      <td>2.476802</td>\n",
       "      <td>0.122638</td>\n",
       "      <td>0.523198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>weapon</td>\n",
       "      <td>secret</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.544676</td>\n",
       "      <td>3.078550</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>0.721450</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.443100</td>\n",
       "      <td>2.075806</td>\n",
       "      <td>0.556900</td>\n",
       "      <td>0.924194</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>wood</td>\n",
       "      <td>forest</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.666691</td>\n",
       "      <td>3.692986</td>\n",
       "      <td>1.866691</td>\n",
       "      <td>1.892986</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>word</td>\n",
       "      <td>similarity</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.202513</td>\n",
       "      <td>2.677294</td>\n",
       "      <td>0.547487</td>\n",
       "      <td>1.072706</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word 1         Word 2   Avg   textOld   textNew  old_diff  new_diff  \\\n",
       "0     Arafat          peace  3.60  3.909414  3.837159  0.309414  0.237159   \n",
       "1     Arafat         terror  3.60  3.646852  3.593611  0.046852  0.006389   \n",
       "2        FBI    fingerprint  3.60  3.470644  3.470644  0.129356  0.129356   \n",
       "3        FBI  investigation  3.00  3.674395  3.625026  0.674395  0.625026   \n",
       "4    Harvard           Yale  2.20  2.514591  2.514591  0.314591  0.314591   \n",
       "..       ...            ...   ...       ...       ...       ...       ...   \n",
       "339      war         troops  3.00  2.877362  2.476802  0.122638  0.523198   \n",
       "340   weapon         secret  3.80  3.544676  3.078550  0.255324  0.721450   \n",
       "341  weather       forecast  3.00  2.443100  2.075806  0.556900  0.924194   \n",
       "342     wood         forest  1.80  3.666691  3.692986  1.866691  1.892986   \n",
       "343     word     similarity  3.75  3.202513  2.677294  0.547487  1.072706   \n",
       "\n",
       "     Old_Diff_Cat  New_Diff_Cat correct_category old_predicted_category  \\\n",
       "0               0             0                U                      U   \n",
       "1               0             0                U                      U   \n",
       "2               0             0                U                      M   \n",
       "3               1             1                M                      U   \n",
       "4               0             0                M                      M   \n",
       "..            ...           ...              ...                    ...   \n",
       "339             0             0                M                      M   \n",
       "340             0             1                U                      U   \n",
       "341             1             1                M                      M   \n",
       "342             1             1                M                      U   \n",
       "343             1             1                U                      M   \n",
       "\n",
       "    new_predicted_category  \n",
       "0                        U  \n",
       "1                        U  \n",
       "2                        M  \n",
       "3                        U  \n",
       "4                        M  \n",
       "..                     ...  \n",
       "339                      M  \n",
       "340                      M  \n",
       "341                      M  \n",
       "342                      U  \n",
       "343                      M  \n",
       "\n",
       "[344 rows x 12 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "automotive-trouble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['Old_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['New_Diff_Cat'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "arabic-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[wordSim353AnnotDF_New_Merged_DF['old_predicted_category'] != wordSim353AnnotDF_New_Merged_DF['correct_category']].to_csv('../data/transEmb/badBefore_'+ today_date +'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acoustic-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[wordSim353AnnotDF_New_Merged_DF['new_predicted_category'] != wordSim353AnnotDF_New_Merged_DF['correct_category']].to_csv('../data/transEmb/badAfter_'+ today_date +'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "accompanied-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.to_csv('../data/transEmb/entireSet.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "breathing-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['Old_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['New_Diff_Cat'] == 0)].to_csv('../data/transEmb/good+good_'+ today_date +'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "chief-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['Old_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['New_Diff_Cat'] == 1)].to_csv('../data/transEmb/good+bad_'+ today_date +'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "shaped-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['Old_Diff_Cat'] == 1) & (wordSim353AnnotDF_New_Merged_DF['New_Diff_Cat'] == 0)].to_csv('../data/transEmb/bad+good_'+ today_date +'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "adolescent-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['Old_Diff_Cat'] == 1) & (wordSim353AnnotDF_New_Merged_DF['New_Diff_Cat'] == 1)].to_csv('../data/transEmb/bad+bad_'+ today_date +'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-bridal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-mirror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "placed-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff'] = abs(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim'] - wordSim353AnnotDF_New_Merged_DF['Avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stopped-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff'] = abs(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim'] - wordSim353AnnotDF_New_Merged_DF['Avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deadly-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southeast-canal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    344.000000\n",
       "mean       0.567297\n",
       "std        0.435379\n",
       "min        0.000000\n",
       "25%        0.250130\n",
       "50%        0.508725\n",
       "75%        0.835197\n",
       "max        5.000000\n",
       "Name: concat_19k_v1_old_cosSim_Diff, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.sort_values(by=['concat_19k_v1_old_cosSim_Diff'],ascending=False)['concat_19k_v1_old_cosSim_Diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adequate-terminology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.440000e+02\n",
       "mean     5.938081e-01\n",
       "std      4.503200e-01\n",
       "min      4.440892e-16\n",
       "25%      2.665817e-01\n",
       "50%      5.349785e-01\n",
       "75%      8.528840e-01\n",
       "max      5.000000e+00\n",
       "Name: concat_19k_v1_2_new_cosSim_Diff, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.sort_values(by=['concat_19k_v1_2_new_cosSim_Diff'],ascending=False)['concat_19k_v1_2_new_cosSim_Diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wired-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineFarNessOfOld(val1):\n",
    "    if 0.000000 <= val1 < 0.508725:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def determineFarNessOfNew(val1):\n",
    "    if 0 <= val1 < 5.349785e-01:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] = wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff'].apply(determineFarNessOfOld)\n",
    "wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] = wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff'].apply(determineFarNessOfNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "operating-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF = wordSim353AnnotDF_New_Merged_DF[['Word 1', 'Word 2', 'Avg', 'concat_19k_v1_old_cosSim', 'concat_19k_v1_2_new_cosSim', 'concat_19k_v1_old_cosSim_Diff', 'concat_19k_v1_2_new_cosSim_Diff', 'concat_19k_v1_old_cosSim_Diff_Cat', 'concat_19k_v1_2_new_cosSim_Diff_Cat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quantitative-money",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Avg</th>\n",
       "      <th>concat_19k_v1_old_cosSim</th>\n",
       "      <th>concat_19k_v1_2_new_cosSim</th>\n",
       "      <th>concat_19k_v1_old_cosSim_Diff</th>\n",
       "      <th>concat_19k_v1_2_new_cosSim_Diff</th>\n",
       "      <th>concat_19k_v1_old_cosSim_Diff_Cat</th>\n",
       "      <th>concat_19k_v1_2_new_cosSim_Diff_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.251198</td>\n",
       "      <td>3.193271</td>\n",
       "      <td>0.348802</td>\n",
       "      <td>0.406729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.231409</td>\n",
       "      <td>3.157229</td>\n",
       "      <td>0.368591</td>\n",
       "      <td>0.442771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.948487</td>\n",
       "      <td>2.853048</td>\n",
       "      <td>0.651513</td>\n",
       "      <td>0.746952</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.930365</td>\n",
       "      <td>2.895604</td>\n",
       "      <td>0.069635</td>\n",
       "      <td>0.104396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.991054</td>\n",
       "      <td>1.991054</td>\n",
       "      <td>0.208946</td>\n",
       "      <td>0.208946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>war</td>\n",
       "      <td>troops</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.913931</td>\n",
       "      <td>2.787213</td>\n",
       "      <td>0.086069</td>\n",
       "      <td>0.212787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>weapon</td>\n",
       "      <td>secret</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.152513</td>\n",
       "      <td>3.119065</td>\n",
       "      <td>0.647487</td>\n",
       "      <td>0.680935</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.492765</td>\n",
       "      <td>2.462389</td>\n",
       "      <td>0.507235</td>\n",
       "      <td>0.537611</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>wood</td>\n",
       "      <td>forest</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.612681</td>\n",
       "      <td>2.606941</td>\n",
       "      <td>0.812681</td>\n",
       "      <td>0.806941</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>word</td>\n",
       "      <td>similarity</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.678276</td>\n",
       "      <td>2.652829</td>\n",
       "      <td>1.071724</td>\n",
       "      <td>1.097171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word 1         Word 2   Avg  concat_19k_v1_old_cosSim  \\\n",
       "0     Arafat          peace  3.60                  3.251198   \n",
       "1     Arafat         terror  3.60                  3.231409   \n",
       "2        FBI    fingerprint  3.60                  2.948487   \n",
       "3        FBI  investigation  3.00                  2.930365   \n",
       "4    Harvard           Yale  2.20                  1.991054   \n",
       "..       ...            ...   ...                       ...   \n",
       "339      war         troops  3.00                  2.913931   \n",
       "340   weapon         secret  3.80                  3.152513   \n",
       "341  weather       forecast  3.00                  2.492765   \n",
       "342     wood         forest  1.80                  2.612681   \n",
       "343     word     similarity  3.75                  2.678276   \n",
       "\n",
       "     concat_19k_v1_2_new_cosSim  concat_19k_v1_old_cosSim_Diff  \\\n",
       "0                      3.193271                       0.348802   \n",
       "1                      3.157229                       0.368591   \n",
       "2                      2.853048                       0.651513   \n",
       "3                      2.895604                       0.069635   \n",
       "4                      1.991054                       0.208946   \n",
       "..                          ...                            ...   \n",
       "339                    2.787213                       0.086069   \n",
       "340                    3.119065                       0.647487   \n",
       "341                    2.462389                       0.507235   \n",
       "342                    2.606941                       0.812681   \n",
       "343                    2.652829                       1.071724   \n",
       "\n",
       "     concat_19k_v1_2_new_cosSim_Diff  concat_19k_v1_old_cosSim_Diff_Cat  \\\n",
       "0                           0.406729                                  0   \n",
       "1                           0.442771                                  0   \n",
       "2                           0.746952                                  1   \n",
       "3                           0.104396                                  0   \n",
       "4                           0.208946                                  0   \n",
       "..                               ...                                ...   \n",
       "339                         0.212787                                  0   \n",
       "340                         0.680935                                  1   \n",
       "341                         0.537611                                  0   \n",
       "342                         0.806941                                  1   \n",
       "343                         1.097171                                  1   \n",
       "\n",
       "     concat_19k_v1_2_new_cosSim_Diff_Cat  \n",
       "0                                      0  \n",
       "1                                      0  \n",
       "2                                      1  \n",
       "3                                      0  \n",
       "4                                      0  \n",
       "..                                   ...  \n",
       "339                                    0  \n",
       "340                                    1  \n",
       "341                                    1  \n",
       "342                                    1  \n",
       "343                                    1  \n",
       "\n",
       "[344 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "attractive-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "proof-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] == 0)].to_csv('../data/concEmb/good+good.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "elder-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] == 0) & (wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] == 1)].to_csv('../data/concEmb/good+bad.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "magnetic-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] == 1) & (wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] == 0)].to_csv('../data/concEmb/bad+good.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "satisfied-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[(wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_old_cosSim_Diff_Cat'] == 1) & (wordSim353AnnotDF_New_Merged_DF['concat_19k_v1_2_new_cosSim_Diff_Cat'] == 1)].to_csv('../data/concEmb/bad+bad.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-milan",
   "metadata": {},
   "source": [
    "# SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "worldwide-genius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datacompy\n",
      "  Downloading datacompy-0.7.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /nas/home/kshenoy/miniconda3/lib/python3.8/site-packages (from datacompy) (1.20.1)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /nas/home/kshenoy/miniconda3/lib/python3.8/site-packages (from datacompy) (1.2.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /nas/home/kshenoy/miniconda3/lib/python3.8/site-packages (from pandas>=0.25.0->datacompy) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /nas/home/kshenoy/miniconda3/lib/python3.8/site-packages (from pandas>=0.25.0->datacompy) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /nas/home/kshenoy/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.25.0->datacompy) (1.15.0)\n",
      "Installing collected packages: datacompy\n",
      "Successfully installed datacompy-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datacompy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "overhead-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF = pd.read_csv('../data/wordsim353_all_embeddings_with_retrofits_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "developing-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF_old = pd.read_csv('../data/wordsim353_all_embeddings_with_retrofits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "catholic-compensation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>ID</th>\n",
       "      <th>H_Sim</th>\n",
       "      <th>H_Dim</th>\n",
       "      <th>F_Sim</th>\n",
       "      <th>F_Dim</th>\n",
       "      <th>N_Sim</th>\n",
       "      <th>N_Dim</th>\n",
       "      <th>D_Sim</th>\n",
       "      <th>...</th>\n",
       "      <th>concat_19k_v2_word1_new</th>\n",
       "      <th>concat_19k_v2_word2_new</th>\n",
       "      <th>concat_19k_v2_old_cosSim</th>\n",
       "      <th>concat_19k_v2_2_new_cosSim</th>\n",
       "      <th>concat_probase_19k_v2_word1_old</th>\n",
       "      <th>concat_probase_19k_v2_word2_old</th>\n",
       "      <th>concat_probase_19k_v2_word1_new</th>\n",
       "      <th>concat_probase_19k_v2_word2_new</th>\n",
       "      <th>concat_probase_19k_v2_old_cosSim</th>\n",
       "      <th>concat_probase_19k_v2_2_new_cosSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>peace</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.006720443092017323, 0.008331487679612525, 0...</td>\n",
       "      <td>[-0.004515859576248157, -0.01172366887295375, ...</td>\n",
       "      <td>3.244539</td>\n",
       "      <td>3.175157</td>\n",
       "      <td>[0.006720440291834372, 0.008331484208161396, 0...</td>\n",
       "      <td>[-0.005011610937734838, -0.013383541550578623,...</td>\n",
       "      <td>[0.006720440291834372, 0.008331484208161396, 0...</td>\n",
       "      <td>[-0.00497129831746384, -0.01325426749683971, -...</td>\n",
       "      <td>3.244539</td>\n",
       "      <td>3.240270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arafat</td>\n",
       "      <td>terror</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.006720443092017323, 0.008331487679612525, 0...</td>\n",
       "      <td>[-0.004862257088069111, 0.014077170590128979, ...</td>\n",
       "      <td>3.085083</td>\n",
       "      <td>3.013958</td>\n",
       "      <td>[0.006720440291834372, 0.008331484208161396, 0...</td>\n",
       "      <td>[-0.005805280438126139, 0.015115419696749257, ...</td>\n",
       "      <td>[0.006720440291834372, 0.008331484208161396, 0...</td>\n",
       "      <td>[-0.004862255062129871, 0.014077164724644747, ...</td>\n",
       "      <td>3.085083</td>\n",
       "      <td>3.013958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI</td>\n",
       "      <td>fingerprint</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.006466897059812569, 0.014694837542908411, -...</td>\n",
       "      <td>[0.01523113309590259, 0.005271417380511587, -0...</td>\n",
       "      <td>2.823093</td>\n",
       "      <td>2.745230</td>\n",
       "      <td>[0.006466894365273728, 0.014694831420063071, -...</td>\n",
       "      <td>[0.013922101136130544, 0.0023911842131386003, ...</td>\n",
       "      <td>[0.006466894365273728, 0.014694831420063071, -...</td>\n",
       "      <td>[0.013814564227839972, 0.0024352598952305004, ...</td>\n",
       "      <td>2.823093</td>\n",
       "      <td>2.816176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI</td>\n",
       "      <td>investigation</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.006466897059812569, 0.014694837542908411, -...</td>\n",
       "      <td>[0.013016090623183913, 0.01114268771757639, -0...</td>\n",
       "      <td>2.920986</td>\n",
       "      <td>2.886161</td>\n",
       "      <td>[0.006466894365273728, 0.014694831420063071, -...</td>\n",
       "      <td>[0.01327496060589727, 0.010965634890657862, -0...</td>\n",
       "      <td>[0.006466894365273728, 0.014694831420063071, -...</td>\n",
       "      <td>[0.013242882546106787, 0.010953106196386554, -...</td>\n",
       "      <td>2.920986</td>\n",
       "      <td>2.919120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Yale</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.01322626159341165, 0.005047111630696947, -0...</td>\n",
       "      <td>[0.010410829393995813, 0.014776997996557633, -...</td>\n",
       "      <td>1.707655</td>\n",
       "      <td>1.707655</td>\n",
       "      <td>[0.013226256082472592, 0.005047109527735016, -...</td>\n",
       "      <td>[0.010410825056152807, 0.014776991839478788, -...</td>\n",
       "      <td>[0.013226256082472592, 0.005047109527735016, -...</td>\n",
       "      <td>[0.010410825056152807, 0.014776991839478788, -...</td>\n",
       "      <td>1.707655</td>\n",
       "      <td>1.707655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word 1         Word 2   ID  H_Sim H_Dim  F_Sim F_Dim  N_Sim N_Dim  D_Sim  \\\n",
       "0   Arafat          peace    8      3     D      4   NaN      3     U      4   \n",
       "1   Arafat         terror    9      3     D      4   NaN      3     U      4   \n",
       "2      FBI    fingerprint  109      3     D      4   NaN      4   NaN      3   \n",
       "3      FBI  investigation  110      3     U      3     U      3     U      3   \n",
       "4  Harvard           Yale  137      2     S      3     S      2     S      2   \n",
       "\n",
       "   ...                            concat_19k_v2_word1_new  \\\n",
       "0  ...  [0.006720443092017323, 0.008331487679612525, 0...   \n",
       "1  ...  [0.006720443092017323, 0.008331487679612525, 0...   \n",
       "2  ...  [0.006466897059812569, 0.014694837542908411, -...   \n",
       "3  ...  [0.006466897059812569, 0.014694837542908411, -...   \n",
       "4  ...  [0.01322626159341165, 0.005047111630696947, -0...   \n",
       "\n",
       "                             concat_19k_v2_word2_new concat_19k_v2_old_cosSim  \\\n",
       "0  [-0.004515859576248157, -0.01172366887295375, ...                 3.244539   \n",
       "1  [-0.004862257088069111, 0.014077170590128979, ...                 3.085083   \n",
       "2  [0.01523113309590259, 0.005271417380511587, -0...                 2.823093   \n",
       "3  [0.013016090623183913, 0.01114268771757639, -0...                 2.920986   \n",
       "4  [0.010410829393995813, 0.014776997996557633, -...                 1.707655   \n",
       "\n",
       "   concat_19k_v2_2_new_cosSim  \\\n",
       "0                    3.175157   \n",
       "1                    3.013958   \n",
       "2                    2.745230   \n",
       "3                    2.886161   \n",
       "4                    1.707655   \n",
       "\n",
       "                     concat_probase_19k_v2_word1_old  \\\n",
       "0  [0.006720440291834372, 0.008331484208161396, 0...   \n",
       "1  [0.006720440291834372, 0.008331484208161396, 0...   \n",
       "2  [0.006466894365273728, 0.014694831420063071, -...   \n",
       "3  [0.006466894365273728, 0.014694831420063071, -...   \n",
       "4  [0.013226256082472592, 0.005047109527735016, -...   \n",
       "\n",
       "                     concat_probase_19k_v2_word2_old  \\\n",
       "0  [-0.005011610937734838, -0.013383541550578623,...   \n",
       "1  [-0.005805280438126139, 0.015115419696749257, ...   \n",
       "2  [0.013922101136130544, 0.0023911842131386003, ...   \n",
       "3  [0.01327496060589727, 0.010965634890657862, -0...   \n",
       "4  [0.010410825056152807, 0.014776991839478788, -...   \n",
       "\n",
       "                     concat_probase_19k_v2_word1_new  \\\n",
       "0  [0.006720440291834372, 0.008331484208161396, 0...   \n",
       "1  [0.006720440291834372, 0.008331484208161396, 0...   \n",
       "2  [0.006466894365273728, 0.014694831420063071, -...   \n",
       "3  [0.006466894365273728, 0.014694831420063071, -...   \n",
       "4  [0.013226256082472592, 0.005047109527735016, -...   \n",
       "\n",
       "                     concat_probase_19k_v2_word2_new  \\\n",
       "0  [-0.00497129831746384, -0.01325426749683971, -...   \n",
       "1  [-0.004862255062129871, 0.014077164724644747, ...   \n",
       "2  [0.013814564227839972, 0.0024352598952305004, ...   \n",
       "3  [0.013242882546106787, 0.010953106196386554, -...   \n",
       "4  [0.010410825056152807, 0.014776991839478788, -...   \n",
       "\n",
       "  concat_probase_19k_v2_old_cosSim concat_probase_19k_v2_2_new_cosSim  \n",
       "0                         3.244539                           3.240270  \n",
       "1                         3.085083                           3.013958  \n",
       "2                         2.823093                           2.816176  \n",
       "3                         2.920986                           2.919120  \n",
       "4                         1.707655                           1.707655  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "expanded-uniform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_7props_19k_old_cosSim</th>\n",
       "      <th>text_7props_19k_2_new_cosSim</th>\n",
       "      <th>text_2props_19k_old_cosSim</th>\n",
       "      <th>text_2props_19k_2_new_cosSim</th>\n",
       "      <th>complex_19k_old_cosSim</th>\n",
       "      <th>complex_19k_2_new_cosSim</th>\n",
       "      <th>transe_19k_old_cosSim</th>\n",
       "      <th>transe_19k_1_new_cosSim</th>\n",
       "      <th>abstract_19k_old_cosSim</th>\n",
       "      <th>abstract_19k_2_new_cosSim</th>\n",
       "      <th>...</th>\n",
       "      <th>transe_probase_19k_old_cosSim</th>\n",
       "      <th>transe_probase_19k_1_new_cosSim</th>\n",
       "      <th>concat_19k_v1_old_cosSim</th>\n",
       "      <th>concat_19k_v1_2_new_cosSim</th>\n",
       "      <th>concat_probase_19k_v1_old_cosSim</th>\n",
       "      <th>concat_probase_19k_v1_2_new_cosSim</th>\n",
       "      <th>concat_19k_v2_old_cosSim</th>\n",
       "      <th>concat_19k_v2_2_new_cosSim</th>\n",
       "      <th>concat_probase_19k_v2_old_cosSim</th>\n",
       "      <th>concat_probase_19k_v2_2_new_cosSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.511033</td>\n",
       "      <td>2.464876</td>\n",
       "      <td>2.482254</td>\n",
       "      <td>2.435161</td>\n",
       "      <td>2.983302</td>\n",
       "      <td>2.684818</td>\n",
       "      <td>2.983302</td>\n",
       "      <td>2.680002</td>\n",
       "      <td>2.652866</td>\n",
       "      <td>2.593916</td>\n",
       "      <td>...</td>\n",
       "      <td>2.983302</td>\n",
       "      <td>2.565886</td>\n",
       "      <td>2.875381</td>\n",
       "      <td>2.826493</td>\n",
       "      <td>2.875381</td>\n",
       "      <td>2.865101</td>\n",
       "      <td>2.868066</td>\n",
       "      <td>2.816685</td>\n",
       "      <td>2.868066</td>\n",
       "      <td>2.856603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.148821</td>\n",
       "      <td>1.152911</td>\n",
       "      <td>1.151060</td>\n",
       "      <td>1.155427</td>\n",
       "      <td>0.645911</td>\n",
       "      <td>0.539092</td>\n",
       "      <td>0.645911</td>\n",
       "      <td>0.619239</td>\n",
       "      <td>0.680525</td>\n",
       "      <td>0.653512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645911</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.573902</td>\n",
       "      <td>0.575585</td>\n",
       "      <td>0.573902</td>\n",
       "      <td>0.574410</td>\n",
       "      <td>1.097121</td>\n",
       "      <td>1.106362</td>\n",
       "      <td>1.097121</td>\n",
       "      <td>1.099179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.005097</td>\n",
       "      <td>1.963229</td>\n",
       "      <td>1.993424</td>\n",
       "      <td>1.949869</td>\n",
       "      <td>2.588591</td>\n",
       "      <td>2.455431</td>\n",
       "      <td>2.588591</td>\n",
       "      <td>2.311818</td>\n",
       "      <td>2.180912</td>\n",
       "      <td>2.137568</td>\n",
       "      <td>...</td>\n",
       "      <td>2.588591</td>\n",
       "      <td>2.183686</td>\n",
       "      <td>2.577938</td>\n",
       "      <td>2.551033</td>\n",
       "      <td>2.577938</td>\n",
       "      <td>2.583811</td>\n",
       "      <td>2.384337</td>\n",
       "      <td>2.350645</td>\n",
       "      <td>2.384337</td>\n",
       "      <td>2.377672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.328276</td>\n",
       "      <td>2.273674</td>\n",
       "      <td>2.274668</td>\n",
       "      <td>2.232156</td>\n",
       "      <td>3.039087</td>\n",
       "      <td>2.708569</td>\n",
       "      <td>3.039087</td>\n",
       "      <td>2.722278</td>\n",
       "      <td>2.616810</td>\n",
       "      <td>2.591640</td>\n",
       "      <td>...</td>\n",
       "      <td>3.039087</td>\n",
       "      <td>2.608041</td>\n",
       "      <td>2.950578</td>\n",
       "      <td>2.912098</td>\n",
       "      <td>2.950578</td>\n",
       "      <td>2.933984</td>\n",
       "      <td>2.716471</td>\n",
       "      <td>2.657078</td>\n",
       "      <td>2.716471</td>\n",
       "      <td>2.704941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.636907</td>\n",
       "      <td>2.576155</td>\n",
       "      <td>2.580482</td>\n",
       "      <td>2.527554</td>\n",
       "      <td>3.359243</td>\n",
       "      <td>2.959259</td>\n",
       "      <td>3.359243</td>\n",
       "      <td>3.090563</td>\n",
       "      <td>3.208919</td>\n",
       "      <td>3.060782</td>\n",
       "      <td>...</td>\n",
       "      <td>3.359243</td>\n",
       "      <td>2.935226</td>\n",
       "      <td>3.208735</td>\n",
       "      <td>3.164426</td>\n",
       "      <td>3.208735</td>\n",
       "      <td>3.196270</td>\n",
       "      <td>2.992265</td>\n",
       "      <td>2.899626</td>\n",
       "      <td>2.992265</td>\n",
       "      <td>2.977770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.340089</td>\n",
       "      <td>4.327902</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_7props_19k_old_cosSim  text_7props_19k_2_new_cosSim  \\\n",
       "count                  344.000000                    344.000000   \n",
       "mean                     2.511033                      2.464876   \n",
       "std                      1.148821                      1.152911   \n",
       "min                      1.000000                      1.000000   \n",
       "25%                      2.005097                      1.963229   \n",
       "50%                      2.328276                      2.273674   \n",
       "75%                      2.636907                      2.576155   \n",
       "max                      7.000000                      7.000000   \n",
       "\n",
       "       text_2props_19k_old_cosSim  text_2props_19k_2_new_cosSim  \\\n",
       "count                  344.000000                    344.000000   \n",
       "mean                     2.482254                      2.435161   \n",
       "std                      1.151060                      1.155427   \n",
       "min                      1.000000                      1.000000   \n",
       "25%                      1.993424                      1.949869   \n",
       "50%                      2.274668                      2.232156   \n",
       "75%                      2.580482                      2.527554   \n",
       "max                      7.000000                      7.000000   \n",
       "\n",
       "       complex_19k_old_cosSim  complex_19k_2_new_cosSim  \\\n",
       "count              344.000000                344.000000   \n",
       "mean                 2.983302                  2.684818   \n",
       "std                  0.645911                  0.539092   \n",
       "min                  1.000000                  1.000000   \n",
       "25%                  2.588591                  2.455431   \n",
       "50%                  3.039087                  2.708569   \n",
       "75%                  3.359243                  2.959259   \n",
       "max                  7.000000                  7.000000   \n",
       "\n",
       "       transe_19k_old_cosSim  transe_19k_1_new_cosSim  \\\n",
       "count             344.000000               344.000000   \n",
       "mean                2.983302                 2.680002   \n",
       "std                 0.645911                 0.619239   \n",
       "min                 1.000000                 1.000000   \n",
       "25%                 2.588591                 2.311818   \n",
       "50%                 3.039087                 2.722278   \n",
       "75%                 3.359243                 3.090563   \n",
       "max                 7.000000                 7.000000   \n",
       "\n",
       "       abstract_19k_old_cosSim  abstract_19k_2_new_cosSim  ...  \\\n",
       "count               344.000000                 344.000000  ...   \n",
       "mean                  2.652866                   2.593916  ...   \n",
       "std                   0.680525                   0.653512  ...   \n",
       "min                   1.000000                   1.000000  ...   \n",
       "25%                   2.180912                   2.137568  ...   \n",
       "50%                   2.616810                   2.591640  ...   \n",
       "75%                   3.208919                   3.060782  ...   \n",
       "max                   4.340089                   4.327902  ...   \n",
       "\n",
       "       transe_probase_19k_old_cosSim  transe_probase_19k_1_new_cosSim  \\\n",
       "count                     344.000000                       344.000000   \n",
       "mean                        2.983302                         2.565886   \n",
       "std                         0.645911                         0.596750   \n",
       "min                         1.000000                         1.000000   \n",
       "25%                         2.588591                         2.183686   \n",
       "50%                         3.039087                         2.608041   \n",
       "75%                         3.359243                         2.935226   \n",
       "max                         7.000000                         7.000000   \n",
       "\n",
       "       concat_19k_v1_old_cosSim  concat_19k_v1_2_new_cosSim  \\\n",
       "count                344.000000                  344.000000   \n",
       "mean                   2.875381                    2.826493   \n",
       "std                    0.573902                    0.575585   \n",
       "min                    1.000000                    1.000000   \n",
       "25%                    2.577938                    2.551033   \n",
       "50%                    2.950578                    2.912098   \n",
       "75%                    3.208735                    3.164426   \n",
       "max                    7.000000                    7.000000   \n",
       "\n",
       "       concat_probase_19k_v1_old_cosSim  concat_probase_19k_v1_2_new_cosSim  \\\n",
       "count                        344.000000                          344.000000   \n",
       "mean                           2.875381                            2.865101   \n",
       "std                            0.573902                            0.574410   \n",
       "min                            1.000000                            1.000000   \n",
       "25%                            2.577938                            2.583811   \n",
       "50%                            2.950578                            2.933984   \n",
       "75%                            3.208735                            3.196270   \n",
       "max                            7.000000                            7.000000   \n",
       "\n",
       "       concat_19k_v2_old_cosSim  concat_19k_v2_2_new_cosSim  \\\n",
       "count                344.000000                  344.000000   \n",
       "mean                   2.868066                    2.816685   \n",
       "std                    1.097121                    1.106362   \n",
       "min                    1.000000                    1.000000   \n",
       "25%                    2.384337                    2.350645   \n",
       "50%                    2.716471                    2.657078   \n",
       "75%                    2.992265                    2.899626   \n",
       "max                    7.000000                    7.000000   \n",
       "\n",
       "       concat_probase_19k_v2_old_cosSim  concat_probase_19k_v2_2_new_cosSim  \n",
       "count                        344.000000                          344.000000  \n",
       "mean                           2.868066                            2.856603  \n",
       "std                            1.097121                            1.099179  \n",
       "min                            1.000000                            1.000000  \n",
       "25%                            2.384337                            2.377672  \n",
       "50%                            2.716471                            2.704941  \n",
       "75%                            2.992265                            2.977770  \n",
       "max                            7.000000                            7.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF[list(filter(lambda p: 'cosSim' in p, wordSim353AnnotDF_New_Merged_DF.columns.to_list()))].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "indian-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacompy\n",
    "compare = datacompy.Compare(\n",
    "    wordSim353AnnotDF_New_Merged_DF[['Word 1',\n",
    " 'Word 2',\n",
    " 'Avg',\n",
    " 'word1_kg_id',\n",
    " 'word2_kg_id',\n",
    " 'category'] + list(filter(lambda p: 'cosSim' in p, wordSim353AnnotDF_New_Merged_DF.columns.to_list()))],\n",
    "    wordSim353AnnotDF_New_Merged_DF_old[['Word 1',\n",
    " 'Word 2',\n",
    " 'Avg',\n",
    " 'word1_kg_id',\n",
    " 'word2_kg_id',\n",
    " 'category'] + list(filter(lambda p: 'cosSim' in p, wordSim353AnnotDF_New_Merged_DF_old.columns.to_list()))],\n",
    "    join_columns = ['Word 1', 'Word 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "vocational-nurse",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataComPy Comparison\n",
      "--------------------\n",
      "\n",
      "DataFrame Summary\n",
      "-----------------\n",
      "\n",
      "  DataFrame  Columns  Rows\n",
      "0       df1       34   344\n",
      "1       df2       34   344\n",
      "\n",
      "Column Summary\n",
      "--------------\n",
      "\n",
      "Number of columns in common: 32\n",
      "Number of columns in df1 but not in df2: 2\n",
      "Number of columns in df2 but not in df1: 2\n",
      "\n",
      "Row Summary\n",
      "-----------\n",
      "\n",
      "Matched on: word 1, word 2\n",
      "Any duplicates on match values: No\n",
      "Absolute Tolerance: 0\n",
      "Relative Tolerance: 0\n",
      "Number of rows in common: 344\n",
      "Number of rows in df1 but not in df2: 0\n",
      "Number of rows in df2 but not in df1: 0\n",
      "\n",
      "Number of rows with some compared columns unequal: 343\n",
      "Number of rows with all compared columns equal: 1\n",
      "\n",
      "Column Comparison\n",
      "-----------------\n",
      "\n",
      "Number of columns compared with some values unequal: 27\n",
      "Number of columns compared with all values equal: 5\n",
      "Total number of values which compare unequal: 5,136\n",
      "\n",
      "Columns with Unequal Values or Types\n",
      "------------------------------------\n",
      "\n",
      "                                 Column df1 dtype df2 dtype  # Unequal      Max Diff  # Null Diff\n",
      "25            abstract_19k_2_new_cossim   float64   float64          8  4.440892e-16            0\n",
      "17              abstract_19k_old_cossim   float64   float64          9  4.440892e-16            0\n",
      "8   abstract_firstsent_19k_2_new_cossim   float64   float64          8  4.440892e-16            0\n",
      "19    abstract_firstsent_19k_old_cossim   float64   float64          8  4.440892e-16            0\n",
      "6                              category    object    object          4  0.000000e+00            0\n",
      "12               complex_19k_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "21       complex_probase_19k_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "11         complex_probase_2_new_cossim   float64   float64          8  4.440892e-16            0\n",
      "18           complex_probase_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "1            concat_19k_v1_2_new_cossim   float64   float64        343  9.656675e-01            0\n",
      "22             concat_19k_v1_old_cossim   float64   float64        343  9.684394e-01            0\n",
      "2            concat_19k_v2_2_new_cossim   float64   float64        325  4.810998e-01            0\n",
      "3              concat_19k_v2_old_cossim   float64   float64        324  4.842197e-01            0\n",
      "10   concat_probase_19k_v1_2_new_cossim   float64   float64        341  9.673423e-01            0\n",
      "7      concat_probase_19k_v1_old_cossim   float64   float64        343  9.684394e-01            0\n",
      "26   concat_probase_19k_v2_2_new_cossim   float64   float64        324  4.828636e-01            0\n",
      "9      concat_probase_19k_v2_old_cossim   float64   float64        324  4.842197e-01            0\n",
      "15         text_2props_19k_2_new_cossim   float64   float64          7  4.440892e-16            0\n",
      "0            text_2props_19k_old_cossim   float64   float64          5  4.440892e-16            0\n",
      "14         text_7props_19k_2_new_cossim   float64   float64         11  4.440892e-16            0\n",
      "24           text_7props_19k_old_cossim   float64   float64          7  4.440892e-16            0\n",
      "5               transe_19k_1_new_cossim   float64   float64          5  4.440892e-16            0\n",
      "4                 transe_19k_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "16      transe_probase_19k_1_new_cossim   float64   float64        340  1.192889e-08            0\n",
      "20        transe_probase_19k_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "23          transe_probase_1_new_cossim   float64   float64          9  4.440892e-16            0\n",
      "13            transe_probase_old_cossim   float64   float64        340  1.452659e+00            0\n",
      "\n",
      "Sample Rows with Unequal Values\n",
      "-------------------------------\n",
      "\n",
      "           word 1       word 2  text_2props_19k_old_cossim (df1)  text_2props_19k_old_cossim (df2)\n",
      "33         bishop        rabbi                          2.333195                          2.333195\n",
      "69         credit         card                          1.834364                          1.834364\n",
      "107         drink          ear                          2.515900                          2.515900\n",
      "271  registration  arrangement                          1.826611                          1.826611\n",
      "169          line    insurance                          2.670612                          2.670612\n",
      "\n",
      "        word 1         word 2  concat_19k_v1_2_new_cossim (df1)  concat_19k_v1_2_new_cossim (df2)\n",
      "107      drink            ear                          3.116502                          2.813165\n",
      "112     energy         crisis                          3.024137                          3.099512\n",
      "14   admission         ticket                          2.647422                          2.819317\n",
      "63    computer       software                          2.167120                          2.273544\n",
      "241  precedent        example                          2.091422                          2.138805\n",
      "44         car         flight                          3.064250                          2.948899\n",
      "229     planet  constellation                          2.240850                          2.286295\n",
      "159       king          queen                          2.169999                          2.241265\n",
      "161        lad        brother                          2.755663                          2.733430\n",
      "297      stock            egg                          2.943623                          2.952019\n",
      "\n",
      "           word 1       word 2  concat_19k_v2_2_new_cossim (df1)  concat_19k_v2_2_new_cossim (df2)\n",
      "61       computer   laboratory                          2.670662                          2.635687\n",
      "239     precedent    cognition                          2.643438                          2.676361\n",
      "286     situation    isolation                          2.313211                          2.399693\n",
      "225       physics    chemistry                          1.755500                          1.873616\n",
      "262    psychology       doctor                          2.861167                          2.665892\n",
      "271  registration  arrangement                          1.935898                          2.144032\n",
      "111          drug        abuse                          2.653034                          2.716209\n",
      "150  impartiality     interest                          2.395906                          2.496811\n",
      "130        forest    graveyard                          2.963496                          2.743907\n",
      "80            cup    substance                          2.738585                          2.703536\n",
      "\n",
      "          word 1       word 2  concat_19k_v2_old_cossim (df1)  concat_19k_v2_old_cossim (df2)\n",
      "247    president        medal                        2.809529                        3.039440\n",
      "70        credit  information                        2.557827                        2.567752\n",
      "58   competition        price                        2.699197                        2.854295\n",
      "117      exhibit  memorabilia                        2.720881                        2.806831\n",
      "47       century       nation                        3.025727                        3.021246\n",
      "280        seven       series                        2.801360                        2.821742\n",
      "193        money       dollar                        2.376377                        2.437513\n",
      "5       Japanese     American                        2.564544                        2.535274\n",
      "340       weapon       secret                        2.889109                        2.897323\n",
      "189        money         bank                        2.261778                        2.170577\n",
      "\n",
      "       word 1     word 2  transe_19k_old_cossim (df1)  transe_19k_old_cossim (df2)\n",
      "36       book      paper                     3.078243                     2.635533\n",
      "5    Japanese   American                     2.496058                     2.408249\n",
      "26       baby     mother                     2.292784                     2.155920\n",
      "248   problem    airport                     3.826307                     3.170909\n",
      "55      coast       hill                     3.722873                     2.798622\n",
      "112    energy     crisis                     3.106233                     3.230795\n",
      "340    weapon     secret                     3.285620                     3.310261\n",
      "219     opera   industry                     3.296724                     3.553488\n",
      "169      line  insurance                     3.089979                     2.829222\n",
      "332      type       kind                     1.000000                     1.000000\n",
      "\n",
      "           word 1       word 2  transe_19k_1_new_cossim (df1)  transe_19k_1_new_cossim (df2)\n",
      "192         money      deposit                       2.837495                       2.837495\n",
      "232        planet       people                       3.716617                       3.716617\n",
      "114        energy    secretary                       2.865451                       2.865451\n",
      "304        street        block                       2.904156                       2.904156\n",
      "271  registration  arrangement                       1.933719                       1.933719\n",
      "\n",
      "       word 1       word 2 category (df1) category (df2)\n",
      "296     stock           CD              U              M\n",
      "45       cell        phone              I              M\n",
      "328      tool    implement              I              M\n",
      "237  practice  institution              M              U\n",
      "\n",
      "         word 1       word 2  concat_probase_19k_v1_old_cossim (df1)  concat_probase_19k_v1_old_cossim (df2)\n",
      "312  television         film                                3.266487                                2.813985\n",
      "191       money     currency                                2.401111                                2.298975\n",
      "243   precedent  information                                3.131530                                3.019516\n",
      "53       closet      clothes                                2.947983                                2.705879\n",
      "142  government       crisis                                3.181431                                2.683486\n",
      "183       media      trading                                3.103774                                2.822458\n",
      "89        delay       racism                                3.037041                                2.943246\n",
      "32         bird        crane                                2.323600                                2.007661\n",
      "126        food      rooster                                3.641608                                3.323421\n",
      "43          car   automobile                                1.000000                                1.000000\n",
      "\n",
      "         word 1     word 2  abstract_firstsent_19k_2_new_cossim (df1)  abstract_firstsent_19k_2_new_cossim (df2)\n",
      "67      country    citizen                                   2.307399                                   2.307399\n",
      "218         oil      stock                                   2.875288                                   2.875288\n",
      "337       vodka        gin                                   1.848263                                   1.848263\n",
      "152    investor    earning                                   1.998387                                   1.998387\n",
      "90   deployment  departure                                   1.826386                                   1.826386\n",
      "208       movie    theater                                   2.390347                                   2.390347\n",
      "263  psychology       fear                                   2.679016                                   2.679016\n",
      "96    discovery      space                                   2.952799                                   2.952799\n",
      "\n",
      "           word 1         word 2  concat_probase_19k_v2_old_cossim (df1)  concat_probase_19k_v2_old_cossim (df2)\n",
      "21   architecture        century                                3.188363                                3.081890\n",
      "117       exhibit    memorabilia                                2.720881                                2.806831\n",
      "60       computer       keyboard                                2.131908                                2.212525\n",
      "120     fertility            egg                                2.202871                                2.244311\n",
      "311     telephone  communication                                2.677514                                2.463340\n",
      "238     precedent     antecedent                                1.935676                                2.019795\n",
      "33         bishop          rabbi                                2.277504                                2.458967\n",
      "203      morality     importance                                2.272562                                2.446757\n",
      "228        planet     astronomer                                2.470710                                2.152302\n",
      "144      governor         office                                2.720705                                2.742336\n",
      "\n",
      "      word 1        word 2  concat_probase_19k_v1_2_new_cossim (df1)  concat_probase_19k_v1_2_new_cossim (df2)\n",
      "166     life         death                                  2.384376                                  2.467146\n",
      "249  problem     challenge                                  2.573163                                  2.851951\n",
      "216     noon        string                                  2.831571                                  3.404519\n",
      "214  network      hardware                                  2.797734                                  2.468385\n",
      "324    tiger        mammal                                  2.608830                                  2.218881\n",
      "269   reason  hypertension                                  3.043544                                  2.554564\n",
      "35      book       library                                  3.335751                                  2.560611\n",
      "169     line     insurance                                  3.121240                                  2.947265\n",
      "319    tiger     carnivore                                  3.332882                                  3.004569\n",
      "161      lad       brother                                  2.885448                                  2.868957\n",
      "\n",
      "           word 1      word 2  complex_probase_2_new_cossim (df1)  complex_probase_2_new_cossim (df2)\n",
      "39          bread      butter                            1.926594                            1.926594\n",
      "102        dollar        buck                            2.733086                            2.733086\n",
      "193         money      dollar                            2.733086                            2.733086\n",
      "150  impartiality    interest                            2.323327                            2.323327\n",
      "1          Arafat      terror                            3.103668                            3.103668\n",
      "266    psychology  psychiatry                            1.826092                            1.826092\n",
      "10         Mexico      Brazil                            1.921104                            1.921104\n",
      "5        Japanese    American                            2.408249                            2.408249\n",
      "\n",
      "          word 1       word 2  complex_19k_old_cossim (df1)  complex_19k_old_cossim (df2)\n",
      "115  environment      ecology                      2.920428                      2.903515\n",
      "256   psychology        Freud                      3.234018                      2.992413\n",
      "169         line    insurance                      3.089979                      2.829222\n",
      "33        bishop        rabbi                      2.300842                      2.845229\n",
      "220        opera  performance                      3.163513                      3.062105\n",
      "267   psychology      science                      2.231959                      2.334221\n",
      "265   psychology         mind                      2.886509                      2.426014\n",
      "45          cell        phone                      3.622510                      2.693966\n",
      "26          baby       mother                      2.292784                      2.155920\n",
      "161          lad      brother                      3.110214                      3.092837\n",
      "\n",
      "     word 1        word 2  transe_probase_old_cossim (df1)  transe_probase_old_cossim (df2)\n",
      "209  murder  manslaughter                         2.249251                         2.257188\n",
      "141   glass         metal                         3.225510                         2.093335\n",
      "296   stock            CD                         3.395233                         3.514011\n",
      "325   tiger      organism                         3.290722                         2.591059\n",
      "35     book       library                         3.701910                         2.539030\n",
      "2       FBI   fingerprint                         3.149125                         2.911334\n",
      "254  profit          loss                         1.653272                         1.573516\n",
      "334   video       archive                         3.219152                         2.407191\n",
      "166    life         death                         2.565452                         2.692000\n",
      "9      Mars     scientist                         3.504530                         3.187455\n",
      "\n",
      "        word 1      word 2  text_7props_19k_2_new_cossim (df1)  text_7props_19k_2_new_cossim (df2)\n",
      "176     luxury         car                            2.942098                            2.942098\n",
      "293      space       world                            2.109041                            2.109041\n",
      "309     summer     drought                            2.687325                            2.687325\n",
      "67     country     citizen                            1.942392                            1.942392\n",
      "169       line   insurance                            2.691916                            2.691916\n",
      "302      stock       phone                            2.963663                            2.963663\n",
      "5     Japanese    American                            2.145108                            2.145108\n",
      "238  precedent  antecedent                            1.844509                            1.844509\n",
      "143   governor   interview                            2.651640                            2.651640\n",
      "152   investor     earning                            1.902240                            1.902240\n",
      "\n",
      "           word 1      word 2  text_2props_19k_2_new_cossim (df1)  text_2props_19k_2_new_cossim (df2)\n",
      "329         train         car                            1.998965                            1.998965\n",
      "10         Mexico      Brazil                            1.950233                            1.950233\n",
      "19   announcement  production                            1.866451                            1.866451\n",
      "121      fighting   defeating                            1.940122                            1.940122\n",
      "293         space       world                            1.993016                            1.993016\n",
      "8        Maradona    football                            2.351065                            2.351065\n",
      "114        energy   secretary                            2.803514                            2.803514\n",
      "\n",
      "      word 1       word 2  transe_probase_19k_1_new_cossim (df1)  transe_probase_19k_1_new_cossim (df2)\n",
      "155  journal  association                               2.736767                               2.736767\n",
      "123    focus         life                               2.337493                               2.337493\n",
      "159     king        queen                               1.570639                               1.570639\n",
      "169     line    insurance                               2.557647                               2.557647\n",
      "305   street     children                               3.186623                               3.186623\n",
      "336    vodka       brandy                               1.527815                               1.527815\n",
      "232   planet       people                               3.593423                               3.593423\n",
      "130   forest    graveyard                               3.142560                               3.142560\n",
      "69    credit         card                               2.076337                               2.076337\n",
      "40   brother         monk                               2.683273                               2.683273\n",
      "\n",
      "         word 1      word 2  abstract_19k_old_cossim (df1)  abstract_19k_old_cossim (df2)\n",
      "285   situation  conclusion                       1.808156                       1.808156\n",
      "303      street      avenue                       2.281843                       2.281843\n",
      "94   disability       death                       2.746255                       2.746255\n",
      "5      Japanese    American                       3.292768                       3.292768\n",
      "183       media     trading                       3.108796                       3.108796\n",
      "11         OPEC     country                       3.042327                       3.042327\n",
      "162         lad      wizard                       3.334772                       3.334772\n",
      "129    football      tennis                       2.518421                       2.518421\n",
      "231      planet        moon                       1.920149                       1.920149\n",
      "\n",
      "           word 1        word 2  complex_probase_old_cossim (df1)  complex_probase_old_cossim (df2)\n",
      "63       computer      software                          2.565704                          2.726328\n",
      "21   architecture       century                          3.418617                          3.099197\n",
      "179           man         woman                          2.351588                          1.471079\n",
      "149         image       surface                          3.137178                          3.256807\n",
      "81            cup     tableware                          2.124012                          1.954043\n",
      "36           book         paper                          3.078243                          2.635533\n",
      "194         money    laundering                          2.759570                          2.800958\n",
      "236   possibility          girl                          3.361988                          2.920025\n",
      "209        murder  manslaughter                          2.249251                          2.257188\n",
      "218           oil         stock                          2.577913                          2.625197\n",
      "\n",
      "           word 1      word 2  abstract_firstsent_19k_old_cossim (df1)  abstract_firstsent_19k_old_cossim (df2)\n",
      "246  preservation       world                                 3.234863                                 3.234863\n",
      "5        Japanese    American                                 2.728319                                 2.728319\n",
      "285     situation  conclusion                                 1.808156                                 1.808156\n",
      "244     precedent         law                                 1.878214                                 1.878214\n",
      "94     disability       death                                 3.016865                                 3.016865\n",
      "175         lover     quarrel                                 3.157233                                 3.157233\n",
      "109         drink      mother                                 3.128050                                 3.128050\n",
      "177      magician      wizard                                 1.909871                                 1.909871\n",
      "\n",
      "        word 1   word 2  transe_probase_19k_old_cossim (df1)  transe_probase_19k_old_cossim (df2)\n",
      "79         cup   object                             2.627446                             2.362561\n",
      "234     planet     star                             2.586230                             2.320493\n",
      "176     luxury      car                             3.150901                             2.977136\n",
      "156    journey      car                             2.971068                             2.457446\n",
      "324      tiger   mammal                             2.909669                             2.322927\n",
      "120  fertility      egg                             2.547399                             2.671721\n",
      "248    problem  airport                             3.826307                             3.170909\n",
      "16    aluminum    metal                             2.712132                             1.916614\n",
      "36        book    paper                             3.078243                             2.635533\n",
      "211      music  project                             3.141641                             3.304875\n",
      "\n",
      "           word 1       word 2  complex_probase_19k_old_cossim (df1)  complex_probase_19k_old_cossim (df2)\n",
      "277       seafood      lobster                              2.240601                              2.113436\n",
      "27           bank        money                              3.066413                              2.792811\n",
      "337         vodka          gin                              1.857971                              2.369972\n",
      "211         music      project                              3.141641                              3.304875\n",
      "271  registration  arrangement                              2.319711                              2.954145\n",
      "143      governor    interview                              4.023383                              3.076389\n",
      "149         image      surface                              3.137178                              3.256807\n",
      "94     disability        death                              2.565398                              2.939547\n",
      "166          life        death                              2.565452                              2.692000\n",
      "226       physics       proton                              3.802075                              2.800635\n",
      "\n",
      "         word 1       word 2  concat_19k_v1_old_cossim (df1)  concat_19k_v1_old_cossim (df2)\n",
      "270      record       number                        2.977163                        2.589607\n",
      "282      shower        flood                        3.398140                        2.908007\n",
      "97     dividend  calculation                        2.507181                        2.708939\n",
      "239   precedent    cognition                        2.724066                        2.793355\n",
      "125        food  preparation                        2.932974                        2.836360\n",
      "342        wood       forest                        3.144257                        2.612681\n",
      "304      street        block                        2.690410                        2.201689\n",
      "250  production         crew                        2.552550                        2.783363\n",
      "6     Jerusalem       Israel                        2.978292                        2.383538\n",
      "210      museum      theater                        3.208882                        2.943593\n",
      "\n",
      "           word 1    word 2  transe_probase_1_new_cossim (df1)  transe_probase_1_new_cossim (df2)\n",
      "108         drink       eat                           2.334188                           2.334188\n",
      "25        attempt     peace                           2.624155                           2.624155\n",
      "232        planet    people                           3.392578                           3.392578\n",
      "204      morality  marriage                           2.173908                           2.173908\n",
      "267    psychology   science                           1.840069                           1.840069\n",
      "20   announcement   warning                           1.930855                           1.930855\n",
      "37         boxing     round                           3.527058                           3.527058\n",
      "77            cup      food                           2.657233                           2.657233\n",
      "73            cup  artifact                           2.065621                           2.065621\n",
      "\n",
      "         word 1         word 2  text_7props_19k_old_cossim (df1)  text_7props_19k_old_cossim (df2)\n",
      "311   telephone  communication                          2.269291                          2.269291\n",
      "205       movie         critic                          2.872865                          2.872865\n",
      "69       credit           card                          1.834364                          1.834364\n",
      "334       video        archive                          1.948662                          1.948662\n",
      "51       change       attitude                          1.894075                          1.894075\n",
      "260  psychology     depression                          1.948810                          1.948810\n",
      "63     computer       software                          1.918968                          1.918968\n",
      "\n",
      "          word 1        word 2  abstract_19k_2_new_cossim (df1)  abstract_19k_2_new_cossim (df2)\n",
      "90    deployment     departure                         1.826386                         1.826386\n",
      "14     admission        ticket                         2.890691                         2.890691\n",
      "84           day        summer                         1.820569                         1.820569\n",
      "217  observation  architecture                         2.541219                         2.541219\n",
      "243    precedent   information                         2.768309                         2.768309\n",
      "253    professor        doctor                         2.462181                         2.462181\n",
      "60      computer      keyboard                         1.977226                         1.977226\n",
      "95      disaster          area                         3.350219                         3.350219\n",
      "\n",
      "        word 1     word 2  concat_probase_19k_v2_2_new_cossim (df1)  concat_probase_19k_v2_2_new_cossim (df2)\n",
      "208      movie    theater                                  2.614114                                  2.456455\n",
      "177   magician     wizard                                  2.146197                                  2.011585\n",
      "86       death        row                                  2.990100                                  2.809539\n",
      "293      space      world                                  2.481352                                  2.412213\n",
      "123      focus       life                                  2.908816                                  2.990622\n",
      "316  territory    surface                                  2.778507                                  2.489232\n",
      "289      smart    student                                  2.754242                                  2.578396\n",
      "333     victim  emergency                                  2.380390                                  2.445431\n",
      "55       coast       hill                                  2.826077                                  2.516979\n",
      "78         cup     liquid                                  2.365327                                  2.264276\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(compare.report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "common-vietnam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1_kg_id</th>\n",
       "      <th>word2_kg_id</th>\n",
       "      <th>word 1</th>\n",
       "      <th>word 2</th>\n",
       "      <th>id</th>\n",
       "      <th>h_sim</th>\n",
       "      <th>h_dim</th>\n",
       "      <th>f_sim</th>\n",
       "      <th>f_dim</th>\n",
       "      <th>n_sim</th>\n",
       "      <th>...</th>\n",
       "      <th>concat_19k_v2_word2_new</th>\n",
       "      <th>concat_19k_v2_old_cossim</th>\n",
       "      <th>concat_19k_v2_2_new_cossim</th>\n",
       "      <th>concat_probase_19k_v2_word1_old</th>\n",
       "      <th>concat_probase_19k_v2_word2_old</th>\n",
       "      <th>concat_probase_19k_v2_word1_new</th>\n",
       "      <th>concat_probase_19k_v2_word2_new</th>\n",
       "      <th>concat_probase_19k_v2_old_cossim</th>\n",
       "      <th>concat_probase_19k_v2_2_new_cossim</th>\n",
       "      <th>avg_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q106106</td>\n",
       "      <td>Q11460</td>\n",
       "      <td>closet</td>\n",
       "      <td>clothes</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0014151543049584102, 0.003161483781535701, ...</td>\n",
       "      <td>2.697022</td>\n",
       "      <td>2.652559</td>\n",
       "      <td>[0.013902607489678993, 0.013241494756981564, -...</td>\n",
       "      <td>[0.0014224480432097992, 0.0031547764732941653,...</td>\n",
       "      <td>[0.01371531560905985, 0.013126875633706597, -0...</td>\n",
       "      <td>[0.0014206775968733409, 0.0031581452887393872,...</td>\n",
       "      <td>2.697022</td>\n",
       "      <td>2.683318</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q107</td>\n",
       "      <td>Q16502</td>\n",
       "      <td>space</td>\n",
       "      <td>world</td>\n",
       "      <td>293</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.0031782974877087693, 0.003973805776938075,...</td>\n",
       "      <td>2.485859</td>\n",
       "      <td>2.347308</td>\n",
       "      <td>[0.00027019944749503126, 0.005353652289998999,...</td>\n",
       "      <td>[-0.0032792710227188605, 0.0036472880832864947...</td>\n",
       "      <td>[0.00027492382990721006, 0.0053545622809597, -...</td>\n",
       "      <td>[-0.0032450374860671267, 0.0036673577053825254...</td>\n",
       "      <td>2.485859</td>\n",
       "      <td>2.481352</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q107</td>\n",
       "      <td>Q2329</td>\n",
       "      <td>space</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>292</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.015268952851071075, -0.0024137893437008715,...</td>\n",
       "      <td>2.798788</td>\n",
       "      <td>2.782963</td>\n",
       "      <td>[0.00027019944749503126, 0.005353652289998999,...</td>\n",
       "      <td>[0.015322423107720673, -0.0024500099720118624,...</td>\n",
       "      <td>[0.00027492382990721006, 0.0053545622809597, -...</td>\n",
       "      <td>[0.015281665873653082, -0.002421165402091456, ...</td>\n",
       "      <td>2.798788</td>\n",
       "      <td>2.795047</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1074</td>\n",
       "      <td>Q7364</td>\n",
       "      <td>skin</td>\n",
       "      <td>eye</td>\n",
       "      <td>288</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.002992664951436964, 0.013922942027531155, -...</td>\n",
       "      <td>2.355813</td>\n",
       "      <td>2.314417</td>\n",
       "      <td>[-0.0026976204618851985, 0.001541600665881322,...</td>\n",
       "      <td>[0.0033640181667058486, 0.014044398230441645, ...</td>\n",
       "      <td>[-0.002678224125439186, 0.0015598357892553907,...</td>\n",
       "      <td>[0.0033484286344994184, 0.014002864550517797, ...</td>\n",
       "      <td>2.355813</td>\n",
       "      <td>2.350603</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1079023</td>\n",
       "      <td>Q500834</td>\n",
       "      <td>championship</td>\n",
       "      <td>tournament</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.00920825730356781, 0.011965374832474578, 0....</td>\n",
       "      <td>1.868699</td>\n",
       "      <td>1.865663</td>\n",
       "      <td>[-0.0008601077391385219, 0.005201185839222482,...</td>\n",
       "      <td>[0.00923153244996602, 0.011960544533439752, 0....</td>\n",
       "      <td>[-0.0008458279784483333, 0.005209858282773185,...</td>\n",
       "      <td>[0.009207264410626997, 0.011951895965764294, 0...</td>\n",
       "      <td>1.868699</td>\n",
       "      <td>1.866785</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  word1_kg_id word2_kg_id        word 1      word 2   id  h_sim h_dim  f_sim  \\\n",
       "0     Q106106      Q11460        closet     clothes   42      3     H      3   \n",
       "1        Q107      Q16502         space       world  293      3     L      3   \n",
       "2        Q107       Q2329         space   chemistry  292      4   NaN      4   \n",
       "3       Q1074       Q7364          skin         eye  288      3     H      3   \n",
       "4    Q1079023     Q500834  championship  tournament   38      1   NaN      1   \n",
       "\n",
       "  f_dim  n_sim  ...                            concat_19k_v2_word2_new  \\\n",
       "0     H      3  ...  [0.0014151543049584102, 0.003161483781535701, ...   \n",
       "1     S      3  ...  [-0.0031782974877087693, 0.003973805776938075,...   \n",
       "2   NaN      4  ...  [0.015268952851071075, -0.0024137893437008715,...   \n",
       "3     H      3  ...  [0.002992664951436964, 0.013922942027531155, -...   \n",
       "4   NaN      2  ...  [0.00920825730356781, 0.011965374832474578, 0....   \n",
       "\n",
       "   concat_19k_v2_old_cossim concat_19k_v2_2_new_cossim  \\\n",
       "0                  2.697022                   2.652559   \n",
       "1                  2.485859                   2.347308   \n",
       "2                  2.798788                   2.782963   \n",
       "3                  2.355813                   2.314417   \n",
       "4                  1.868699                   1.865663   \n",
       "\n",
       "                     concat_probase_19k_v2_word1_old  \\\n",
       "0  [0.013902607489678993, 0.013241494756981564, -...   \n",
       "1  [0.00027019944749503126, 0.005353652289998999,...   \n",
       "2  [0.00027019944749503126, 0.005353652289998999,...   \n",
       "3  [-0.0026976204618851985, 0.001541600665881322,...   \n",
       "4  [-0.0008601077391385219, 0.005201185839222482,...   \n",
       "\n",
       "                     concat_probase_19k_v2_word2_old  \\\n",
       "0  [0.0014224480432097992, 0.0031547764732941653,...   \n",
       "1  [-0.0032792710227188605, 0.0036472880832864947...   \n",
       "2  [0.015322423107720673, -0.0024500099720118624,...   \n",
       "3  [0.0033640181667058486, 0.014044398230441645, ...   \n",
       "4  [0.00923153244996602, 0.011960544533439752, 0....   \n",
       "\n",
       "                     concat_probase_19k_v2_word1_new  \\\n",
       "0  [0.01371531560905985, 0.013126875633706597, -0...   \n",
       "1  [0.00027492382990721006, 0.0053545622809597, -...   \n",
       "2  [0.00027492382990721006, 0.0053545622809597, -...   \n",
       "3  [-0.002678224125439186, 0.0015598357892553907,...   \n",
       "4  [-0.0008458279784483333, 0.005209858282773185,...   \n",
       "\n",
       "                     concat_probase_19k_v2_word2_new  \\\n",
       "0  [0.0014206775968733409, 0.0031581452887393872,...   \n",
       "1  [-0.0032450374860671267, 0.0036673577053825254...   \n",
       "2  [0.015281665873653082, -0.002421165402091456, ...   \n",
       "3  [0.0033484286344994184, 0.014002864550517797, ...   \n",
       "4  [0.009207264410626997, 0.011951895965764294, 0...   \n",
       "\n",
       "   concat_probase_19k_v2_old_cossim  concat_probase_19k_v2_2_new_cossim  \\\n",
       "0                          2.697022                            2.683318   \n",
       "1                          2.485859                            2.481352   \n",
       "2                          2.798788                            2.795047   \n",
       "3                          2.355813                            2.350603   \n",
       "4                          1.868699                            1.866785   \n",
       "\n",
       "  avg_old  \n",
       "0     3.0  \n",
       "1     3.2  \n",
       "2     4.0  \n",
       "3     3.0  \n",
       "4     1.2  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "rising-platform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20519776]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(np.array([float(val1) for val1 in wordSim353AnnotDF_New_Merged_DF.iloc[0]['concat_19k_v2_word1_new'][1:-1].split(\",\")]).reshape(1,-1), np.array([float(val1) for val1 in wordSim353AnnotDF_New_Merged_DF.iloc[0]['concat_19k_v2_word2_new'][1:-1].split(\",\")]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "governing-offer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Word 1', 'Word 2', 'ID', 'H_Sim', 'H_Dim', 'F_Sim', 'F_Dim', 'N_Sim',\n",
       "       'N_Dim', 'D_Sim',\n",
       "       ...\n",
       "       'concat_19k_v2_word1_new', 'concat_19k_v2_word2_new',\n",
       "       'concat_19k_v2_old_cosSim', 'concat_19k_v2_2_new_cosSim',\n",
       "       'concat_probase_19k_v2_word1_old', 'concat_probase_19k_v2_word2_old',\n",
       "       'concat_probase_19k_v2_word1_new', 'concat_probase_19k_v2_word2_new',\n",
       "       'concat_probase_19k_v2_old_cosSim',\n",
       "       'concat_probase_19k_v2_2_new_cosSim'],\n",
       "      dtype='object', length=104)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSim353AnnotDF_New_Merged_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "rough-february",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_7props_19k_old_cosSim',\n",
       " 'text_7props_19k_2_new_cosSim',\n",
       " 'text_2props_19k_old_cosSim',\n",
       " 'text_2props_19k_2_new_cosSim',\n",
       " 'complex_19k_old_cosSim',\n",
       " 'complex_19k_2_new_cosSim',\n",
       " 'transe_19k_old_cosSim',\n",
       " 'transe_19k_1_new_cosSim',\n",
       " 'abstract_19k_old_cosSim',\n",
       " 'abstract_19k_2_new_cosSim',\n",
       " 'abstract_firstSent_19k_old_cosSim',\n",
       " 'abstract_firstSent_19k_2_new_cosSim',\n",
       " 'complex_probase_old_cosSim',\n",
       " 'complex_probase_2_new_cosSim',\n",
       " 'transe_probase_old_cosSim',\n",
       " 'transe_probase_1_new_cosSim',\n",
       " 'complex_probase_19k_old_cosSim',\n",
       " 'complex_probase_19k_2_new_cosSim',\n",
       " 'transe_probase_19k_old_cosSim',\n",
       " 'transe_probase_19k_1_new_cosSim',\n",
       " 'concat_19k_v1_old_cosSim',\n",
       " 'concat_19k_v1_2_new_cosSim',\n",
       " 'concat_probase_19k_v1_old_cosSim',\n",
       " 'concat_probase_19k_v1_2_new_cosSim',\n",
       " 'concat_19k_v2_old_cosSim',\n",
       " 'concat_19k_v2_2_new_cosSim',\n",
       " 'concat_probase_19k_v2_old_cosSim',\n",
       " 'concat_probase_19k_v2_2_new_cosSim']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda p: 'cosSim' in p, wordSim353AnnotDF_New_Merged_DF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "hired-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "extraordinary-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_pairs = [('text_7props_19k', 'text_7props_19k_2'),\n",
    "             ('text_2props_19k', 'text_2props_19k_2'),\n",
    "             ('complex_19k', 'complex_19k_2'),\n",
    "             ('transe_19k', 'transe_19k_1'),\n",
    "             ('abstract_19k', 'abstract_19k_2'),\n",
    "             ('abstract_firstSent_19k', 'abstract_firstSent_19k_2'),\n",
    "             ('complex_probase', 'complex_probase_2'),\n",
    "             ('transe_probase', 'transe_probase_1'),\n",
    "             ('complex_probase_19k', 'complex_probase_19k_2'),\n",
    "             ('transe_probase_19k', 'transe_probase_19k_1'),\n",
    "             ('concat_19k_v1', 'concat_19k_v1_2'),\n",
    "             ('concat_probase_19k_v1', 'concat_probase_19k_v1_2'),\n",
    "             ('concat_19k_v2', 'concat_19k_v2_2'),\n",
    "             ('concat_probase_19k_v2', 'concat_probase_19k_v2_2')]\n",
    "colMappers = {p[0]+'_old_cosSim': p[1]+'_new_cosSim' for p in emb_pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "political-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldColList = list(filter(lambda p: 'old_cosSim' in p, wordSim353AnnotDF_New_Merged_DF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "flexible-booking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_7props_19k_old_cosSim',\n",
       " 'text_2props_19k_old_cosSim',\n",
       " 'complex_19k_old_cosSim',\n",
       " 'transe_19k_old_cosSim',\n",
       " 'abstract_19k_old_cosSim',\n",
       " 'abstract_firstSent_19k_old_cosSim',\n",
       " 'complex_probase_old_cosSim',\n",
       " 'transe_probase_old_cosSim',\n",
       " 'complex_probase_19k_old_cosSim',\n",
       " 'transe_probase_19k_old_cosSim',\n",
       " 'concat_19k_v1_old_cosSim',\n",
       " 'concat_probase_19k_v1_old_cosSim',\n",
       " 'concat_19k_v2_old_cosSim',\n",
       " 'concat_probase_19k_v2_old_cosSim']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldColList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "radio-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSim353AnnotDF_New = pd.read_csv('../data/wordsim353_with_r3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "recent-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oldColList, [colMappers[col] for col in oldColList]\n",
    "t1234 = []\n",
    "t4567 = []\n",
    "for col in oldColList:\n",
    "    t1234.append(accuracy_score(wordSim353AnnotDF_New_Merged_DF.Avg.apply(label_samples), wordSim353AnnotDF_New_Merged_DF[col].apply(label_samples)))\n",
    "    t4567.append(accuracy_score(wordSim353AnnotDF_New_Merged_DF.Avg.apply(label_samples), wordSim353AnnotDF_New_Merged_DF[colMappers[col]].apply(label_samples)))\n",
    "                 \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "opening-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1234 = list(zip(indNames,t1234, t4567))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "settled-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1234 = pd.DataFrame(t1234, columns=['Type', 'Accuracy (in %) of old embeddings compared to annotated category', 'Accuracy (in %) of new embeddings compared to annotated category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "young-heath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - 19k</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.686047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.680233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Complex - Probase-19k</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>0.662791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complex - 19k</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>0.659884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Complex - Probase</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>0.656977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transe - 19k</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>0.654070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.654070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transe - Probase</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>0.645349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Transe - Probase-19k</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>0.642442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract - 19k</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.627907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6 embeddings - Probase-19k</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.627907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6 embeddings - 19k</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text 7 props - 19k</td>\n",
       "      <td>0.572674</td>\n",
       "      <td>0.569767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text 2 props - 19k</td>\n",
       "      <td>0.566860</td>\n",
       "      <td>0.555233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Type  \\\n",
       "10          Complex-Transe-AbsFirstSent - 19k   \n",
       "11  Complex-Transe-AbsFirstSent - Probase-19k   \n",
       "8                       Complex - Probase-19k   \n",
       "2                               Complex - 19k   \n",
       "6                           Complex - Probase   \n",
       "3                                Transe - 19k   \n",
       "5               Abstract First Sentence - 19k   \n",
       "7                            Transe - Probase   \n",
       "9                        Transe - Probase-19k   \n",
       "4                              Abstract - 19k   \n",
       "13                 6 embeddings - Probase-19k   \n",
       "12                         6 embeddings - 19k   \n",
       "0                          Text 7 props - 19k   \n",
       "1                          Text 2 props - 19k   \n",
       "\n",
       "    Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "10                                           0.680233                  \n",
       "11                                           0.680233                  \n",
       "8                                            0.598837                  \n",
       "2                                            0.598837                  \n",
       "6                                            0.598837                  \n",
       "3                                            0.598837                  \n",
       "5                                            0.651163                  \n",
       "7                                            0.598837                  \n",
       "9                                            0.598837                  \n",
       "4                                            0.627907                  \n",
       "13                                           0.625000                  \n",
       "12                                           0.625000                  \n",
       "0                                            0.572674                  \n",
       "1                                            0.566860                  \n",
       "\n",
       "    Accuracy (in %) of new embeddings compared to annotated category  \n",
       "10                                           0.686047                 \n",
       "11                                           0.680233                 \n",
       "8                                            0.662791                 \n",
       "2                                            0.659884                 \n",
       "6                                            0.656977                 \n",
       "3                                            0.654070                 \n",
       "5                                            0.654070                 \n",
       "7                                            0.645349                 \n",
       "9                                            0.642442                 \n",
       "4                                            0.627907                 \n",
       "13                                           0.627907                 \n",
       "12                                           0.625000                 \n",
       "0                                            0.569767                 \n",
       "1                                            0.555233                 "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1234.sort_values(by=['Accuracy (in %) of new embeddings compared to annotated category'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "beneficial-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndGenerateAccuracies(wordSim353AnnotDF_New_Merged_DF, colList):\n",
    "    X = wordSim353AnnotDF_New_Merged_DF[colList]\n",
    "    Y = wordSim353AnnotDF_New_Merged_DF['category']\n",
    "\n",
    "    N_SPLITS = 10\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, random_state=19, shuffle=True)\n",
    "    X_train_splits, X_test_splits, Y_train_splits, Y_test_splits = [], [], [], []\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        X_train_splits.append(X.iloc[train_index])\n",
    "        X_test_splits.append(X.iloc[test_index])\n",
    "        Y_train_splits.append(Y.iloc[train_index])\n",
    "        Y_test_splits.append(Y.iloc[test_index])\n",
    "\n",
    "    preds = []\n",
    "    for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=100))\n",
    "        clf.fit(X_train1, Y_train1)\n",
    "        preds.append(clf.predict(X_test1))\n",
    "\n",
    "    tempVals = []\n",
    "\n",
    "    acc = 0\n",
    "    for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "        acc += accuracy_score(pred, Y_test1)\n",
    "\n",
    "    tempVals.append(acc/N_SPLITS)\n",
    "\n",
    "    for col in colList:\n",
    "        preds = []\n",
    "        for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "            clf1 = make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=100))\n",
    "            clf1.fit(X_train1[[col]], Y_train1)\n",
    "            preds.append(clf1.predict(X_test1[[col]]))\n",
    "        acc = 0\n",
    "        for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "            acc += accuracy_score(pred, Y_test1)\n",
    "        tempVals.append(acc/N_SPLITS)\n",
    "    return tempVals\n",
    "\n",
    "def compareEmbeddings(wordSim353AnnotDF_New_Merged_DF, oldColList, newColList, indNames):\n",
    "    tempVals1 = trainAndGenerateAccuracies(wordSim353AnnotDF_New_Merged_DF, oldColList)\n",
    "    tempVals2 = trainAndGenerateAccuracies(wordSim353AnnotDF_New_Merged_DF, newColList)\n",
    "    summ = (pd.DataFrame(list(zip(tempVals1, tempVals2)), index = ['Combined'] + indNames, columns = ['Accuracy (in %) of old embeddings compared to annotated category', 'Accuracy (in %) of new embeddings compared to annotated category']) * 100)\n",
    "    summ['Increase'] = summ['Accuracy (in %) of new embeddings compared to annotated category'] - summ['Accuracy (in %) of old embeddings compared to annotated category']\n",
    "    return summ.sort_values(by=['Increase'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "intensive-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndFindAccuracy(wordSim353AnnotDF_New_Merged_DF, colList):\n",
    "    X = wordSim353AnnotDF_New_Merged_DF[colList]\n",
    "    Y = wordSim353AnnotDF_New_Merged_DF['category']\n",
    "\n",
    "    N_SPLITS = 10\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, random_state=19, shuffle=True)\n",
    "    X_train_splits, X_test_splits, Y_train_splits, Y_test_splits = [], [], [], []\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        X_train_splits.append(X.iloc[train_index])\n",
    "        X_test_splits.append(X.iloc[test_index])\n",
    "        Y_train_splits.append(Y.iloc[train_index])\n",
    "        Y_test_splits.append(Y.iloc[test_index])\n",
    "\n",
    "    preds = []\n",
    "    for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=100))\n",
    "        clf.fit(X_train1, Y_train1)\n",
    "        preds.append(clf.predict(X_test1))\n",
    "\n",
    "    tempVals = []\n",
    "\n",
    "    acc = 0\n",
    "    for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "        acc += accuracy_score(pred, Y_test1)\n",
    "\n",
    "    return acc/N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "significant-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndFindAccuracyRF(wordSim353AnnotDF_New_Merged_DF, colList):\n",
    "    X = wordSim353AnnotDF_New_Merged_DF[colList]\n",
    "    Y = wordSim353AnnotDF_New_Merged_DF['category']\n",
    "\n",
    "    N_SPLITS = 10\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, random_state=19, shuffle=True)\n",
    "    X_train_splits, X_test_splits, Y_train_splits, Y_test_splits = [], [], [], []\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        X_train_splits.append(X.iloc[train_index])\n",
    "        X_test_splits.append(X.iloc[test_index])\n",
    "        Y_train_splits.append(Y.iloc[train_index])\n",
    "        Y_test_splits.append(Y.iloc[test_index])\n",
    "\n",
    "    preds = []\n",
    "    for X_train1, Y_train1, X_test1, Y_test1 in zip(X_train_splits, Y_train_splits, X_test_splits, Y_test_splits):\n",
    "        clf = RandomForestClassifier(max_depth=max(2 * len(colList) // 3,3), random_state=100)\n",
    "        clf.fit(X_train1, Y_train1)\n",
    "        preds.append(clf.predict(X_test1))\n",
    "\n",
    "    tempVals = []\n",
    "\n",
    "    acc = 0\n",
    "    for pred, Y_test1 in zip(preds, Y_test_splits):\n",
    "        acc += accuracy_score(pred, Y_test1)\n",
    "\n",
    "    return acc/N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fitting-jurisdiction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text 2 props - 19k</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>67.159664</td>\n",
       "      <td>1.159664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Complex - 19k</th>\n",
       "      <td>66.865546</td>\n",
       "      <td>67.159664</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combined</th>\n",
       "      <td>68.899160</td>\n",
       "      <td>69.168067</td>\n",
       "      <td>0.268908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transe - 19k</th>\n",
       "      <td>66.865546</td>\n",
       "      <td>66.571429</td>\n",
       "      <td>-0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abstract - 19k</th>\n",
       "      <td>66.546218</td>\n",
       "      <td>65.983193</td>\n",
       "      <td>-0.563025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 7 props - 19k</th>\n",
       "      <td>67.747899</td>\n",
       "      <td>67.159664</td>\n",
       "      <td>-0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abstract First Sentence - 19k</th>\n",
       "      <td>73.218487</td>\n",
       "      <td>71.504202</td>\n",
       "      <td>-1.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "Text 2 props - 19k                                                     66.000000                  \n",
       "Complex - 19k                                                          66.865546                  \n",
       "Combined                                                               68.899160                  \n",
       "Transe - 19k                                                           66.865546                  \n",
       "Abstract - 19k                                                         66.546218                  \n",
       "Text 7 props - 19k                                                     67.747899                  \n",
       "Abstract First Sentence - 19k                                          73.218487                  \n",
       "\n",
       "                               Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "Text 2 props - 19k                                                     67.159664                  \n",
       "Complex - 19k                                                          67.159664                  \n",
       "Combined                                                               69.168067                  \n",
       "Transe - 19k                                                           66.571429                  \n",
       "Abstract - 19k                                                         65.983193                  \n",
       "Text 7 props - 19k                                                     67.159664                  \n",
       "Abstract First Sentence - 19k                                          71.504202                  \n",
       "\n",
       "                               Increase  \n",
       "Text 2 props - 19k             1.159664  \n",
       "Complex - 19k                  0.294118  \n",
       "Combined                       0.268908  \n",
       "Transe - 19k                  -0.294118  \n",
       "Abstract - 19k                -0.563025  \n",
       "Text 7 props - 19k            -0.588235  \n",
       "Abstract First Sentence - 19k -1.714286  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldColList = ['text_7props_19k_old_cosSim',\n",
    "'text_2props_19k_old_cosSim',\n",
    " 'complex_19k_old_cosSim',\n",
    " 'transe_19k_old_cosSim',\n",
    " 'abstract_19k_old_cosSim',\n",
    " 'abstract_firstSent_19k_old_cosSim']\n",
    "indNames = ['Text 7 props - 19k', 'Text 2 props - 19k', 'Complex - 19k', \n",
    "            'Transe - 19k', 'Abstract - 19k', 'Abstract First Sentence - 19k']\n",
    "compareEmbeddings(wordSim353AnnotDF_New_Merged_DF, oldColList, [colMappers[col] for col in oldColList], indNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "loose-cuisine",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Complex + Transe + Abstract FirstSent 19k</th>\n",
       "      <td>66.176471</td>\n",
       "      <td>66.462185</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combined</th>\n",
       "      <td>68.756303</td>\n",
       "      <td>69.033613</td>\n",
       "      <td>0.277311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text7, Text2, Complex, Transe, Abstract, Abstract FirstSent</th>\n",
       "      <td>69.630252</td>\n",
       "      <td>69.327731</td>\n",
       "      <td>-0.302521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "Complex + Transe + Abstract FirstSent 19k                                                   66.176471                  \n",
       "Combined                                                                                    68.756303                  \n",
       "Text7, Text2, Complex, Transe, Abstract, Abstra...                                          69.630252                  \n",
       "\n",
       "                                                    Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "Complex + Transe + Abstract FirstSent 19k                                                   66.462185                  \n",
       "Combined                                                                                    69.033613                  \n",
       "Text7, Text2, Complex, Transe, Abstract, Abstra...                                          69.327731                  \n",
       "\n",
       "                                                    Increase  \n",
       "Complex + Transe + Abstract FirstSent 19k           0.285714  \n",
       "Combined                                            0.277311  \n",
       "Text7, Text2, Complex, Transe, Abstract, Abstra... -0.302521  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldColList = ['concat_19k_v1_old_cosSim',\n",
    "'concat_19k_v2_old_cosSim']\n",
    "indNames = ['Complex + Transe + Abstract FirstSent 19k', 'Text7, Text2, Complex, Transe, Abstract, Abstract FirstSent']\n",
    "compareEmbeddings(wordSim353AnnotDF_New_Merged_DF, oldColList, [colMappers[col] for col in oldColList], indNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "second-lightning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_7props_19k_old_cosSim',\n",
       " 'text_2props_19k_old_cosSim',\n",
       " 'complex_19k_old_cosSim',\n",
       " 'transe_19k_old_cosSim',\n",
       " 'abstract_19k_old_cosSim',\n",
       " 'abstract_firstSent_19k_old_cosSim',\n",
       " 'complex_probase_old_cosSim',\n",
       " 'transe_probase_old_cosSim',\n",
       " 'complex_probase_19k_old_cosSim',\n",
       " 'transe_probase_19k_old_cosSim',\n",
       " 'concat_19k_v1_old_cosSim',\n",
       " 'concat_probase_19k_v1_old_cosSim',\n",
       " 'concat_19k_v2_old_cosSim',\n",
       " 'concat_probase_19k_v2_old_cosSim']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda p: 'old_cosSim' in p, wordSim353AnnotDF_New_Merged_DF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "institutional-gamma",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oldColList = ['text_7props_19k_old_cosSim',\n",
    " 'text_2props_19k_old_cosSim',\n",
    " 'complex_19k_old_cosSim',\n",
    " 'transe_19k_old_cosSim',\n",
    " 'abstract_19k_old_cosSim',\n",
    " 'abstract_firstSent_19k_old_cosSim',\n",
    " 'complex_probase_old_cosSim',\n",
    " 'transe_probase_old_cosSim',\n",
    " 'complex_probase_19k_old_cosSim',\n",
    " 'transe_probase_19k_old_cosSim',\n",
    " 'concat_19k_v1_old_cosSim',\n",
    " 'concat_probase_19k_v1_old_cosSim',\n",
    " 'concat_19k_v2_old_cosSim',\n",
    " 'concat_probase_19k_v2_old_cosSim']\n",
    "indNames = ['Text 7 props - 19k', 'Text 2 props - 19k', 'Complex - 19k', 'Transe - 19k', \n",
    "            'Abstract - 19k', 'Abstract First Sentence - 19k', 'Complex - Probase', 'Transe - Probase', \n",
    "            'Complex - Probase-19k', 'Transe - Probase-19k', 'Complex-Transe-AbsFirstSent - 19k',\n",
    "            'Complex-Transe-AbsFirstSent - Probase-19k', '6 embeddings - 19k',\n",
    "            '6 embeddings - Probase-19k']\n",
    "compareEmbeddings(wordSim353AnnotDF_New_Merged_DF, oldColList, [colMappers[col] for col in oldColList], indNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-store",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "processed-reynolds",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oldColList = ['text_7props_19k_old_cosSim',\n",
    " 'text_2props_19k_old_cosSim',\n",
    " 'complex_19k_old_cosSim',\n",
    " 'transe_19k_old_cosSim',\n",
    " 'abstract_19k_old_cosSim',\n",
    " 'abstract_firstSent_19k_old_cosSim',\n",
    " 'complex_probase_old_cosSim',\n",
    " 'transe_probase_old_cosSim',\n",
    " 'complex_probase_19k_old_cosSim',\n",
    " 'transe_probase_19k_old_cosSim',\n",
    " 'concat_19k_v1_old_cosSim',\n",
    " 'concat_probase_19k_v1_old_cosSim',\n",
    " 'concat_19k_v2_old_cosSim',\n",
    " 'concat_probase_19k_v2_old_cosSim']\n",
    "indNames = ['Text 7 props - 19k', 'Text 2 props - 19k', 'Complex - 19k', 'Transe - 19k', \n",
    "            'Abstract - 19k', 'Abstract First Sentence - 19k', 'Complex - Probase', 'Transe - Probase', \n",
    "            'Complex - Probase-19k', 'Transe - Probase-19k', 'Complex-Transe-AbsFirstSent - 19k',\n",
    "            'Complex-Transe-AbsFirstSent - Probase-19k', '6 embeddings - 19k',\n",
    "            '6 embeddings - Probase-19k']\n",
    "oldColPairs = list(zip(oldColList, indNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "forced-dining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 7 props - 19k\n",
      "Text 2 props - 19k\n",
      "Complex - 19k\n",
      "Transe - 19k\n",
      "Abstract - 19k\n",
      "Abstract First Sentence - 19k\n",
      "Complex - Probase\n",
      "Transe - Probase\n",
      "Complex - Probase-19k\n",
      "Transe - Probase-19k\n",
      "Complex-Transe-AbsFirstSent - 19k\n",
      "Complex-Transe-AbsFirstSent - Probase-19k\n",
      "6 embeddings - 19k\n",
      "6 embeddings - Probase-19k\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(indNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "permanent-comfort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb(len(oldColPairs), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "quantitative-japanese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**(len(oldColPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accs = []\n",
    "# for r in tqdm(range(1,len(oldColPairs)+1)):\n",
    "#     for comb in tqdm(combinations(oldColPairs, r)):\n",
    "#         print(len(comb))\n",
    "# #         oldAcc = trainAndFindAccuracy(wordSim353AnnotDF_New_Merged_DF, [col[0] for col in comb])\n",
    "# #         newAcc = trainAndFindAccuracy(wordSim353AnnotDF_New_Merged_DF, [colMappers[col[0]] for col in comb])\n",
    "#         print(\" & \".join([col[1] for col in comb]).count(\"&\"))\n",
    "# #         accs.append((indName, oldAcc, newAcc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "fatal-publicity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77739ea8b6bf4cfb933f406e6e9699a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def generateCombAccuracies(oldColPairs, r):\n",
    "    accs = []\n",
    "    for comb in tqdm(combinations(oldColPairs, r)):\n",
    "        assert len(comb) == r\n",
    "        oldAcc = trainAndFindAccuracy(wordSim353AnnotDF_New_Merged_DF, [col[0] for col in comb])\n",
    "        newAcc = trainAndFindAccuracy(wordSim353AnnotDF_New_Merged_DF, [colMappers[col[0]] for col in comb])\n",
    "        indName = \" & \".join([col[1] for col in comb])\n",
    "        accs.append((indName, oldAcc, newAcc))\n",
    "    return accs\n",
    "    \n",
    "results = Parallel(n_jobs=14)(delayed(generateCombAccuracies)(oldColPairs, i) for i in tqdm(range(1,len(oldColPairs)+1)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "documentary-production",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# def generateCombAccuracies(oldColPairs, r):\n",
    "#     accs = []\n",
    "#     for comb in tqdm(combinations(oldColPairs, r)):\n",
    "#         assert len(comb) == r\n",
    "#         oldAcc = trainAndFindAccuracyRF(wordSim353AnnotDF_New_Merged_DF, [col[0] for col in comb])\n",
    "#         newAcc = trainAndFindAccuracyRF(wordSim353AnnotDF_New_Merged_DF, [colMappers[col[0]] for col in comb])\n",
    "#         indName = \" & \".join([col[1] for col in comb])\n",
    "#         accs.append((indName, oldAcc, newAcc))\n",
    "#     return accs\n",
    "    \n",
    "# results = Parallel(n_jobs=14)(delayed(generateCombAccuracies)(oldColPairs, i) for i in tqdm(range(1,len(oldColPairs)+1)))\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "necessary-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_flat = [item for sublist in results for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "divided-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_flat == results_flat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "large-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs = (pd.DataFrame(results_flat, columns = ['Combination','Accuracy (in %) of old embeddings compared to annotated category', 'Accuracy (in %) of new embeddings compared to annotated category']).set_index('Combination') * 100).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "moved-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs['Increase'] = allCombs['Accuracy (in %) of new embeddings compared to annotated category'] - allCombs['Accuracy (in %) of old embeddings compared to annotated category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "biological-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs['count'] = allCombs['Combination'].apply(lambda p: p.count(\"&\")+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "artificial-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs.to_csv('../data/wordsim353_all_combinations_SVM_accuracies.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "restricted-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs = pd.read_csv('../data/wordsim353_all_combinations_SVM_accuracies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "palestinian-sharp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text 7 props - 19k</td>\n",
       "      <td>65.428571</td>\n",
       "      <td>65.126050</td>\n",
       "      <td>-0.302521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text 2 props - 19k</td>\n",
       "      <td>64.554622</td>\n",
       "      <td>63.680672</td>\n",
       "      <td>-0.873950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complex - 19k</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>65.445378</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transe - 19k</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>66.890756</td>\n",
       "      <td>2.310924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract - 19k</td>\n",
       "      <td>67.739496</td>\n",
       "      <td>68.050420</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Combination  \\\n",
       "0  Text 7 props - 19k   \n",
       "1  Text 2 props - 19k   \n",
       "2       Complex - 19k   \n",
       "3        Transe - 19k   \n",
       "4      Abstract - 19k   \n",
       "\n",
       "   Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "0                                          65.428571                  \n",
       "1                                          64.554622                  \n",
       "2                                          64.579832                  \n",
       "3                                          64.579832                  \n",
       "4                                          67.739496                  \n",
       "\n",
       "   Accuracy (in %) of new embeddings compared to annotated category  Increase  \\\n",
       "0                                          65.126050                -0.302521   \n",
       "1                                          63.680672                -0.873950   \n",
       "2                                          65.445378                 0.865546   \n",
       "3                                          66.890756                 2.310924   \n",
       "4                                          68.050420                 0.310924   \n",
       "\n",
       "   count  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "congressional-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined accuracies of 16383 combinations of embedding scores based on the length 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Determined accuracies of {len(allCombs)} combinations of embedding scores based on the length {len(oldColPairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "single-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "sharp-tunisia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>72.705882</td>\n",
       "      <td>71.537815</td>\n",
       "      <td>-1.168067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>71.840336</td>\n",
       "      <td>70.966387</td>\n",
       "      <td>-0.873950</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>71.840336</td>\n",
       "      <td>70.378151</td>\n",
       "      <td>-1.462185</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>71.840336</td>\n",
       "      <td>71.848739</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Abstract - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>71.546218</td>\n",
       "      <td>71.243697</td>\n",
       "      <td>-0.302521</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12350</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>69.504202</td>\n",
       "      <td>-1.470588</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>70.075630</td>\n",
       "      <td>-0.899160</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12154</th>\n",
       "      <td>Text 2 props - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>70.084034</td>\n",
       "      <td>-0.890756</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11944</th>\n",
       "      <td>Text 2 props - 19k &amp; Complex - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>69.781513</td>\n",
       "      <td>-1.193277</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12349</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase-19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>69.210084</td>\n",
       "      <td>-1.764706</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                         Combination  \\\n",
       "5      Abstract First Sentence - 19k                                                                                                                                                                                                   \n",
       "30     Text 2 props - 19k & Abstract First Sentence - 19k                                                                                                                                                                              \n",
       "204    Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k                                                                                                                                                             \n",
       "18     Text 7 props - 19k & Abstract First Sentence - 19k                                                                                                                                                                              \n",
       "60     Abstract - 19k & Abstract First Sentence - 19k                                                                                                                                                                                  \n",
       "12350  Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Transe - Probase-19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k    \n",
       "12329  Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex - Probase & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k       \n",
       "12154  Text 2 props - 19k & Transe - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k            \n",
       "11944  Text 2 props - 19k & Complex - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k           \n",
       "12349  Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex - Probase-19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k   \n",
       "\n",
       "       Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "5      72.705882                                                          \n",
       "30     71.840336                                                          \n",
       "204    71.840336                                                          \n",
       "18     71.840336                                                          \n",
       "60     71.546218                                                          \n",
       "12350  70.974790                                                          \n",
       "12329  70.974790                                                          \n",
       "12154  70.974790                                                          \n",
       "11944  70.974790                                                          \n",
       "12349  70.974790                                                          \n",
       "\n",
       "       Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "5      71.537815                                                          \n",
       "30     70.966387                                                          \n",
       "204    70.378151                                                          \n",
       "18     71.848739                                                          \n",
       "60     71.243697                                                          \n",
       "12350  69.504202                                                          \n",
       "12329  70.075630                                                          \n",
       "12154  70.084034                                                          \n",
       "11944  69.781513                                                          \n",
       "12349  69.210084                                                          \n",
       "\n",
       "       Increase  count  \n",
       "5     -1.168067  1      \n",
       "30    -0.873950  2      \n",
       "204   -1.462185  3      \n",
       "18     0.008403  2      \n",
       "60    -0.302521  2      \n",
       "12350 -1.470588  8      \n",
       "12329 -0.899160  8      \n",
       "12154 -0.890756  8      \n",
       "11944 -1.193277  8      \n",
       "12349 -1.764706  8      "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs.sort_values(by=['Accuracy (in %) of old embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "federal-timing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>71.840336</td>\n",
       "      <td>71.848739</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.394958</td>\n",
       "      <td>71.546218</td>\n",
       "      <td>1.151261</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>72.705882</td>\n",
       "      <td>71.537815</td>\n",
       "      <td>-1.168067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Transe - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>68.630252</td>\n",
       "      <td>71.521008</td>\n",
       "      <td>2.890756</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>69.210084</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>2.042017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>70.084034</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>1.168067</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.092437</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>1.159664</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7049</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.386555</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>Text 7 props - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>69.798319</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>1.453782</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11327</th>\n",
       "      <td>Text 7 props - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>70.100840</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>1.151261</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                Combination  \\\n",
       "18     Text 7 props - 19k & Abstract First Sentence - 19k                                                                                                                                                     \n",
       "5318   Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex - Probase & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - Probase-19k                                       \n",
       "5      Abstract First Sentence - 19k                                                                                                                                                                          \n",
       "51     Transe - 19k & Abstract First Sentence - 19k                                                                                                                                                           \n",
       "108    Text 7 props - 19k & Text 2 props - 19k & Abstract First Sentence - 19k                                                                                                                                \n",
       "694    Text 7 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k & 6 embeddings - 19k                                                                                            \n",
       "8035   Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Transe - Probase & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k                   \n",
       "7049   Text 7 props - 19k & Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Transe - Probase & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - Probase-19k                   \n",
       "1916   Text 7 props - 19k & Transe - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k                                                                     \n",
       "11327  Text 7 props - 19k & Transe - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex - Probase & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k   \n",
       "\n",
       "       Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "18     71.840336                                                          \n",
       "5318   70.394958                                                          \n",
       "5      72.705882                                                          \n",
       "51     68.630252                                                          \n",
       "108    69.210084                                                          \n",
       "694    70.084034                                                          \n",
       "8035   70.092437                                                          \n",
       "7049   70.386555                                                          \n",
       "1916   69.798319                                                          \n",
       "11327  70.100840                                                          \n",
       "\n",
       "       Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "18     71.848739                                                          \n",
       "5318   71.546218                                                          \n",
       "5      71.537815                                                          \n",
       "51     71.521008                                                          \n",
       "108    71.252101                                                          \n",
       "694    71.252101                                                          \n",
       "8035   71.252101                                                          \n",
       "7049   71.252101                                                          \n",
       "1916   71.252101                                                          \n",
       "11327  71.252101                                                          \n",
       "\n",
       "       Increase  count  \n",
       "18     0.008403  2      \n",
       "5318   1.151261  6      \n",
       "5     -1.168067  1      \n",
       "51     2.890756  2      \n",
       "108    2.042017  3      \n",
       "694    1.168067  4      \n",
       "8035   1.159664  7      \n",
       "7049   0.865546  7      \n",
       "1916   1.453782  5      \n",
       "11327  1.151261  8      "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs.sort_values(by=['Accuracy (in %) of new embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "known-basement",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase-19k &amp; Transe - Probase-19k</td>\n",
       "      <td>66.285714</td>\n",
       "      <td>69.193277</td>\n",
       "      <td>2.907563</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Transe - Probase &amp; Complex - Probase-19k</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>68.613445</td>\n",
       "      <td>2.899160</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Transe - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>68.630252</td>\n",
       "      <td>71.521008</td>\n",
       "      <td>2.890756</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9440</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Transe - Probase &amp; Complex - Probase-19k &amp; Transe - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>66.563025</td>\n",
       "      <td>69.184874</td>\n",
       "      <td>2.621849</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>Complex - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Complex - Probase-19k &amp; Transe - Probase-19k</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>68.327731</td>\n",
       "      <td>2.613445</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Transe - Probase &amp; Complex - Probase-19k</td>\n",
       "      <td>66.285714</td>\n",
       "      <td>68.899160</td>\n",
       "      <td>2.613445</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Transe - Probase-19k</td>\n",
       "      <td>66.285714</td>\n",
       "      <td>68.899160</td>\n",
       "      <td>2.613445</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>Complex - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Complex - Probase-19k</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>68.319328</td>\n",
       "      <td>2.605042</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Complex - Probase-19k &amp; Transe - Probase-19k</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>68.319328</td>\n",
       "      <td>2.605042</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Complex - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>68.647059</td>\n",
       "      <td>71.226891</td>\n",
       "      <td>2.579832</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            Combination  \\\n",
       "1041  Complex - 19k & Abstract - 19k & Complex - Probase-19k & Transe - Probase-19k                                                                       \n",
       "2828  Complex - 19k & Abstract - 19k & Complex - Probase & Transe - Probase & Complex - Probase-19k                                                       \n",
       "51    Transe - 19k & Abstract First Sentence - 19k                                                                                                        \n",
       "9440  Complex - 19k & Abstract - 19k & Complex - Probase & Transe - Probase & Complex - Probase-19k & Transe - Probase-19k & 6 embeddings - Probase-19k   \n",
       "2701  Complex - 19k & Transe - 19k & Abstract - 19k & Complex - Probase-19k & Transe - Probase-19k                                                        \n",
       "1035  Complex - 19k & Abstract - 19k & Transe - Probase & Complex - Probase-19k                                                                           \n",
       "1030  Complex - 19k & Abstract - 19k & Complex - Probase & Transe - Probase-19k                                                                           \n",
       "2689  Complex - 19k & Transe - 19k & Abstract - 19k & Complex - Probase & Complex - Probase-19k                                                           \n",
       "2834  Complex - 19k & Abstract - 19k & Complex - Probase & Complex - Probase-19k & Transe - Probase-19k                                                   \n",
       "1026  Complex - 19k & Abstract - 19k & Abstract First Sentence - 19k & 6 embeddings - 19k                                                                 \n",
       "\n",
       "      Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "1041  66.285714                                                          \n",
       "2828  65.714286                                                          \n",
       "51    68.630252                                                          \n",
       "9440  66.563025                                                          \n",
       "2701  65.714286                                                          \n",
       "1035  66.285714                                                          \n",
       "1030  66.285714                                                          \n",
       "2689  65.714286                                                          \n",
       "2834  65.714286                                                          \n",
       "1026  68.647059                                                          \n",
       "\n",
       "      Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "1041  69.193277                                                          \n",
       "2828  68.613445                                                          \n",
       "51    71.521008                                                          \n",
       "9440  69.184874                                                          \n",
       "2701  68.327731                                                          \n",
       "1035  68.899160                                                          \n",
       "1030  68.899160                                                          \n",
       "2689  68.319328                                                          \n",
       "2834  68.319328                                                          \n",
       "1026  71.226891                                                          \n",
       "\n",
       "      Increase  count  \n",
       "1041  2.907563  4      \n",
       "2828  2.899160  5      \n",
       "51    2.890756  2      \n",
       "9440  2.621849  7      \n",
       "2701  2.613445  5      \n",
       "1035  2.613445  4      \n",
       "1030  2.613445  4      \n",
       "2689  2.605042  5      \n",
       "2834  2.605042  5      \n",
       "1026  2.579832  4      "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs.sort_values(by=['Increase'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "private-conditions",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>72.705882</td>\n",
       "      <td>71.537815</td>\n",
       "      <td>-1.168067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6 embeddings - 19k</td>\n",
       "      <td>70.092437</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>1.159664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6 embeddings - Probase-19k</td>\n",
       "      <td>70.092437</td>\n",
       "      <td>70.672269</td>\n",
       "      <td>0.579832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract - 19k</td>\n",
       "      <td>67.739496</td>\n",
       "      <td>68.050420</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>67.470588</td>\n",
       "      <td>67.176471</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - 19k</td>\n",
       "      <td>67.470588</td>\n",
       "      <td>66.899160</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transe - 19k</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>66.890756</td>\n",
       "      <td>2.310924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Transe - Probase-19k</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>66.890756</td>\n",
       "      <td>2.310924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transe - Probase</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>66.596639</td>\n",
       "      <td>2.016807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Complex - Probase-19k</td>\n",
       "      <td>64.579832</td>\n",
       "      <td>65.445378</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Combination  \\\n",
       "5   Abstract First Sentence - 19k               \n",
       "12  6 embeddings - 19k                          \n",
       "13  6 embeddings - Probase-19k                  \n",
       "4   Abstract - 19k                              \n",
       "11  Complex-Transe-AbsFirstSent - Probase-19k   \n",
       "10  Complex-Transe-AbsFirstSent - 19k           \n",
       "3   Transe - 19k                                \n",
       "9   Transe - Probase-19k                        \n",
       "7   Transe - Probase                            \n",
       "8   Complex - Probase-19k                       \n",
       "\n",
       "    Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "5   72.705882                                                          \n",
       "12  70.092437                                                          \n",
       "13  70.092437                                                          \n",
       "4   67.739496                                                          \n",
       "11  67.470588                                                          \n",
       "10  67.470588                                                          \n",
       "3   64.579832                                                          \n",
       "9   64.579832                                                          \n",
       "7   64.579832                                                          \n",
       "8   64.579832                                                          \n",
       "\n",
       "    Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "5   71.537815                                                          \n",
       "12  71.252101                                                          \n",
       "13  70.672269                                                          \n",
       "4   68.050420                                                          \n",
       "11  67.176471                                                          \n",
       "10  66.899160                                                          \n",
       "3   66.890756                                                          \n",
       "9   66.890756                                                          \n",
       "7   66.596639                                                          \n",
       "8   65.445378                                                          \n",
       "\n",
       "    Increase  count  \n",
       "5  -1.168067  1      \n",
       "12  1.159664  1      \n",
       "13  0.579832  1      \n",
       "4   0.310924  1      \n",
       "11 -0.294118  1      \n",
       "10 -0.571429  1      \n",
       "3   2.310924  1      \n",
       "9   2.310924  1      \n",
       "7   2.016807  1      \n",
       "8   0.865546  1      "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs[allCombs['count'] == 1].sort_values(by=['Accuracy (in %) of new embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-think",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "trying-liabilities",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123c20d4e60b4e3e8b09c0e0e46efc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def generateCombAccuracies(oldColPairs, r):\n",
    "    accs = []\n",
    "    for comb in tqdm(combinations(oldColPairs, r)):\n",
    "        assert len(comb) == r\n",
    "        oldAcc = trainAndFindAccuracyRF(wordSim353AnnotDF_New_Merged_DF, [col[0] for col in comb])\n",
    "        newAcc = trainAndFindAccuracyRF(wordSim353AnnotDF_New_Merged_DF, [colMappers[col[0]] for col in comb])\n",
    "        indName = \" & \".join([col[1] for col in comb])\n",
    "        accs.append((indName, oldAcc, newAcc))\n",
    "    return accs\n",
    "    \n",
    "results1 = Parallel(n_jobs=14)(delayed(generateCombAccuracies)(oldColPairs, i) for i in tqdm(range(1,len(oldColPairs)+1)))\n",
    "print(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "competitive-liverpool",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results == results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "accredited-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_flat1 = [item for sublist in results1 for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "specialized-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs1 = (pd.DataFrame(results_flat1, columns = ['Combination','Accuracy (in %) of old embeddings compared to annotated category', 'Accuracy (in %) of new embeddings compared to annotated category']).set_index('Combination') * 100).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "published-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs1['Increase'] = allCombs1['Accuracy (in %) of new embeddings compared to annotated category'] - allCombs['Accuracy (in %) of old embeddings compared to annotated category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "nominated-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombs1['count'] = allCombs1['Combination'].apply(lambda p: p.count(\"&\")+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "alleged-fruit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text 7 props - 19k</td>\n",
       "      <td>65.126050</td>\n",
       "      <td>63.672269</td>\n",
       "      <td>-1.453782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text 2 props - 19k</td>\n",
       "      <td>61.899160</td>\n",
       "      <td>63.344538</td>\n",
       "      <td>1.445378</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complex - 19k</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>64.277311</td>\n",
       "      <td>-2.336134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transe - 19k</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>66.310924</td>\n",
       "      <td>-0.302521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract - 19k</td>\n",
       "      <td>68.899160</td>\n",
       "      <td>66.008403</td>\n",
       "      <td>-2.890756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Combination  \\\n",
       "0  Text 7 props - 19k   \n",
       "1  Text 2 props - 19k   \n",
       "2  Complex - 19k        \n",
       "3  Transe - 19k         \n",
       "4  Abstract - 19k       \n",
       "\n",
       "   Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "0  65.126050                                                          \n",
       "1  61.899160                                                          \n",
       "2  66.613445                                                          \n",
       "3  66.613445                                                          \n",
       "4  68.899160                                                          \n",
       "\n",
       "   Accuracy (in %) of new embeddings compared to annotated category  Increase  \\\n",
       "0  63.672269                                                        -1.453782   \n",
       "1  63.344538                                                         1.445378   \n",
       "2  64.277311                                                        -2.336134   \n",
       "3  66.310924                                                        -0.302521   \n",
       "4  66.008403                                                        -2.890756   \n",
       "\n",
       "   count  \n",
       "0  1      \n",
       "1  1      \n",
       "2  1      \n",
       "3  1      \n",
       "4  1      "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "increased-indonesian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined accuracies of 16383 combinations of embedding scores based on the length 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Determined accuracies of {len(allCombs1)} combinations of embedding scores based on the length {len(oldColPairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "english-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fantastic-narrow",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>73.285714</td>\n",
       "      <td>70.075630</td>\n",
       "      <td>-3.210084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Abstract - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>72.117647</td>\n",
       "      <td>68.327731</td>\n",
       "      <td>-3.789916</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>72.100840</td>\n",
       "      <td>70.361345</td>\n",
       "      <td>-1.739496</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k</td>\n",
       "      <td>71.831933</td>\n",
       "      <td>70.378151</td>\n",
       "      <td>-1.453782</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>71.831933</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>-0.579832</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>71.815126</td>\n",
       "      <td>69.789916</td>\n",
       "      <td>-2.025210</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>71.815126</td>\n",
       "      <td>69.798319</td>\n",
       "      <td>-2.016807</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>71.815126</td>\n",
       "      <td>70.378151</td>\n",
       "      <td>-1.436975</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>71.815126</td>\n",
       "      <td>69.495798</td>\n",
       "      <td>-2.319328</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>71.815126</td>\n",
       "      <td>69.487395</td>\n",
       "      <td>-2.327731</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           Combination  \\\n",
       "5     Abstract First Sentence - 19k                                                                                                                      \n",
       "60    Abstract - 19k & Abstract First Sentence - 19k                                                                                                     \n",
       "138   Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k                                                                                \n",
       "151   Text 7 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k                                                             \n",
       "152   Text 7 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k                                                     \n",
       "2114  Text 7 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k   \n",
       "2001  Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - Probase-19k       \n",
       "2000  Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k               \n",
       "1999  Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k & 6 embeddings - Probase-19k               \n",
       "1998  Text 7 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k & 6 embeddings - 19k                       \n",
       "\n",
       "      Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "5     73.285714                                                          \n",
       "60    72.117647                                                          \n",
       "138   72.100840                                                          \n",
       "151   71.831933                                                          \n",
       "152   71.831933                                                          \n",
       "2114  71.815126                                                          \n",
       "2001  71.815126                                                          \n",
       "2000  71.815126                                                          \n",
       "1999  71.815126                                                          \n",
       "1998  71.815126                                                          \n",
       "\n",
       "      Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "5     70.075630                                                          \n",
       "60    68.327731                                                          \n",
       "138   70.361345                                                          \n",
       "151   70.378151                                                          \n",
       "152   71.252101                                                          \n",
       "2114  69.789916                                                          \n",
       "2001  69.798319                                                          \n",
       "2000  70.378151                                                          \n",
       "1999  69.495798                                                          \n",
       "1998  69.487395                                                          \n",
       "\n",
       "      Increase  count  \n",
       "5    -3.210084  1      \n",
       "60   -3.789916  2      \n",
       "138  -1.739496  3      \n",
       "151  -1.453782  3      \n",
       "152  -0.579832  3      \n",
       "2114 -2.025210  5      \n",
       "2001 -2.016807  5      \n",
       "2000 -1.436975  5      \n",
       "1999 -2.319328  5      \n",
       "1998 -2.327731  5      "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs1.sort_values(by=['Accuracy (in %) of old embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "brown-punishment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>70.663866</td>\n",
       "      <td>71.260504</td>\n",
       "      <td>0.596639</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>71.226891</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Abstract - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>71.235294</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>71.831933</td>\n",
       "      <td>71.252101</td>\n",
       "      <td>-0.579832</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase-19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>68.310924</td>\n",
       "      <td>71.235294</td>\n",
       "      <td>2.924370</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Text 7 props - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k</td>\n",
       "      <td>69.764706</td>\n",
       "      <td>71.235294</td>\n",
       "      <td>1.470588</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Text 2 props - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - 19k</td>\n",
       "      <td>71.226891</td>\n",
       "      <td>70.974790</td>\n",
       "      <td>-0.252101</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Text 7 props - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>71.529412</td>\n",
       "      <td>70.966387</td>\n",
       "      <td>-0.563025</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>68.605042</td>\n",
       "      <td>70.966387</td>\n",
       "      <td>2.361345</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Text 7 props - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>70.663866</td>\n",
       "      <td>70.966387</td>\n",
       "      <td>0.302521</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      Combination  \\\n",
       "681   Text 7 props - 19k & Abstract First Sentence - 19k & Transe - Probase & Complex-Transe-AbsFirstSent - Probase-19k                                                                                             \n",
       "218   Text 2 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k                                                                                                                \n",
       "1575  Text 7 props - 19k & Text 2 props - 19k & Abstract - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k                                                                          \n",
       "152   Text 7 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k                                                                                                                \n",
       "3884  Text 7 props - 19k & Text 2 props - 19k & Abstract First Sentence - 19k & Complex - Probase-19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k                                              \n",
       "129   Text 7 props - 19k & Transe - 19k & Abstract First Sentence - 19k                                                                                                                                             \n",
       "217   Text 2 props - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - 19k                                                                                                                        \n",
       "604   Text 7 props - 19k & Transe - 19k & Abstract First Sentence - 19k & Complex-Transe-AbsFirstSent - Probase-19k                                                                                                 \n",
       "7207  Text 7 props - 19k & Text 2 props - 19k & Abstract First Sentence - 19k & Transe - Probase-19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - Probase-19k   \n",
       "690   Text 7 props - 19k & Abstract First Sentence - 19k & Transe - Probase-19k & Complex-Transe-AbsFirstSent - Probase-19k                                                                                         \n",
       "\n",
       "      Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "681   70.663866                                                          \n",
       "218   71.226891                                                          \n",
       "1575  71.235294                                                          \n",
       "152   71.831933                                                          \n",
       "3884  68.310924                                                          \n",
       "129   69.764706                                                          \n",
       "217   71.226891                                                          \n",
       "604   71.529412                                                          \n",
       "7207  68.605042                                                          \n",
       "690   70.663866                                                          \n",
       "\n",
       "      Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "681   71.260504                                                          \n",
       "218   71.252101                                                          \n",
       "1575  71.252101                                                          \n",
       "152   71.252101                                                          \n",
       "3884  71.235294                                                          \n",
       "129   71.235294                                                          \n",
       "217   70.974790                                                          \n",
       "604   70.966387                                                          \n",
       "7207  70.966387                                                          \n",
       "690   70.966387                                                          \n",
       "\n",
       "      Increase  count  \n",
       "681   0.596639  4      \n",
       "218   0.025210  3      \n",
       "1575  0.016807  5      \n",
       "152  -0.579832  3      \n",
       "3884  2.924370  6      \n",
       "129   1.470588  3      \n",
       "217  -0.252101  3      \n",
       "604  -0.563025  4      \n",
       "7207  2.361345  7      \n",
       "690   0.302521  4      "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs1.sort_values(by=['Accuracy (in %) of new embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "considerable-syndication",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13048</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Transe - Probase &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>64.252101</td>\n",
       "      <td>70.352941</td>\n",
       "      <td>6.100840</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13084</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>64.252101</td>\n",
       "      <td>69.210084</td>\n",
       "      <td>4.957983</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14022</th>\n",
       "      <td>Text 7 props - 19k &amp; Complex - 19k &amp; Abstract First Sentence - 19k &amp; Transe - Probase &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - 19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>64.529412</td>\n",
       "      <td>69.176471</td>\n",
       "      <td>4.647059</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13861</th>\n",
       "      <td>Text 7 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Transe - Probase-19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>64.243697</td>\n",
       "      <td>68.890756</td>\n",
       "      <td>4.647059</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7551</th>\n",
       "      <td>Text 7 props - 19k &amp; Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Complex - Probase-19k &amp; Transe - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>63.092437</td>\n",
       "      <td>67.722689</td>\n",
       "      <td>4.630252</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13058</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract First Sentence - 19k &amp; Complex - Probase &amp; Complex - Probase-19k &amp; Complex-Transe-AbsFirstSent - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>64.252101</td>\n",
       "      <td>68.605042</td>\n",
       "      <td>4.352941</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Complex - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>63.689076</td>\n",
       "      <td>68.033613</td>\n",
       "      <td>4.344538</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>Text 7 props - 19k &amp; Complex - 19k &amp; Abstract - 19k &amp; Complex - Probase &amp; Transe - Probase &amp; Complex - Probase-19k &amp; 6 embeddings - Probase-19k</td>\n",
       "      <td>63.092437</td>\n",
       "      <td>67.436975</td>\n",
       "      <td>4.344538</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>Text 7 props - 19k &amp; Complex - 19k &amp; Abstract - 19k &amp; Transe - Probase &amp; Complex - Probase-19k &amp; Transe - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>63.092437</td>\n",
       "      <td>67.428571</td>\n",
       "      <td>4.336134</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>Text 7 props - 19k &amp; Text 2 props - 19k &amp; Complex - 19k &amp; Transe - 19k &amp; Abstract - 19k &amp; Complex - Probase-19k &amp; 6 embeddings - 19k</td>\n",
       "      <td>63.689076</td>\n",
       "      <td>68.025210</td>\n",
       "      <td>4.336134</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                          Combination  \\\n",
       "13048  Text 7 props - 19k & Text 2 props - 19k & Complex - 19k & Transe - 19k & Abstract First Sentence - 19k & Complex - Probase & Transe - Probase & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k                                   \n",
       "13084  Text 7 props - 19k & Text 2 props - 19k & Complex - 19k & Transe - 19k & Abstract First Sentence - 19k & Transe - Probase & Transe - Probase-19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k                                \n",
       "14022  Text 7 props - 19k & Complex - 19k & Abstract First Sentence - 19k & Transe - Probase & Transe - Probase-19k & Complex-Transe-AbsFirstSent - 19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k   \n",
       "13861  Text 7 props - 19k & Complex - 19k & Transe - 19k & Abstract First Sentence - 19k & Complex - Probase & Transe - Probase-19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k & 6 embeddings - Probase-19k                       \n",
       "7551   Text 7 props - 19k & Complex - 19k & Abstract - 19k & Complex - Probase & Complex - Probase-19k & Transe - Probase-19k & 6 embeddings - Probase-19k                                                                                              \n",
       "13058  Text 7 props - 19k & Text 2 props - 19k & Complex - 19k & Transe - 19k & Abstract First Sentence - 19k & Complex - Probase & Complex - Probase-19k & Complex-Transe-AbsFirstSent - Probase-19k & 6 embeddings - 19k                              \n",
       "6500   Text 7 props - 19k & Text 2 props - 19k & Complex - 19k & Transe - 19k & Abstract - 19k & Complex - Probase-19k & 6 embeddings - Probase-19k                                                                                                     \n",
       "7537   Text 7 props - 19k & Complex - 19k & Abstract - 19k & Complex - Probase & Transe - Probase & Complex - Probase-19k & 6 embeddings - Probase-19k                                                                                                  \n",
       "7570   Text 7 props - 19k & Complex - 19k & Abstract - 19k & Transe - Probase & Complex - Probase-19k & Transe - Probase-19k & 6 embeddings - 19k                                                                                                       \n",
       "6499   Text 7 props - 19k & Text 2 props - 19k & Complex - 19k & Transe - 19k & Abstract - 19k & Complex - Probase-19k & 6 embeddings - 19k                                                                                                             \n",
       "\n",
       "       Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "13048  64.252101                                                          \n",
       "13084  64.252101                                                          \n",
       "14022  64.529412                                                          \n",
       "13861  64.243697                                                          \n",
       "7551   63.092437                                                          \n",
       "13058  64.252101                                                          \n",
       "6500   63.689076                                                          \n",
       "7537   63.092437                                                          \n",
       "7570   63.092437                                                          \n",
       "6499   63.689076                                                          \n",
       "\n",
       "       Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "13048  70.352941                                                          \n",
       "13084  69.210084                                                          \n",
       "14022  69.176471                                                          \n",
       "13861  68.890756                                                          \n",
       "7551   67.722689                                                          \n",
       "13058  68.605042                                                          \n",
       "6500   68.033613                                                          \n",
       "7537   67.436975                                                          \n",
       "7570   67.428571                                                          \n",
       "6499   68.025210                                                          \n",
       "\n",
       "       Increase  count  \n",
       "13048  6.100840  9      \n",
       "13084  4.957983  9      \n",
       "14022  4.647059  9      \n",
       "13861  4.647059  9      \n",
       "7551   4.630252  7      \n",
       "13058  4.352941  9      \n",
       "6500   4.344538  7      \n",
       "7537   4.344538  7      \n",
       "7570   4.336134  7      \n",
       "6499   4.336134  7      "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs1.sort_values(by=['Increase'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "binary-committee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy (in %) of old embeddings compared to annotated category</th>\n",
       "      <th>Accuracy (in %) of new embeddings compared to annotated category</th>\n",
       "      <th>Increase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - Probase-19k</td>\n",
       "      <td>70.042017</td>\n",
       "      <td>70.630252</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstract First Sentence - 19k</td>\n",
       "      <td>73.285714</td>\n",
       "      <td>70.075630</td>\n",
       "      <td>-3.210084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Complex-Transe-AbsFirstSent - 19k</td>\n",
       "      <td>70.042017</td>\n",
       "      <td>68.302521</td>\n",
       "      <td>-1.739496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6 embeddings - Probase-19k</td>\n",
       "      <td>68.907563</td>\n",
       "      <td>68.042017</td>\n",
       "      <td>-0.865546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6 embeddings - 19k</td>\n",
       "      <td>68.907563</td>\n",
       "      <td>66.857143</td>\n",
       "      <td>-2.050420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Complex - Probase</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>66.596639</td>\n",
       "      <td>-0.016807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transe - Probase</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>66.596639</td>\n",
       "      <td>-0.016807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transe - 19k</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>66.310924</td>\n",
       "      <td>-0.302521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Transe - Probase-19k</td>\n",
       "      <td>66.613445</td>\n",
       "      <td>66.008403</td>\n",
       "      <td>-0.605042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract - 19k</td>\n",
       "      <td>68.899160</td>\n",
       "      <td>66.008403</td>\n",
       "      <td>-2.890756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Combination  \\\n",
       "11  Complex-Transe-AbsFirstSent - Probase-19k   \n",
       "5   Abstract First Sentence - 19k               \n",
       "10  Complex-Transe-AbsFirstSent - 19k           \n",
       "13  6 embeddings - Probase-19k                  \n",
       "12  6 embeddings - 19k                          \n",
       "6   Complex - Probase                           \n",
       "7   Transe - Probase                            \n",
       "3   Transe - 19k                                \n",
       "9   Transe - Probase-19k                        \n",
       "4   Abstract - 19k                              \n",
       "\n",
       "    Accuracy (in %) of old embeddings compared to annotated category  \\\n",
       "11  70.042017                                                          \n",
       "5   73.285714                                                          \n",
       "10  70.042017                                                          \n",
       "13  68.907563                                                          \n",
       "12  68.907563                                                          \n",
       "6   66.613445                                                          \n",
       "7   66.613445                                                          \n",
       "3   66.613445                                                          \n",
       "9   66.613445                                                          \n",
       "4   68.899160                                                          \n",
       "\n",
       "    Accuracy (in %) of new embeddings compared to annotated category  \\\n",
       "11  70.630252                                                          \n",
       "5   70.075630                                                          \n",
       "10  68.302521                                                          \n",
       "13  68.042017                                                          \n",
       "12  66.857143                                                          \n",
       "6   66.596639                                                          \n",
       "7   66.596639                                                          \n",
       "3   66.310924                                                          \n",
       "9   66.008403                                                          \n",
       "4   66.008403                                                          \n",
       "\n",
       "    Increase  count  \n",
       "11  0.588235  1      \n",
       "5  -3.210084  1      \n",
       "10 -1.739496  1      \n",
       "13 -0.865546  1      \n",
       "12 -2.050420  1      \n",
       "6  -0.016807  1      \n",
       "7  -0.016807  1      \n",
       "3  -0.302521  1      \n",
       "9  -0.605042  1      \n",
       "4  -2.890756  1      "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombs1[allCombs1['count'] == 1].sort_values(by=['Accuracy (in %) of new embeddings compared to annotated category'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-event",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-spider",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-thought",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "western-easter",
   "metadata": {},
   "source": [
    "# Generate Embeddings Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "nervous-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = pd.concat([wordSim353AnnotDF_New2[['word1_kg_id', 'Word 1']], wordSim353AnnotDF_New2[['word2_kg_id', 'Word 2']].rename(columns={'Word 2': 'Word 1', 'word2_kg_id': 'word1_kg_id'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "neither-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = wordList[~wordList.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "welsh-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList['word1_kg_id'].apply(lambda p: \"\\t\".join([str(p1) for p1 in embedDict[p].tolist()])).to_csv('../data/wordsim353_embeddings.tsv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "processed-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList['word1_kg_id'].apply(lambda p: \"\\t\".join([str(p1) for p1 in newEmbedDict[p].tolist()])).to_csv('../data/wordsim353_embeddings_new_attempt1.tsv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "psychological-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList['Word 1'].to_csv('../data/wordsim353_embeddings_words.tsv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-munich",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-appliance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-textbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-orlando",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-qatar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-brick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-kernel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-atlas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-means",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-fever",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-baker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-charm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgtkEnv",
   "language": "python",
   "name": "kgtkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "308px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
